2025-04-18 19:15:21.357 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 19:15:21.371 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 19:15:21.431 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: shizuku-local | {}
2025-04-18 19:15:21.431 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 19:15:21.431 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: sherpa_onnx_asr | {}
2025-04-18 19:15:32.966 | INFO     | src.open_llm_vtuber.asr.sherpa_onnx_asr:__init__:81 | Sherpa-Onnx-ASR: Using cpu for inference | {}
2025-04-18 19:15:32.966 | WARNING  | src.open_llm_vtuber.asr.sherpa_onnx_asr:_create_recognizer:166 | SenseVoice model not found. Downloading the model... | {}
2025-04-18 19:15:32.966 | WARNING  | src.open_llm_vtuber.asr.utils:check_and_extract_local_file:160 | Local file not found or not a tar.bz2 archive: models\sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17.tar.bz2 | {}
2025-04-18 19:15:32.966 | INFO     | src.open_llm_vtuber.asr.sherpa_onnx_asr:_create_recognizer:176 | Local file not found. Downloading... | {}
2025-04-18 19:15:32.966 | INFO     | src.open_llm_vtuber.asr.utils:download_and_extract:82 | üèÉ‚Äç‚ôÇÔ∏èDownloading https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17.tar.bz2 to ./models\sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17.tar.bz2... | {}
2025-04-18 19:15:34.334 | DEBUG    | src.open_llm_vtuber.asr.utils:download_and_extract:86 | Total file size: 999.33 MB | {}
2025-04-18 19:16:59.359 | INFO     | src.open_llm_vtuber.asr.utils:download_and_extract:102 | Downloaded sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17.tar.bz2 successfully. | {}
2025-04-18 19:16:59.360 | INFO     | src.open_llm_vtuber.asr.utils:download_and_extract:106 | Extracting sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17.tar.bz2... | {}
2025-04-18 19:18:41.627 | INFO     | src.open_llm_vtuber.asr.utils:download_and_extract:109 | Extraction completed. | {}
2025-04-18 19:18:41.821 | DEBUG    | src.open_llm_vtuber.asr.utils:download_and_extract:113 | Deleted the compressed file: sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17.tar.bz2 | {}
2025-04-18 19:18:47.043 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 19:18:47.202 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 19:19:23.980 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 19:19:24.213 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 19:19:24.217 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 19:19:24.217 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 19:19:24.217 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:19:24.219 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 19:19:24.219 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 19:19:25.136 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, qwen2.5:latest | {}
2025-04-18 19:19:25.142 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 19:19:29.192 | ERROR    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:44 | Failed to preload model: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002979A5184D0>: Failed to establish a new connection: [WinError 10061] ÎåÄÏÉÅ Ïª¥Ìì®ÌÑ∞ÏóêÏÑú Ïó∞Í≤∞ÏùÑ Í±∞Î∂ÄÌñàÏúºÎØÄÎ°ú Ïó∞Í≤∞ÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§')) | {}
2025-04-18 19:19:29.192 | CRITICAL | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:45 | Fail to connect to Ollama backend. Is Ollama server running? Try running `ollama list` to start the server and try again.
The AI will repeat 'Error connecting chat endpoint' until the server is running. | {}
2025-04-18 19:19:29.192 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 19:19:29.192 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 19:19:29.196 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 19:19:29.196 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:19:29.196 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 19:19:58.101 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:cleanup:61 | Ollama: Unloading model: qwen2.5:latest | {}
2025-04-18 19:28:49.908 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 19:28:49.990 | ERROR    | __main__:run:62 | Error syncing user config: while constructing a mapping
  in "<unicode string>", line 258, column 5
found duplicate key "edge_tts" with value "{}" (original value: "{}")
  in "<unicode string>", line 280, column 5

To suppress this check see:
    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys
 | {}
2025-04-18 19:28:50.020 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: shizuku-local | {}
2025-04-18 19:28:50.020 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 19:28:50.020 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: whisper | {}
2025-04-18 19:28:50.025 | ERROR    | __main__:<module>:91 | An error has been caught in function '<module>', process 'MainProcess' (27328), thread 'MainThread' (20268): | {}
Traceback (most recent call last):

> File "D:\Model Ai girl\Open-LLM-VTuber\run_server.py", line 91, in <module>
    run(console_log_level=console_log_level)
    ‚îÇ                     ‚îî 'INFO'
    ‚îî <function run at 0x0000023136122340>

  File "D:\Model Ai girl\Open-LLM-VTuber\run_server.py", line 71, in run
    server = WebSocketServer(config=config)
             ‚îÇ                      ‚îî Config(system_config=SystemConfig(conf_version='v1.1.1', host='localhost', port=12393, config_alts_dir='characters', tool_pro...
             ‚îî <class 'src.open_llm_vtuber.server.WebSocketServer'>

  File "D:\Model Ai girl\Open-LLM-VTuber\src\open_llm_vtuber\server.py", line 45, in __init__
    default_context_cache.load_from_config(config)
    ‚îÇ                     ‚îÇ                ‚îî Config(system_config=SystemConfig(conf_version='v1.1.1', host='localhost', port=12393, config_alts_dir='characters', tool_pro...
    ‚îÇ                     ‚îî <function ServiceContext.load_from_config at 0x00000231360A5580>
    ‚îî <src.open_llm_vtuber.service_context.ServiceContext object at 0x000002313615C080>

  File "D:\Model Ai girl\Open-LLM-VTuber\src\open_llm_vtuber\service_context.py", line 132, in load_from_config
    self.init_asr(config.character_config.asr_config)
    ‚îÇ    ‚îÇ        ‚îÇ      ‚îÇ                ‚îî ASRConfig(asr_model='whisper', azure_asr=AzureASRConfig(api_key='azure_api_key', region='eastus', languages=['en-US', 'zh-CN'...
    ‚îÇ    ‚îÇ        ‚îÇ      ‚îî CharacterConfig(conf_name='shizuku-local', conf_uid='shizuku-local-001', live2d_model_name='shizuku-local', character_name='S...
    ‚îÇ    ‚îÇ        ‚îî Config(system_config=SystemConfig(conf_version='v1.1.1', host='localhost', port=12393, config_alts_dir='characters', tool_pro...
    ‚îÇ    ‚îî <function ServiceContext.init_asr at 0x00000231360A56C0>
    ‚îî <src.open_llm_vtuber.service_context.ServiceContext object at 0x000002313615C080>

  File "D:\Model Ai girl\Open-LLM-VTuber\src\open_llm_vtuber\service_context.py", line 167, in init_asr
    self.asr_engine = ASRFactory.get_asr_system(
    ‚îÇ    ‚îÇ            ‚îÇ          ‚îî <staticmethod(<function ASRFactory.get_asr_system at 0x0000023134DAF6A0>)>
    ‚îÇ    ‚îÇ            ‚îî <class 'src.open_llm_vtuber.asr.asr_factory.ASRFactory'>
    ‚îÇ    ‚îî None
    ‚îî <src.open_llm_vtuber.service_context.ServiceContext object at 0x000002313615C080>

  File "D:\Model Ai girl\Open-LLM-VTuber\src\open_llm_vtuber\asr\asr_factory.py", line 22, in get_asr_system
    from .openai_whisper_asr import VoiceRecognition as WhisperASR

  File "D:\Model Ai girl\Open-LLM-VTuber\src\open_llm_vtuber\asr\openai_whisper_asr.py", line 2, in <module>
    import whisper

ModuleNotFoundError: No module named 'whisper'
2025-04-18 19:30:31.364 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 19:30:31.446 | ERROR    | __main__:run:62 | Error syncing user config: while constructing a mapping
  in "<unicode string>", line 258, column 5
found duplicate key "edge_tts" with value "{}" (original value: "{}")
  in "<unicode string>", line 280, column 5

To suppress this check see:
    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys
 | {}
2025-04-18 19:30:31.475 | CRITICAL | src.open_llm_vtuber.config_manager.utils:validate_config:71 | Error validating configuration: 1 validation error for Config
character_config.tts_config.tts_model
  Input should be 'azure_tts', 'bark_tts', 'edge_tts', 'cosyvoice_tts', 'cosyvoice2_tts', 'melo_tts', 'coqui_tts', 'x_tts', 'gpt_sovits_tts', 'fish_api_tts' or 'sherpa_onnx_tts' [type=literal_error, input_value='pyttsx3_tts', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/literal_error | {}
2025-04-18 19:30:31.477 | ERROR    | src.open_llm_vtuber.config_manager.utils:validate_config:72 | Configuration data: | {}
2025-04-18 19:30:31.477 | ERROR    | src.open_llm_vtuber.config_manager.utils:validate_config:73 | {'system_config': {'conf_version': 'v1.1.1', 'host': 'localhost', 'port': 12393, 'config_alts_dir': 'characters', 'tool_prompts': {'live2d_expression_prompt': 'live2d_expression_prompt'}, 'group_conversation_prompt': 'group_conversation_prompt'}, 'character_config': {'conf_name': 'shizuku-local', 'conf_uid': 'shizuku-local-001', 'live2d_model_name': 'shizuku-local', 'character_name': 'Shizuku', 'avatar': 'shizuku.png', 'human_name': 'Human', 'persona_prompt': "You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n", 'agent_config': {'conversation_agent_choice': 'basic_memory_agent', 'agent_settings': {'basic_memory_agent': {'llm_provider': 'openai_llm', 'faster_first_response': True, 'segment_method': 'pysbd'}, 'mem0_agent': {'vector_store': {'provider': 'qdrant', 'config': {'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}}, 'llm': {'provider': 'ollama', 'config': {'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}}, 'embedder': {'provider': 'ollama', 'config': {'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'}}}, 'hume_ai_agent': {'api_key': '', 'host': 'api.hume.ai', 'config_id': '', 'idle_timeout': 15}}, 'llm_configs': {'openai_compatible_llm': {'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'somethingelse', 'organization_id': 'org_eternity', 'project_id': 'project_glass', 'model': 'qwen2.5:latest', 'temperature': 1.0, 'interrupt_method': 'user'}, 'claude_llm': {'base_url': 'https://api.anthropic.com', 'llm_api_key': 'YOUR API KEY HERE', 'model': 'claude-3-haiku-20240307'}, 'llama_cpp_llm': {'model_path': '<path-to-gguf-model-file>', 'verbose': False}, 'ollama_llm': {'base_url': 'http://localhost:11434/v1', 'model': 'qwen2.5:latest', 'temperature': 1.0, 'keep_alive': -1, 'unload_at_exit': True}, 'openai_llm': {'llm_api_key': 'sk-0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJK', 'model': 'gpt-3.5-turbo', 'temperature': 1.0}, 'gemini_llm': {'llm_api_key': 'Your Gemini API Key', 'model': 'gemini-2.0-flash-exp', 'temperature': 1.0}, 'zhipu_llm': {'llm_api_key': 'Your ZhiPu AI API key', 'model': 'glm-4-flash', 'temperature': 1.0}, 'deepseek_llm': {'llm_api_key': 'Your DeepSeek API key', 'model': 'deepseek-chat', 'temperature': 0.7}, 'mistral_llm': {'llm_api_key': 'Your Mistral API key', 'model': 'pixtral-large-latest', 'temperature': 1.0}, 'groq_llm': {'llm_api_key': 'your groq API key', 'model': 'llama-3.3-70b-versatile', 'temperature': 1.0}}}, 'asr_config': {'asr_model': 'groq_whisper_asr', 'azure_asr': {'api_key': 'azure_api_key', 'region': 'eastus', 'languages': ['en-US', 'zh-CN']}, 'faster_whisper': {'model_path': 'distil-medium.en', 'download_root': 'models/whisper', 'language': 'en', 'device': 'auto'}, 'whisper_cpp': {'model_name': 'small', 'model_dir': 'models/whisper', 'print_realtime': False, 'print_progress': False, 'language': 'auto'}, 'whisper': {'name': 'medium', 'download_root': 'models/whisper', 'device': 'cpu'}, 'fun_asr': {'model_name': 'iic/SenseVoiceSmall', 'vad_model': 'fsmn-vad', 'punc_model': 'ct-punc', 'device': 'cpu', 'disable_update': True, 'ncpu': 4, 'hub': 'ms', 'use_itn': False, 'language': 'auto'}, 'sherpa_onnx_asr': {'model_type': 'sense_voice', 'sense_voice': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', 'tokens': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', 'num_threads': 4, 'use_itn': True, 'provider': 'cpu'}, 'groq_whisper_asr': {'api_key': 'gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', 'model': 'whisper-large-v3-turbo', 'lang': ''}}, 'tts_config': {'tts_model': 'pyttsx3_tts', 'edge_tts': {'voice': 'en-US-AvaMultilingualNeural'}, 'azure_tts': {'api_key': 'azure-api-key', 'region': 'eastus', 'voice': 'en-US-AshleyNeural', 'pitch': '26', 'rate': '1'}, 'bark_tts': {'voice': 'v2/en_speaker_1'}, 'cosyvoice_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': 'È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', 'sft_dropdown': '‰∏≠ÊñáÂ•≥', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'seed': 0, 'api_name': '/generate_audio'}, 'cosyvoice2_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': '3sÊûÅÈÄüÂ§çÂàª', 'sft_dropdown': '', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'stream': False, 'seed': 0, 'speed': 1.0, 'api_name': '/generate_audio'}, 'melo_tts': {'speaker': 'EN-Default', 'language': 'EN', 'device': 'auto', 'speed': 1.0}, 'x_tts': {'api_url': 'http://127.0.0.1:8020/tts_to_audio', 'speaker_wav': 'female', 'language': 'en'}, 'gpt_sovits_tts': {'api_url': 'http://127.0.0.1:9880/tts', 'text_lang': 'zh', 'ref_audio_path': '', 'prompt_lang': 'zh', 'prompt_text': '', 'text_split_method': 'cut5', 'batch_size': '1', 'media_type': 'wav', 'streaming_mode': 'false'}, 'fish_api_tts': {'api_key': '', 'reference_id': '', 'latency': 'balanced', 'base_url': 'https://api.fish.audio'}, 'coqui_tts': {'model_name': 'tts_models/en/ljspeech/tacotron2-DDC', 'speaker_wav': '', 'language': 'en', 'device': ''}, 'sherpa_onnx_tts': {'vits_model': '/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', 'vits_lexicon': '/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', 'vits_tokens': '/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', 'vits_data_dir': '', 'vits_dict_dir': '/path/to/tts-models/vits-melo-tts-zh_en/dict', 'tts_rule_fsts': '/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', 'max_num_sentences': 2, 'sid': 1, 'provider': 'cpu', 'num_threads': 1, 'speed': 1.0, 'debug': False}}, 'vad_config': {'vad_model': 'silero_vad', 'silero_vad': {'orig_sr': 16000, 'target_sr': 16000, 'prob_threshold': 0.4, 'db_threshold': 60, 'required_hits': 3, 'required_misses': 24, 'smoothing_window': 5}}, 'tts_preprocessor_config': {'remove_special_char': True, 'ignore_brackets': True, 'ignore_parentheses': True, 'ignore_asterisks': True, 'ignore_angle_brackets': True, 'translator_config': {'translate_audio': False, 'translate_provider': 'deeplx', 'deeplx': {'deeplx_target_lang': 'JA', 'deeplx_api_endpoint': 'http://localhost:1188/v2/translate'}, 'tencent': {'secret_id': '', 'secret_key': '', 'region': 'ap-guangzhou', 'source_lang': 'zh', 'target_lang': 'ja'}}}}} | {}
2025-04-18 19:30:31.477 | ERROR    | __main__:<module>:91 | An error has been caught in function '<module>', process 'MainProcess' (20368), thread 'MainThread' (17928): | {}
Traceback (most recent call last):

> File "D:\Model Ai girl\Open-LLM-VTuber\run_server.py", line 91, in <module>
    run(console_log_level=console_log_level)
    ‚îÇ                     ‚îî 'INFO'
    ‚îî <function run at 0x0000027ECD292340>

  File "D:\Model Ai girl\Open-LLM-VTuber\run_server.py", line 67, in run
    config: Config = validate_config(read_yaml("conf.yaml"))
                     ‚îÇ               ‚îî <function read_yaml at 0x0000027EABA67F60>
                     ‚îî <function validate_config at 0x0000027EABA74040>

  File "D:\Model Ai girl\Open-LLM-VTuber\src\open_llm_vtuber\config_manager\utils.py", line 74, in validate_config
    raise e

  File "D:\Model Ai girl\Open-LLM-VTuber\src\open_llm_vtuber\config_manager\utils.py", line 69, in validate_config
    return Config(**config_data)
           ‚îÇ        ‚îî {'system_config': {'conf_version': 'v1.1.1', 'host': 'localhost', 'port': 12393, 'config_alts_dir': 'characters', 'tool_promp...
           ‚îî <class 'src.open_llm_vtuber.config_manager.main.Config'>

  File "D:\Model Ai girl\Open-LLM-VTuber\venv\Lib\site-packages\pydantic\main.py", line 253, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ‚îÇ    ‚îÇ                      ‚îÇ               ‚îÇ                   ‚îî Config()
                     ‚îÇ    ‚îÇ                      ‚îÇ               ‚îî {'system_config': {'conf_version': 'v1.1.1', 'host': 'localhost', 'port': 12393, 'config_alts_dir': 'characters', 'tool_promp...
                     ‚îÇ    ‚îÇ                      ‚îî <method 'validate_python' of 'pydantic_core._pydantic_core.SchemaValidator' objects>
                     ‚îÇ    ‚îî SchemaValidator(title="Config", validator=Model(
                     ‚îÇ          ModelValidator {
                     ‚îÇ              revalidate: Never,
                     ‚îÇ              validator: ModelFiel...
                     ‚îî Config()

pydantic_core._pydantic_core.ValidationError: 1 validation error for Config
character_config.tts_config.tts_model
  Input should be 'azure_tts', 'bark_tts', 'edge_tts', 'cosyvoice_tts', 'cosyvoice2_tts', 'melo_tts', 'coqui_tts', 'x_tts', 'gpt_sovits_tts', 'fish_api_tts' or 'sherpa_onnx_tts' [type=literal_error, input_value='pyttsx3_tts', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/literal_error
2025-04-18 19:31:23.128 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 19:31:23.188 | ERROR    | __main__:run:62 | Error syncing user config: while constructing a mapping
  in "<unicode string>", line 258, column 5
found duplicate key "edge_tts" with value "{}" (original value: "{}")
  in "<unicode string>", line 280, column 5

To suppress this check see:
    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys
 | {}
2025-04-18 19:31:23.225 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: shizuku-local | {}
2025-04-18 19:31:23.225 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 19:31:23.228 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 19:31:23.997 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 19:31:48.328 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 19:31:58.104 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 19:31:58.202 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 19:31:58.202 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 19:31:58.202 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 19:31:58.205 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:31:58.205 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 19:31:58.205 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: openai_llm | {}
2025-04-18 19:31:58.559 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: https://api.openai.com/v1, gpt-3.5-turbo | {}
2025-04-18 19:31:58.559 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 19:31:58.559 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 19:31:58.559 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 19:31:58.559 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:31:58.559 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 19:34:48.554 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 19:34:48.567 | ERROR    | __main__:run:62 | Error syncing user config: while constructing a mapping
  in "<unicode string>", line 258, column 5
found duplicate key "edge_tts" with value "{}" (original value: "{}")
  in "<unicode string>", line 280, column 5

To suppress this check see:
    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys
 | {}
2025-04-18 19:34:48.603 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: shizuku-local | {}
2025-04-18 19:34:48.603 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 19:34:48.603 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 19:34:49.103 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 19:34:49.276 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 19:34:52.470 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 19:34:52.605 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 19:34:52.605 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 19:34:52.605 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 19:34:52.605 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:34:52.605 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 19:34:52.605 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: openai_llm | {}
2025-04-18 19:34:52.999 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: https://api.openai.com/v1, gpt-3.5-turbo | {}
2025-04-18 19:34:52.999 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 19:34:52.999 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 19:34:52.999 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 19:34:52.999 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:34:52.999 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 19:38:15.755 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 19:38:15.766 | ERROR    | __main__:run:62 | Error syncing user config: while constructing a mapping
  in "<unicode string>", line 258, column 5
found duplicate key "edge_tts" with value "{}" (original value: "{}")
  in "<unicode string>", line 280, column 5

To suppress this check see:
    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys
 | {}
2025-04-18 19:38:15.805 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: shizuku-local | {}
2025-04-18 19:38:15.807 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 19:38:15.807 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 19:38:15.846 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 19:38:15.993 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 19:38:18.509 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 19:38:18.609 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 19:38:18.609 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 19:38:18.609 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 19:38:18.609 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:38:18.609 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 19:38:18.609 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: openai_llm | {}
2025-04-18 19:38:18.961 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: https://api.openai.com/v1, gpt-3.5-turbo | {}
2025-04-18 19:38:18.961 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 19:38:18.961 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 19:38:18.961 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 19:38:18.961 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:38:18.961 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 19:38:20.283 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='shizuku-local' character_name='Shizuku' human_name='Human' avatar='shizuku.png' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='openai_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='qwen2.5:latest', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='sk-0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJK', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='en-US-AvaMultilingualNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 19:38:20.287 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client bc949443-e6b3-4b47-8f11-60ebcd02f2bd | {}
2025-04-18 19:38:20.426 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 19:38:20.436 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_19-38-20_ea46dc115980465ab3410ae0505b7308.json | {}
2025-04-18 19:38:47.732 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_19-38-47_8cb19d1f78be4ef5ac5bc6993c1c9ca0.json | {}
2025-04-18 19:39:00.097 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain ‚õÑÔ∏è started! | {}
2025-04-18 19:39:00.098 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing human message to chat_history\shizuku-local-001\2025-04-18_19-38-47_8cb19d1f78be4ef5ac5bc6993c1c9ca0.json | {}
2025-04-18 19:39:00.100 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored human message | {}
2025-04-18 19:39:00.101 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:72 | User input: ÏïàÎÖï | {}
2025-04-18 19:39:00.101 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:73 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}] | {}
2025-04-18 19:39:00.571 | ERROR    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:110 | LLM API: Error occurred: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-01234**************************************HIJK. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}} | {}
2025-04-18 19:39:00.572 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:111 | Base URL: https://api.openai.com/v1 | {}
2025-04-18 19:39:00.573 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:112 | Model: gpt-3.5-turbo | {}
2025-04-18 19:39:00.575 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:113 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}] | {}
2025-04-18 19:39:00.576 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:114 | temperature: 1.0 | {}
2025-04-18 19:39:01.528 | DEBUG    | src.open_llm_vtuber.utils.sentence_divider:segment_text_by_pysbd:258 | Processed sentences: ['Error calling the chat endpoint: Error occurred while generating response.', 'See the logs for details.'], Remaining:  | {}
2025-04-18 19:39:01.529 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:39:01.529 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:39:01.529 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:39:01.530 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Error calling the chat endpoint: Error occurred while generating response.'''... | {}
2025-04-18 19:39:01.530 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:39:01.531 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Error calling the chat endpoint: Error occurred while generating response.''' (by Shizuku) | {}
2025-04-18 19:39:01.531 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Error calling the chat endpoint: Error occurred while generating response.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:39:01.531 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: See the logs for details. | {}
2025-04-18 19:39:01.531 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: See the logs for details. | {}
2025-04-18 19:39:01.531 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: See the logs for details. | {}
2025-04-18 19:39:01.532 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''See the logs for details.'''... | {}
2025-04-18 19:39:01.532 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:39:01.532 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''See the logs for details.''' (by Shizuku) | {}
2025-04-18 19:39:01.532 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='See the logs for details.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:39:01.533 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Error calling the chat endpoint: Error occurred while generating response.'''... | {}
2025-04-18 19:39:01.533 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''See the logs for details.'''... | {}
2025-04-18 19:39:02.885 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_193901_96f88249.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:39:02.887 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_193901_96f88249.mp3 | {}
2025-04-18 19:39:02.888 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:39:02.907 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_193901_b7734da5.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:39:02.909 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_193901_b7734da5.mp3 | {}
2025-04-18 19:39:02.910 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:39:03.057 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:send_conversation_end_signal:210 | üòéüëç‚úÖ Conversation Chain üòä completed! | {}
2025-04-18 19:39:03.058 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing ai message to chat_history\shizuku-local-001\2025-04-18_19-38-47_8cb19d1f78be4ef5ac5bc6993c1c9ca0.json | {}
2025-04-18 19:39:03.059 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored ai message | {}
2025-04-18 19:39:03.060 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:104 | AI response: Error calling the chat endpoint: Error occurred while generating response.See the logs for details. | {}
2025-04-18 19:39:03.060 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation ‚õÑÔ∏è. | {}
2025-04-18 19:39:08.755 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain üéâ started! | {}
2025-04-18 19:39:08.756 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:process_user_input:151 | Transcribing audio input... | {}
2025-04-18 19:39:09.650 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:108 | Speech Recognition canceled: CancellationReason.Error | {}
2025-04-18 19:39:09.652 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:112 | Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. SessionId: e3198f379f4a491694bcecaa75270a87 | {}
2025-04-18 19:39:09.652 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:118 | Transcription failed: Speech Recognition failed: CancellationReason.Error | {}
2025-04-18 19:39:09.653 | DEBUG    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:125 | Failed to remove temporary file cache\6eb322e3-1320-437c-a5b4-f2f891670112.wav: [WinError 32] Îã§Î•∏ ÌîÑÎ°úÏÑ∏Ïä§Í∞Ä ÌååÏùºÏùÑ ÏÇ¨Ïö© Ï§ëÏù¥Í∏∞ ÎïåÎ¨∏Ïóê ÌîÑÎ°úÏÑ∏Ïä§Í∞Ä Ïï°ÏÑ∏Ïä§ Ìï† Ïàò ÏóÜÏäµÎãàÎã§: 'cache\\6eb322e3-1320-437c-a5b4-f2f891670112.wav' | {}
2025-04-18 19:39:09.654 | ERROR    | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:112 | Error in conversation chain: Speech Recognition failed: CancellationReason.Error | {}
2025-04-18 19:39:09.656 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation üéâ. | {}
2025-04-18 19:39:13.669 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing ai message to chat_history\shizuku-local-001\2025-04-18_19-38-47_8cb19d1f78be4ef5ac5bc6993c1c9ca0.json | {}
2025-04-18 19:39:13.670 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored ai message | {}
2025-04-18 19:39:13.671 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing system message to chat_history\shizuku-local-001\2025-04-18_19-38-47_8cb19d1f78be4ef5ac5bc6993c1c9ca0.json | {}
2025-04-18 19:39:13.672 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored system message | {}
2025-04-18 19:39:13.706 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain üéÉ started! | {}
2025-04-18 19:39:13.706 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing human message to chat_history\shizuku-local-001\2025-04-18_19-38-47_8cb19d1f78be4ef5ac5bc6993c1c9ca0.json | {}
2025-04-18 19:39:13.707 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored human message | {}
2025-04-18 19:39:13.707 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:72 | User input: ÏïàÎÖï! | {}
2025-04-18 19:39:13.708 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:73 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}, {'role': 'assistant', 'content': '...'}, {'role': 'system', 'content': '[Interrupted by user]'}, {'role': 'user', 'content': 'ÏïàÎÖï!'}] | {}
2025-04-18 19:39:13.962 | ERROR    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:110 | LLM API: Error occurred: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-01234**************************************HIJK. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}} | {}
2025-04-18 19:39:13.963 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:111 | Base URL: https://api.openai.com/v1 | {}
2025-04-18 19:39:13.964 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:112 | Model: gpt-3.5-turbo | {}
2025-04-18 19:39:13.965 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:113 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}, {'role': 'assistant', 'content': '...'}, {'role': 'system', 'content': '[Interrupted by user]'}, {'role': 'user', 'content': 'ÏïàÎÖï!'}] | {}
2025-04-18 19:39:13.966 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:114 | temperature: 1.0 | {}
2025-04-18 19:39:13.976 | DEBUG    | src.open_llm_vtuber.utils.sentence_divider:segment_text_by_pysbd:258 | Processed sentences: ['Error calling the chat endpoint: Error occurred while generating response.', 'See the logs for details.'], Remaining:  | {}
2025-04-18 19:39:13.977 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:39:13.978 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:39:13.978 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:39:13.978 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Error calling the chat endpoint: Error occurred while generating response.'''... | {}
2025-04-18 19:39:13.978 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:39:13.978 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Error calling the chat endpoint: Error occurred while generating response.''' (by Shizuku) | {}
2025-04-18 19:39:13.978 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Error calling the chat endpoint: Error occurred while generating response.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:39:13.978 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: See the logs for details. | {}
2025-04-18 19:39:13.979 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: See the logs for details. | {}
2025-04-18 19:39:13.979 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: See the logs for details. | {}
2025-04-18 19:39:13.979 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''See the logs for details.'''... | {}
2025-04-18 19:39:13.979 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:39:13.979 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''See the logs for details.''' (by Shizuku) | {}
2025-04-18 19:39:13.979 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='See the logs for details.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:39:13.979 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Error calling the chat endpoint: Error occurred while generating response.'''... | {}
2025-04-18 19:39:13.980 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''See the logs for details.'''... | {}
2025-04-18 19:39:15.246 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_193913_454931b0.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:39:15.248 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_193913_454931b0.mp3 | {}
2025-04-18 19:39:15.249 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:39:15.265 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_193913_d5baaa98.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:39:15.266 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_193913_d5baaa98.mp3 | {}
2025-04-18 19:39:15.267 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:39:15.409 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:send_conversation_end_signal:210 | üòéüëç‚úÖ Conversation Chain üòä completed! | {}
2025-04-18 19:39:15.410 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing ai message to chat_history\shizuku-local-001\2025-04-18_19-38-47_8cb19d1f78be4ef5ac5bc6993c1c9ca0.json | {}
2025-04-18 19:39:15.412 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored ai message | {}
2025-04-18 19:39:15.413 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:104 | AI response: Error calling the chat endpoint: Error occurred while generating response.See the logs for details. | {}
2025-04-18 19:39:15.414 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation üéÉ. | {}
2025-04-18 19:40:34.432 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 19:40:34.439 | ERROR    | __main__:run:62 | Error syncing user config: while constructing a mapping
  in "<unicode string>", line 258, column 5
found duplicate key "edge_tts" with value "{}" (original value: "{}")
  in "<unicode string>", line 280, column 5

To suppress this check see:
    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys
 | {}
2025-04-18 19:40:34.472 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: shizuku-local | {}
2025-04-18 19:40:34.473 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 19:40:34.474 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 19:40:34.515 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 19:40:34.661 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 19:40:37.745 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 19:40:37.874 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 19:40:37.875 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 19:40:37.875 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 19:40:37.875 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:40:37.875 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 19:40:37.876 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: openai_llm | {}
2025-04-18 19:40:38.530 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: https://api.openai.com/v1, gpt-3.5-turbo | {}
2025-04-18 19:40:38.532 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 19:40:38.533 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 19:40:38.533 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 19:40:38.533 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:40:38.534 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 19:44:57.738 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 19:44:57.764 | ERROR    | __main__:run:62 | Error syncing user config: while constructing a mapping
  in "<unicode string>", line 258, column 5
found duplicate key "edge_tts" with value "{}" (original value: "{}")
  in "<unicode string>", line 280, column 5

To suppress this check see:
    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys
 | {}
2025-04-18 19:44:57.851 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: shizuku-local | {}
2025-04-18 19:44:57.851 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 19:44:57.851 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 19:44:57.934 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 19:44:58.192 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 19:45:02.937 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 19:45:03.155 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 19:45:03.155 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 19:45:03.155 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 19:45:03.155 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:45:03.155 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 19:45:03.155 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: openai_llm | {}
2025-04-18 19:45:03.880 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: https://api.openai.com/v1, gpt-3.5-turbo | {}
2025-04-18 19:45:03.889 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 19:45:03.889 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 19:45:03.889 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 19:45:03.889 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:45:03.889 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 19:45:13.325 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='shizuku-local' character_name='Shizuku' human_name='Human' avatar='shizuku.png' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='openai_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='qwen2.5:latest', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='sk-0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJK', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='en-US-AvaMultilingualNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 19:45:13.341 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 4bfc0033-91c3-4fa6-8f90-88932b592dd7 | {}
2025-04-18 19:45:13.533 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 19:45:13.551 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_19-38-20_ea46dc115980465ab3410ae0505b7308 | {}
2025-04-18 19:45:13.555 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_19-45-13_bbb679c340934070a0fd8f950e79ead0.json | {}
2025-04-18 19:45:18.293 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain üé≠ started! | {}
2025-04-18 19:45:18.295 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing human message to chat_history\shizuku-local-001\2025-04-18_19-45-13_bbb679c340934070a0fd8f950e79ead0.json | {}
2025-04-18 19:45:18.298 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored human message | {}
2025-04-18 19:45:18.298 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:72 | User input: ÏïàÎÖï | {}
2025-04-18 19:45:18.299 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:73 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}] | {}
2025-04-18 19:45:18.763 | ERROR    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:110 | LLM API: Error occurred: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-01234**************************************HIJK. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}} | {}
2025-04-18 19:45:18.770 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:111 | Base URL: https://api.openai.com/v1 | {}
2025-04-18 19:45:18.774 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:112 | Model: gpt-3.5-turbo | {}
2025-04-18 19:45:18.778 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:113 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}] | {}
2025-04-18 19:45:18.782 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:114 | temperature: 1.0 | {}
2025-04-18 19:45:19.929 | DEBUG    | src.open_llm_vtuber.utils.sentence_divider:segment_text_by_pysbd:258 | Processed sentences: ['Error calling the chat endpoint: Error occurred while generating response.', 'See the logs for details.'], Remaining:  | {}
2025-04-18 19:45:19.930 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:45:19.930 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:45:19.931 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:45:19.932 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Error calling the chat endpoint: Error occurred while generating response.'''... | {}
2025-04-18 19:45:19.932 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:45:19.933 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Error calling the chat endpoint: Error occurred while generating response.''' (by Shizuku) | {}
2025-04-18 19:45:19.933 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Error calling the chat endpoint: Error occurred while generating response.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:45:19.934 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: See the logs for details. | {}
2025-04-18 19:45:19.934 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: See the logs for details. | {}
2025-04-18 19:45:19.934 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: See the logs for details. | {}
2025-04-18 19:45:19.934 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''See the logs for details.'''... | {}
2025-04-18 19:45:19.934 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:45:19.935 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''See the logs for details.''' (by Shizuku) | {}
2025-04-18 19:45:19.935 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='See the logs for details.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:45:19.935 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Error calling the chat endpoint: Error occurred while generating response.'''... | {}
2025-04-18 19:45:19.936 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''See the logs for details.'''... | {}
2025-04-18 19:45:21.861 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_194519_c3529403.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:45:21.866 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_194519_c3529403.mp3 | {}
2025-04-18 19:45:21.868 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:45:21.890 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_194519_79719e8e.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:45:21.893 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_194519_79719e8e.mp3 | {}
2025-04-18 19:45:21.894 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:45:22.098 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:send_conversation_end_signal:210 | üòéüëç‚úÖ Conversation Chain üòä completed! | {}
2025-04-18 19:45:22.099 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing ai message to chat_history\shizuku-local-001\2025-04-18_19-45-13_bbb679c340934070a0fd8f950e79ead0.json | {}
2025-04-18 19:45:22.103 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored ai message | {}
2025-04-18 19:45:22.104 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:104 | AI response: Error calling the chat endpoint: Error occurred while generating response.See the logs for details. | {}
2025-04-18 19:45:22.105 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation üé≠. | {}
2025-04-18 19:45:30.908 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain üê≠ started! | {}
2025-04-18 19:45:30.909 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing human message to chat_history\shizuku-local-001\2025-04-18_19-45-13_bbb679c340934070a0fd8f950e79ead0.json | {}
2025-04-18 19:45:30.911 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored human message | {}
2025-04-18 19:45:30.913 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:72 | User input: ÏïàÎÖï | {}
2025-04-18 19:45:30.914 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:73 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}, {'role': 'assistant', 'content': 'Error calling the chat endpoint: Error occurred while generating response. See the logs for details.'}, {'role': 'user', 'content': 'ÏïàÎÖï'}] | {}
2025-04-18 19:45:31.176 | ERROR    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:110 | LLM API: Error occurred: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-01234**************************************HIJK. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}} | {}
2025-04-18 19:45:31.177 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:111 | Base URL: https://api.openai.com/v1 | {}
2025-04-18 19:45:31.178 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:112 | Model: gpt-3.5-turbo | {}
2025-04-18 19:45:31.180 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:113 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}, {'role': 'assistant', 'content': 'Error calling the chat endpoint: Error occurred while generating response. See the logs for details.'}, {'role': 'user', 'content': 'ÏïàÎÖï'}] | {}
2025-04-18 19:45:31.181 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:114 | temperature: 1.0 | {}
2025-04-18 19:45:31.193 | DEBUG    | src.open_llm_vtuber.utils.sentence_divider:segment_text_by_pysbd:258 | Processed sentences: ['Error calling the chat endpoint: Error occurred while generating response.', 'See the logs for details.'], Remaining:  | {}
2025-04-18 19:45:31.193 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:45:31.194 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:45:31.194 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:45:31.194 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Error calling the chat endpoint: Error occurred while generating response.'''... | {}
2025-04-18 19:45:31.195 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:45:31.195 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Error calling the chat endpoint: Error occurred while generating response.''' (by Shizuku) | {}
2025-04-18 19:45:31.196 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Error calling the chat endpoint: Error occurred while generating response.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:45:31.197 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: See the logs for details. | {}
2025-04-18 19:45:31.197 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: See the logs for details. | {}
2025-04-18 19:45:31.197 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: See the logs for details. | {}
2025-04-18 19:45:31.197 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''See the logs for details.'''... | {}
2025-04-18 19:45:31.197 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:45:31.197 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''See the logs for details.''' (by Shizuku) | {}
2025-04-18 19:45:31.197 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='See the logs for details.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:45:31.198 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Error calling the chat endpoint: Error occurred while generating response.'''... | {}
2025-04-18 19:45:31.198 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''See the logs for details.'''... | {}
2025-04-18 19:45:32.993 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_194531_453d340e.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:45:32.994 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_194531_453d340e.mp3 | {}
2025-04-18 19:45:32.995 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:45:33.016 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_194531_861c40cc.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:45:33.018 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_194531_861c40cc.mp3 | {}
2025-04-18 19:45:33.019 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:45:33.199 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:send_conversation_end_signal:210 | üòéüëç‚úÖ Conversation Chain üòä completed! | {}
2025-04-18 19:45:33.201 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing ai message to chat_history\shizuku-local-001\2025-04-18_19-45-13_bbb679c340934070a0fd8f950e79ead0.json | {}
2025-04-18 19:45:33.205 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored ai message | {}
2025-04-18 19:45:33.205 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:104 | AI response: Error calling the chat endpoint: Error occurred while generating response.See the logs for details. | {}
2025-04-18 19:45:33.205 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation üê≠. | {}
2025-04-18 19:45:57.017 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain ‚òòÔ∏è started! | {}
2025-04-18 19:45:57.018 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing human message to chat_history\shizuku-local-001\2025-04-18_19-45-13_bbb679c340934070a0fd8f950e79ead0.json | {}
2025-04-18 19:45:57.021 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored human message | {}
2025-04-18 19:45:57.021 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:72 | User input: ÏïàÎÖï | {}
2025-04-18 19:45:57.022 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:73 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}, {'role': 'assistant', 'content': 'Error calling the chat endpoint: Error occurred while generating response. See the logs for details.'}, {'role': 'user', 'content': 'ÏïàÎÖï'}, {'role': 'assistant', 'content': 'Error calling the chat endpoint: Error occurred while generating response. See the logs for details.'}, {'role': 'user', 'content': 'ÏïàÎÖï'}] | {}
2025-04-18 19:45:57.264 | ERROR    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:110 | LLM API: Error occurred: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-01234**************************************HIJK. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}} | {}
2025-04-18 19:45:57.265 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:111 | Base URL: https://api.openai.com/v1 | {}
2025-04-18 19:45:57.265 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:112 | Model: gpt-3.5-turbo | {}
2025-04-18 19:45:57.267 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:113 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}, {'role': 'assistant', 'content': 'Error calling the chat endpoint: Error occurred while generating response. See the logs for details.'}, {'role': 'user', 'content': 'ÏïàÎÖï'}, {'role': 'assistant', 'content': 'Error calling the chat endpoint: Error occurred while generating response. See the logs for details.'}, {'role': 'user', 'content': 'ÏïàÎÖï'}] | {}
2025-04-18 19:45:57.268 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:114 | temperature: 1.0 | {}
2025-04-18 19:45:57.280 | DEBUG    | src.open_llm_vtuber.utils.sentence_divider:segment_text_by_pysbd:258 | Processed sentences: ['Error calling the chat endpoint: Error occurred while generating response.', 'See the logs for details.'], Remaining:  | {}
2025-04-18 19:45:57.281 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:45:57.281 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:45:57.281 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:45:57.281 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Error calling the chat endpoint: Error occurred while generating response.'''... | {}
2025-04-18 19:45:57.281 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:45:57.281 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Error calling the chat endpoint: Error occurred while generating response.''' (by Shizuku) | {}
2025-04-18 19:45:57.281 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Error calling the chat endpoint: Error occurred while generating response.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:45:57.281 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: See the logs for details. | {}
2025-04-18 19:45:57.281 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: See the logs for details. | {}
2025-04-18 19:45:57.282 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: See the logs for details. | {}
2025-04-18 19:45:57.282 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''See the logs for details.'''... | {}
2025-04-18 19:45:57.282 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:45:57.282 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''See the logs for details.''' (by Shizuku) | {}
2025-04-18 19:45:57.282 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='See the logs for details.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:45:57.282 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Error calling the chat endpoint: Error occurred while generating response.'''... | {}
2025-04-18 19:45:57.283 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''See the logs for details.'''... | {}
2025-04-18 19:45:58.840 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_194557_b41f1ebc.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:45:58.842 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_194557_b41f1ebc.mp3 | {}
2025-04-18 19:45:58.843 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:45:58.864 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_194557_1c2d7808.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:45:58.899 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_194557_1c2d7808.mp3 | {}
2025-04-18 19:45:58.900 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:45:59.110 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:send_conversation_end_signal:210 | üòéüëç‚úÖ Conversation Chain üòä completed! | {}
2025-04-18 19:45:59.112 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing ai message to chat_history\shizuku-local-001\2025-04-18_19-45-13_bbb679c340934070a0fd8f950e79ead0.json | {}
2025-04-18 19:45:59.115 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored ai message | {}
2025-04-18 19:45:59.116 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:104 | AI response: Error calling the chat endpoint: Error occurred while generating response.See the logs for details. | {}
2025-04-18 19:45:59.116 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation ‚òòÔ∏è. | {}
2025-04-18 19:46:02.486 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain üêº started! | {}
2025-04-18 19:46:02.489 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing human message to chat_history\shizuku-local-001\2025-04-18_19-45-13_bbb679c340934070a0fd8f950e79ead0.json | {}
2025-04-18 19:46:02.492 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored human message | {}
2025-04-18 19:46:02.492 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:72 | User input: ÏïÑ | {}
2025-04-18 19:46:02.494 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:73 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}, {'role': 'assistant', 'content': 'Error calling the chat endpoint: Error occurred while generating response. See the logs for details.'}, {'role': 'user', 'content': 'ÏïàÎÖï'}, {'role': 'assistant', 'content': 'Error calling the chat endpoint: Error occurred while generating response. See the logs for details.'}, {'role': 'user', 'content': 'ÏïàÎÖï'}, {'role': 'assistant', 'content': 'Error calling the chat endpoint: Error occurred while generating response. See the logs for details.'}, {'role': 'user', 'content': 'ÏïÑ'}] | {}
2025-04-18 19:46:02.755 | ERROR    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:110 | LLM API: Error occurred: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-01234**************************************HIJK. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}} | {}
2025-04-18 19:46:02.757 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:111 | Base URL: https://api.openai.com/v1 | {}
2025-04-18 19:46:02.759 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:112 | Model: gpt-3.5-turbo | {}
2025-04-18 19:46:02.762 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:113 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}, {'role': 'assistant', 'content': 'Error calling the chat endpoint: Error occurred while generating response. See the logs for details.'}, {'role': 'user', 'content': 'ÏïàÎÖï'}, {'role': 'assistant', 'content': 'Error calling the chat endpoint: Error occurred while generating response. See the logs for details.'}, {'role': 'user', 'content': 'ÏïàÎÖï'}, {'role': 'assistant', 'content': 'Error calling the chat endpoint: Error occurred while generating response. See the logs for details.'}, {'role': 'user', 'content': 'ÏïÑ'}] | {}
2025-04-18 19:46:02.763 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:114 | temperature: 1.0 | {}
2025-04-18 19:46:02.780 | DEBUG    | src.open_llm_vtuber.utils.sentence_divider:segment_text_by_pysbd:258 | Processed sentences: ['Error calling the chat endpoint: Error occurred while generating response.', 'See the logs for details.'], Remaining:  | {}
2025-04-18 19:46:02.780 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:46:02.780 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:46:02.780 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 19:46:02.781 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Error calling the chat endpoint: Error occurred while generating response.'''... | {}
2025-04-18 19:46:02.781 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:46:02.781 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Error calling the chat endpoint: Error occurred while generating response.''' (by Shizuku) | {}
2025-04-18 19:46:02.783 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Error calling the chat endpoint: Error occurred while generating response.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:46:02.783 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: See the logs for details. | {}
2025-04-18 19:46:02.783 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: See the logs for details. | {}
2025-04-18 19:46:02.783 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: See the logs for details. | {}
2025-04-18 19:46:02.783 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''See the logs for details.'''... | {}
2025-04-18 19:46:02.783 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:46:02.783 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''See the logs for details.''' (by Shizuku) | {}
2025-04-18 19:46:02.784 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='See the logs for details.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:46:02.784 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Error calling the chat endpoint: Error occurred while generating response.'''... | {}
2025-04-18 19:46:02.784 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''See the logs for details.'''... | {}
2025-04-18 19:46:03.851 | INFO     | src.open_llm_vtuber.conversations.conversation_handler:handle_individual_interrupt:97 | üõë Conversation task was successfully interrupted | {}
2025-04-18 19:46:03.852 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing ai message to chat_history\shizuku-local-001\2025-04-18_19-45-13_bbb679c340934070a0fd8f950e79ead0.json | {}
2025-04-18 19:46:03.855 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored ai message | {}
2025-04-18 19:46:03.857 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing system message to chat_history\shizuku-local-001\2025-04-18_19-45-13_bbb679c340934070a0fd8f950e79ead0.json | {}
2025-04-18 19:46:03.859 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored system message | {}
2025-04-18 19:46:03.859 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:109 | ü§°üëç Conversation üêº cancelled because interrupted. | {}
2025-04-18 19:46:03.860 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation üêº. | {}
2025-04-18 19:46:07.518 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain üêª started! | {}
2025-04-18 19:46:07.542 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:process_user_input:151 | Transcribing audio input... | {}
2025-04-18 19:46:08.458 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:108 | Speech Recognition canceled: CancellationReason.Error | {}
2025-04-18 19:46:08.460 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:112 | Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. SessionId: 9e6835fd8bb242c2882f30a18514d406 | {}
2025-04-18 19:46:08.462 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:118 | Transcription failed: Speech Recognition failed: CancellationReason.Error | {}
2025-04-18 19:46:08.463 | DEBUG    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:125 | Failed to remove temporary file cache\3c003c7d-f4bf-4b36-8f25-392c8d2bd745.wav: [WinError 32] Îã§Î•∏ ÌîÑÎ°úÏÑ∏Ïä§Í∞Ä ÌååÏùºÏùÑ ÏÇ¨Ïö© Ï§ëÏù¥Í∏∞ ÎïåÎ¨∏Ïóê ÌîÑÎ°úÏÑ∏Ïä§Í∞Ä Ïï°ÏÑ∏Ïä§ Ìï† Ïàò ÏóÜÏäµÎãàÎã§: 'cache\\3c003c7d-f4bf-4b36-8f25-392c8d2bd745.wav' | {}
2025-04-18 19:46:08.463 | ERROR    | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:112 | Error in conversation chain: Speech Recognition failed: CancellationReason.Error | {}
2025-04-18 19:46:08.465 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation üêª. | {}
2025-04-18 19:47:50.271 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 19:47:50.287 | ERROR    | __main__:run:62 | Error syncing user config: while constructing a mapping
  in "<unicode string>", line 258, column 5
found duplicate key "edge_tts" with value "{}" (original value: "{}")
  in "<unicode string>", line 280, column 5

To suppress this check see:
    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys
 | {}
2025-04-18 19:47:50.362 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: shizuku-local | {}
2025-04-18 19:47:50.362 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 19:47:50.362 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 19:47:50.437 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 19:47:50.702 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 19:47:55.858 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 19:47:56.039 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 19:47:56.039 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 19:47:56.046 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 19:47:56.046 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:47:56.048 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 19:47:56.049 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: openai_llm | {}
2025-04-18 19:47:57.173 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: https://api.openai.com/v1, gpt-3.5-turbo | {}
2025-04-18 19:47:57.181 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 19:47:57.181 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 19:47:57.181 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 19:47:57.181 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:47:57.181 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 19:47:58.919 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='shizuku-local' character_name='Shizuku' human_name='Human' avatar='shizuku.png' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='openai_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='qwen2.5:latest', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='en-US-AvaMultilingualNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 19:47:58.933 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client b1295e5c-24b6-471f-be49-6380b26e6f16 | {}
2025-04-18 19:47:59.118 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 19:47:59.146 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_19-47-59_b8f3e87368a345ef802fe81efe9970e1.json | {}
2025-04-18 19:48:02.983 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain üíê started! | {}
2025-04-18 19:48:02.986 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing human message to chat_history\shizuku-local-001\2025-04-18_19-47-59_b8f3e87368a345ef802fe81efe9970e1.json | {}
2025-04-18 19:48:02.989 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored human message | {}
2025-04-18 19:48:02.989 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:72 | User input: ÏïàÎÖï! | {}
2025-04-18 19:48:02.990 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:73 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï!'}] | {}
2025-04-18 19:48:06.813 | ERROR    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:104 | Error calling the chat endpoint: Rate limit exceeded: <Response [429 Too Many Requests]> | {}
2025-04-18 19:48:07.921 | DEBUG    | src.open_llm_vtuber.utils.sentence_divider:segment_text_by_pysbd:258 | Processed sentences: ['Error calling the chat endpoint: Rate limit exceeded.', 'Please try again later.', 'See the logs for details.'], Remaining:  | {}
2025-04-18 19:48:07.924 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Error calling the chat endpoint: Rate limit exceeded. | {}
2025-04-18 19:48:07.924 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Error calling the chat endpoint: Rate limit exceeded. | {}
2025-04-18 19:48:07.925 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Error calling the chat endpoint: Rate limit exceeded. | {}
2025-04-18 19:48:07.927 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Error calling the chat endpoint: Rate limit exceeded.'''... | {}
2025-04-18 19:48:07.928 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:48:07.929 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Error calling the chat endpoint: Rate limit exceeded.''' (by Shizuku) | {}
2025-04-18 19:48:07.930 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Error calling the chat endpoint: Rate limit exceeded.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:48:07.930 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Please try again later. | {}
2025-04-18 19:48:07.931 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Please try again later. | {}
2025-04-18 19:48:07.931 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Please try again later. | {}
2025-04-18 19:48:07.931 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Please try again later.'''... | {}
2025-04-18 19:48:07.931 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:48:07.931 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Please try again later.''' (by Shizuku) | {}
2025-04-18 19:48:07.931 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Please try again later.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:48:07.931 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: See the logs for details. | {}
2025-04-18 19:48:07.932 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: See the logs for details. | {}
2025-04-18 19:48:07.932 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: See the logs for details. | {}
2025-04-18 19:48:07.932 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''See the logs for details.'''... | {}
2025-04-18 19:48:07.932 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:48:07.932 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''See the logs for details.''' (by Shizuku) | {}
2025-04-18 19:48:07.932 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='See the logs for details.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:48:07.933 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Error calling the chat endpoint: Rate limit exceeded.'''... | {}
2025-04-18 19:48:07.933 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Please try again later.'''... | {}
2025-04-18 19:48:07.936 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''See the logs for details.'''... | {}
2025-04-18 19:48:10.061 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_194807_b1be3633.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:48:10.062 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_194807_b1be3633.mp3 | {}
2025-04-18 19:48:10.064 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:48:10.488 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_194807_ae1e6cf3.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:48:10.498 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_194807_ae1e6cf3.mp3 | {}
2025-04-18 19:48:10.499 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:48:10.789 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_194807_22312368.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:48:10.791 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_194807_22312368.mp3 | {}
2025-04-18 19:48:10.792 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:48:11.030 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:send_conversation_end_signal:210 | üòéüëç‚úÖ Conversation Chain üòä completed! | {}
2025-04-18 19:48:11.030 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing ai message to chat_history\shizuku-local-001\2025-04-18_19-47-59_b8f3e87368a345ef802fe81efe9970e1.json | {}
2025-04-18 19:48:11.033 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored ai message | {}
2025-04-18 19:48:11.033 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:104 | AI response: Error calling the chat endpoint: Rate limit exceeded.Please try again later.See the logs for details. | {}
2025-04-18 19:48:11.034 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation üíê. | {}
2025-04-18 19:48:15.497 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain üåç started! | {}
2025-04-18 19:48:15.499 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing human message to chat_history\shizuku-local-001\2025-04-18_19-47-59_b8f3e87368a345ef802fe81efe9970e1.json | {}
2025-04-18 19:48:15.501 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored human message | {}
2025-04-18 19:48:15.501 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:72 | User input: ÏïàÎÖï! | {}
2025-04-18 19:48:15.501 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:73 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï!'}, {'role': 'assistant', 'content': 'Error calling the chat endpoint: Rate limit exceeded. Please try again later. See the logs for details.'}, {'role': 'user', 'content': 'ÏïàÎÖï!'}] | {}
2025-04-18 19:48:18.319 | ERROR    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:104 | Error calling the chat endpoint: Rate limit exceeded: <Response [429 Too Many Requests]> | {}
2025-04-18 19:48:18.339 | DEBUG    | src.open_llm_vtuber.utils.sentence_divider:segment_text_by_pysbd:258 | Processed sentences: ['Error calling the chat endpoint: Rate limit exceeded.', 'Please try again later.', 'See the logs for details.'], Remaining:  | {}
2025-04-18 19:48:18.339 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Error calling the chat endpoint: Rate limit exceeded. | {}
2025-04-18 19:48:18.341 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Error calling the chat endpoint: Rate limit exceeded. | {}
2025-04-18 19:48:18.341 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Error calling the chat endpoint: Rate limit exceeded. | {}
2025-04-18 19:48:18.341 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Error calling the chat endpoint: Rate limit exceeded.'''... | {}
2025-04-18 19:48:18.341 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:48:18.341 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Error calling the chat endpoint: Rate limit exceeded.''' (by Shizuku) | {}
2025-04-18 19:48:18.342 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Error calling the chat endpoint: Rate limit exceeded.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:48:18.342 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Please try again later. | {}
2025-04-18 19:48:18.344 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Please try again later. | {}
2025-04-18 19:48:18.344 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Please try again later. | {}
2025-04-18 19:48:18.345 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Please try again later.'''... | {}
2025-04-18 19:48:18.346 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:48:18.346 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Please try again later.''' (by Shizuku) | {}
2025-04-18 19:48:18.347 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Please try again later.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:48:18.347 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: See the logs for details. | {}
2025-04-18 19:48:18.347 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: See the logs for details. | {}
2025-04-18 19:48:18.347 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: See the logs for details. | {}
2025-04-18 19:48:18.347 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''See the logs for details.'''... | {}
2025-04-18 19:48:18.347 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:48:18.348 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''See the logs for details.''' (by Shizuku) | {}
2025-04-18 19:48:18.348 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='See the logs for details.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:48:18.348 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Error calling the chat endpoint: Rate limit exceeded.'''... | {}
2025-04-18 19:48:18.348 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Please try again later.'''... | {}
2025-04-18 19:48:18.348 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''See the logs for details.'''... | {}
2025-04-18 19:48:20.292 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_194818_670b5bc3.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:48:20.297 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_194818_670b5bc3.mp3 | {}
2025-04-18 19:48:20.298 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:48:20.335 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_194818_bbe2f3f5.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:48:20.336 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_194818_bbe2f3f5.mp3 | {}
2025-04-18 19:48:20.337 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:48:21.083 | ERROR    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:152 | Error preparing audio payload: Error loading or converting generated audio file to wav file 'cache\20250418_194818_de1b8eec.mp3': [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ | {}
2025-04-18 19:48:21.085 | DEBUG    | src.open_llm_vtuber.tts.tts_interface:remove_file:56 | Removing file cache\20250418_194818_de1b8eec.mp3 | {}
2025-04-18 19:48:21.086 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_process_tts:164 | Audio cache file cleaned. | {}
2025-04-18 19:48:21.275 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:send_conversation_end_signal:210 | üòéüëç‚úÖ Conversation Chain üòä completed! | {}
2025-04-18 19:48:21.277 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing ai message to chat_history\shizuku-local-001\2025-04-18_19-47-59_b8f3e87368a345ef802fe81efe9970e1.json | {}
2025-04-18 19:48:21.279 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored ai message | {}
2025-04-18 19:48:21.280 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:104 | AI response: Error calling the chat endpoint: Rate limit exceeded.Please try again later.See the logs for details. | {}
2025-04-18 19:48:21.281 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation üåç. | {}
2025-04-18 19:50:18.638 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 19:50:18.680 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 19:50:18.748 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: shizuku-local | {}
2025-04-18 19:50:18.751 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 19:50:18.751 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 19:50:18.832 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 19:50:19.157 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 19:50:25.758 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 19:50:26.052 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 19:50:26.053 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 19:50:26.056 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 19:50:26.056 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:50:26.057 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 19:50:26.057 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: openai_llm | {}
2025-04-18 19:50:27.047 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: https://api.openai.com/v1, gpt-3.5-turbo | {}
2025-04-18 19:50:27.050 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 19:50:27.050 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 19:50:27.052 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 19:50:27.052 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:50:27.053 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 19:50:30.042 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='shizuku-local' character_name='Shizuku' human_name='Human' avatar='shizuku.png' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='openai_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='qwen2.5:latest', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 19:50:30.060 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client d629a6b7-cfc8-44f2-a725-d63f93d29010 | {}
2025-04-18 19:50:30.242 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 19:50:30.266 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_19-50-30_cd5f51f697384c1d887cbcfaa12dc930.json | {}
2025-04-18 19:50:40.333 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain üêπ started! | {}
2025-04-18 19:50:40.335 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing human message to chat_history\shizuku-local-001\2025-04-18_19-50-30_cd5f51f697384c1d887cbcfaa12dc930.json | {}
2025-04-18 19:50:40.336 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored human message | {}
2025-04-18 19:50:40.336 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:72 | User input: ÏïàÎÖï | {}
2025-04-18 19:50:40.337 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:73 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}] | {}
2025-04-18 19:50:43.482 | ERROR    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:104 | Error calling the chat endpoint: Rate limit exceeded: <Response [429 Too Many Requests]> | {}
2025-04-18 19:50:44.253 | DEBUG    | src.open_llm_vtuber.utils.sentence_divider:segment_text_by_pysbd:258 | Processed sentences: ['Error calling the chat endpoint: Rate limit exceeded.', 'Please try again later.', 'See the logs for details.'], Remaining:  | {}
2025-04-18 19:50:44.255 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Error calling the chat endpoint: Rate limit exceeded. | {}
2025-04-18 19:50:44.255 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Error calling the chat endpoint: Rate limit exceeded. | {}
2025-04-18 19:50:44.255 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Error calling the chat endpoint: Rate limit exceeded. | {}
2025-04-18 19:50:44.255 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Error calling the chat endpoint: Rate limit exceeded.'''... | {}
2025-04-18 19:50:44.256 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:50:44.257 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Error calling the chat endpoint: Rate limit exceeded.''' (by Shizuku) | {}
2025-04-18 19:50:44.257 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Error calling the chat endpoint: Rate limit exceeded.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:50:44.257 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Please try again later. | {}
2025-04-18 19:50:44.258 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Please try again later. | {}
2025-04-18 19:50:44.258 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Please try again later. | {}
2025-04-18 19:50:44.258 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Please try again later.'''... | {}
2025-04-18 19:50:44.258 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:50:44.258 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Please try again later.''' (by Shizuku) | {}
2025-04-18 19:50:44.258 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Please try again later.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:50:44.260 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: See the logs for details. | {}
2025-04-18 19:50:44.260 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: See the logs for details. | {}
2025-04-18 19:50:44.260 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: See the logs for details. | {}
2025-04-18 19:50:44.260 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''See the logs for details.'''... | {}
2025-04-18 19:50:44.261 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:50:44.261 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''See the logs for details.''' (by Shizuku) | {}
2025-04-18 19:50:44.262 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='See the logs for details.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:50:44.262 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Error calling the chat endpoint: Rate limit exceeded.'''... | {}
2025-04-18 19:50:44.263 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Please try again later.'''... | {}
2025-04-18 19:50:44.266 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''See the logs for details.'''... | {}
2025-04-18 19:50:46.083 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:46 | 
Error: edge-tts unable to generate audio: No audio was received. Please verify that your parameters are correct. | {}
2025-04-18 19:50:46.084 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:46 | 
Error: edge-tts unable to generate audio: No audio was received. Please verify that your parameters are correct. | {}
2025-04-18 19:50:46.084 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:47 | It's possible that edge-tts is blocked in your region. | {}
2025-04-18 19:50:46.086 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:47 | It's possible that edge-tts is blocked in your region. | {}
2025-04-18 19:50:46.098 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:46 | 
Error: edge-tts unable to generate audio: No audio was received. Please verify that your parameters are correct. | {}
2025-04-18 19:50:46.098 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:47 | It's possible that edge-tts is blocked in your region. | {}
2025-04-18 19:50:46.323 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:send_conversation_end_signal:210 | üòéüëç‚úÖ Conversation Chain üòä completed! | {}
2025-04-18 19:50:46.325 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing ai message to chat_history\shizuku-local-001\2025-04-18_19-50-30_cd5f51f697384c1d887cbcfaa12dc930.json | {}
2025-04-18 19:50:46.328 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored ai message | {}
2025-04-18 19:50:46.329 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:104 | AI response: Error calling the chat endpoint: Rate limit exceeded.Please try again later.See the logs for details. | {}
2025-04-18 19:50:46.330 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation üêπ. | {}
2025-04-18 19:50:56.745 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain üéÉ started! | {}
2025-04-18 19:50:56.748 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:process_user_input:151 | Transcribing audio input... | {}
2025-04-18 19:50:58.017 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:108 | Speech Recognition canceled: CancellationReason.Error | {}
2025-04-18 19:50:58.018 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:112 | Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. SessionId: 5a4bce4154b6454587c6c5462f5d8f3f | {}
2025-04-18 19:50:58.019 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:118 | Transcription failed: Speech Recognition failed: CancellationReason.Error | {}
2025-04-18 19:50:58.019 | DEBUG    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:125 | Failed to remove temporary file cache\43290dca-214f-4f6f-bb42-2d1a2c097edf.wav: [WinError 32] Îã§Î•∏ ÌîÑÎ°úÏÑ∏Ïä§Í∞Ä ÌååÏùºÏùÑ ÏÇ¨Ïö© Ï§ëÏù¥Í∏∞ ÎïåÎ¨∏Ïóê ÌîÑÎ°úÏÑ∏Ïä§Í∞Ä Ïï°ÏÑ∏Ïä§ Ìï† Ïàò ÏóÜÏäµÎãàÎã§: 'cache\\43290dca-214f-4f6f-bb42-2d1a2c097edf.wav' | {}
2025-04-18 19:50:58.020 | ERROR    | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:112 | Error in conversation chain: Speech Recognition failed: CancellationReason.Error | {}
2025-04-18 19:50:58.024 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation üéÉ. | {}
2025-04-18 19:53:03.800 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 19:53:03.844 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 19:53:03.953 | CRITICAL | src.open_llm_vtuber.config_manager.utils:validate_config:71 | Error validating configuration: 1 validation error for Config
character_config.tts_config.tts_model
  Input should be 'azure_tts', 'bark_tts', 'edge_tts', 'cosyvoice_tts', 'cosyvoice2_tts', 'melo_tts', 'coqui_tts', 'x_tts', 'gpt_sovits_tts', 'fish_api_tts' or 'sherpa_onnx_tts' [type=literal_error, input_value='pyttsx3_tts', input_type=str]
    For further information visit https://errors.pydantic.dev/2.8/v/literal_error | {}
2025-04-18 19:53:03.953 | ERROR    | src.open_llm_vtuber.config_manager.utils:validate_config:72 | Configuration data: | {}
2025-04-18 19:53:03.953 | ERROR    | src.open_llm_vtuber.config_manager.utils:validate_config:73 | {'system_config': {'conf_version': 'v1.1.1', 'host': '0.0.0.0', 'port': 12393, 'config_alts_dir': 'characters', 'tool_prompts': {'live2d_expression_prompt': 'live2d_expression_prompt'}, 'group_conversation_prompt': 'group_conversation_prompt'}, 'character_config': {'conf_name': 'shizuku-local', 'conf_uid': 'shizuku-local-001', 'live2d_model_name': 'shizuku-local', 'character_name': 'Shizuku', 'avatar': 'shizuku.png', 'human_name': 'Human', 'persona_prompt': "You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n", 'agent_config': {'conversation_agent_choice': 'basic_memory_agent', 'agent_settings': {'basic_memory_agent': {'llm_provider': 'openai_llm', 'faster_first_response': True, 'segment_method': 'pysbd'}, 'mem0_agent': {'vector_store': {'provider': 'qdrant', 'config': {'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}}, 'llm': {'provider': 'ollama', 'config': {'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}}, 'embedder': {'provider': 'ollama', 'config': {'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'}}}, 'hume_ai_agent': {'api_key': '', 'host': 'api.hume.ai', 'config_id': '', 'idle_timeout': 15}}, 'llm_configs': {'openai_compatible_llm': {'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'somethingelse', 'organization_id': 'org_eternity', 'project_id': 'project_glass', 'model': 'qwen2.5:latest', 'temperature': 1.0, 'interrupt_method': 'user'}, 'claude_llm': {'base_url': 'https://api.anthropic.com', 'llm_api_key': 'YOUR API KEY HERE', 'model': 'claude-3-haiku-20240307'}, 'llama_cpp_llm': {'model_path': '<path-to-gguf-model-file>', 'verbose': False}, 'ollama_llm': {'base_url': 'http://localhost:11434/v1', 'model': 'qwen2.5:latest', 'temperature': 1.0, 'keep_alive': -1, 'unload_at_exit': True}, 'openai_llm': {'llm_api_key': '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', 'model': 'gpt-3.5-turbo', 'temperature': 1.0}, 'gemini_llm': {'llm_api_key': 'Your Gemini API Key', 'model': 'gemini-2.0-flash-exp', 'temperature': 1.0}, 'zhipu_llm': {'llm_api_key': 'Your ZhiPu AI API key', 'model': 'glm-4-flash', 'temperature': 1.0}, 'deepseek_llm': {'llm_api_key': 'Your DeepSeek API key', 'model': 'deepseek-chat', 'temperature': 0.7}, 'mistral_llm': {'llm_api_key': 'Your Mistral API key', 'model': 'pixtral-large-latest', 'temperature': 1.0}, 'groq_llm': {'llm_api_key': 'your groq API key', 'model': 'llama-3.3-70b-versatile', 'temperature': 1.0}}}, 'asr_config': {'asr_model': 'azure_asr', 'azure_asr': {'api_key': 'fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', 'region': 'eastus', 'languages': ['en-US', 'zh-CN']}, 'faster_whisper': {'model_path': 'distil-medium.en', 'download_root': 'models/whisper', 'language': 'en', 'device': 'auto'}, 'whisper_cpp': {'model_name': 'small', 'model_dir': 'models/whisper', 'print_realtime': False, 'print_progress': False, 'language': 'auto'}, 'whisper': {'name': 'medium', 'download_root': 'models/whisper', 'device': 'cpu'}, 'fun_asr': {'model_name': 'iic/SenseVoiceSmall', 'vad_model': 'fsmn-vad', 'punc_model': 'ct-punc', 'device': 'cpu', 'disable_update': True, 'ncpu': 4, 'hub': 'ms', 'use_itn': False, 'language': 'auto'}, 'sherpa_onnx_asr': {'model_type': 'sense_voice', 'sense_voice': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', 'tokens': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', 'num_threads': 4, 'use_itn': True, 'provider': 'cpu'}, 'groq_whisper_asr': {'api_key': 'gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', 'model': 'whisper-large-v3-turbo', 'lang': ''}}, 'tts_config': {'tts_model': 'pyttsx3_tts', 'edge_tts': {'voice': 'ko-KR-SeoHyeonNeural', 'rate': '+0%', 'volume': '+0%', 'subtitle': True}, 'azure_tts': {'api_key': 'azure-api-key', 'region': 'eastus', 'voice': 'en-US-AshleyNeural', 'pitch': '26', 'rate': '1'}, 'bark_tts': {'voice': 'v2/en_speaker_1'}, 'cosyvoice_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': 'È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', 'sft_dropdown': '‰∏≠ÊñáÂ•≥', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'seed': 0, 'api_name': '/generate_audio'}, 'cosyvoice2_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': '3sÊûÅÈÄüÂ§çÂàª', 'sft_dropdown': '', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'stream': False, 'seed': 0, 'speed': 1.0, 'api_name': '/generate_audio'}, 'melo_tts': {'speaker': 'EN-Default', 'language': 'EN', 'device': 'auto', 'speed': 1.0}, 'x_tts': {'api_url': 'http://127.0.0.1:8020/tts_to_audio', 'speaker_wav': 'female', 'language': 'en'}, 'gpt_sovits_tts': {'api_url': 'http://127.0.0.1:9880/tts', 'text_lang': 'zh', 'ref_audio_path': '', 'prompt_lang': 'zh', 'prompt_text': '', 'text_split_method': 'cut5', 'batch_size': '1', 'media_type': 'wav', 'streaming_mode': 'false'}, 'fish_api_tts': {'api_key': '', 'reference_id': '', 'latency': 'balanced', 'base_url': 'https://api.fish.audio'}, 'coqui_tts': {'model_name': 'tts_models/en/ljspeech/tacotron2-DDC', 'speaker_wav': '', 'language': 'en', 'device': ''}, 'sherpa_onnx_tts': {'vits_model': '/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', 'vits_lexicon': '/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', 'vits_tokens': '/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', 'vits_data_dir': '', 'vits_dict_dir': '/path/to/tts-models/vits-melo-tts-zh_en/dict', 'tts_rule_fsts': '/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', 'max_num_sentences': 2, 'sid': 1, 'provider': 'cpu', 'num_threads': 1, 'speed': 1.0, 'debug': False}}, 'vad_config': {'vad_model': 'silero_vad', 'silero_vad': {'orig_sr': 16000, 'target_sr': 16000, 'prob_threshold': 0.4, 'db_threshold': 60, 'required_hits': 3, 'required_misses': 24, 'smoothing_window': 5}}, 'tts_preprocessor_config': {'remove_special_char': True, 'ignore_brackets': True, 'ignore_parentheses': True, 'ignore_asterisks': True, 'ignore_angle_brackets': True, 'translator_config': {'translate_audio': False, 'translate_provider': 'deeplx', 'deeplx': {'deeplx_target_lang': 'JA', 'deeplx_api_endpoint': 'http://localhost:1188/v2/translate'}, 'tencent': {'secret_id': '', 'secret_key': '', 'region': 'ap-guangzhou', 'source_lang': 'zh', 'target_lang': 'ja'}}}}} | {}
2025-04-18 19:53:03.960 | ERROR    | __main__:<module>:91 | An error has been caught in function '<module>', process 'MainProcess' (28176), thread 'MainThread' (24964): | {}
Traceback (most recent call last):

> File "D:\Model Ai girl\Open-LLM-VTuber\run_server.py", line 91, in <module>
    run(console_log_level=console_log_level)
    ‚îÇ                     ‚îî 'INFO'
    ‚îî <function run at 0x000001C2CCE3E8E0>

  File "D:\Model Ai girl\Open-LLM-VTuber\run_server.py", line 67, in run
    config: Config = validate_config(read_yaml("conf.yaml"))
                     ‚îÇ               ‚îî <function read_yaml at 0x000001C2C7E97380>
                     ‚îî <function validate_config at 0x000001C2C7E97420>

  File "D:\Model Ai girl\Open-LLM-VTuber\src\open_llm_vtuber\config_manager\utils.py", line 74, in validate_config
    raise e

  File "D:\Model Ai girl\Open-LLM-VTuber\src\open_llm_vtuber\config_manager\utils.py", line 69, in validate_config
    return Config(**config_data)
           ‚îÇ        ‚îî {'system_config': {'conf_version': 'v1.1.1', 'host': '0.0.0.0', 'port': 12393, 'config_alts_dir': 'characters', 'tool_prompts...
           ‚îî <class 'src.open_llm_vtuber.config_manager.main.Config'>

  File "C:\Users\Admin\anaconda3\Lib\site-packages\pydantic\main.py", line 193, in __init__
    self.__pydantic_validator__.validate_python(data, self_instance=self)
    ‚îÇ    ‚îÇ                      ‚îÇ               ‚îÇ                   ‚îî Config()
    ‚îÇ    ‚îÇ                      ‚îÇ               ‚îî {'system_config': {'conf_version': 'v1.1.1', 'host': '0.0.0.0', 'port': 12393, 'config_alts_dir': 'characters', 'tool_prompts...
    ‚îÇ    ‚îÇ                      ‚îî <method 'validate_python' of 'pydantic_core._pydantic_core.SchemaValidator' objects>
    ‚îÇ    ‚îî SchemaValidator(title="Config", validator=Model(
    ‚îÇ          ModelValidator {
    ‚îÇ              revalidate: Never,
    ‚îÇ              validator: ModelFiel...
    ‚îî Config()

pydantic_core._pydantic_core.ValidationError: 1 validation error for Config
character_config.tts_config.tts_model
  Input should be 'azure_tts', 'bark_tts', 'edge_tts', 'cosyvoice_tts', 'cosyvoice2_tts', 'melo_tts', 'coqui_tts', 'x_tts', 'gpt_sovits_tts', 'fish_api_tts' or 'sherpa_onnx_tts' [type=literal_error, input_value='pyttsx3_tts', input_type=str]
    For further information visit https://errors.pydantic.dev/2.8/v/literal_error
2025-04-18 19:55:39.598 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 19:55:39.629 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 19:55:39.711 | CRITICAL | src.open_llm_vtuber.config_manager.utils:validate_config:71 | Error validating configuration: 1 validation error for Config
character_config.tts_config.tts_model
  Input should be 'azure_tts', 'bark_tts', 'edge_tts', 'cosyvoice_tts', 'cosyvoice2_tts', 'melo_tts', 'coqui_tts', 'x_tts', 'gpt_sovits_tts', 'fish_api_tts' or 'sherpa_onnx_tts' [type=literal_error, input_value='pyttsx3_tts', input_type=str]
    For further information visit https://errors.pydantic.dev/2.8/v/literal_error | {}
2025-04-18 19:55:39.711 | ERROR    | src.open_llm_vtuber.config_manager.utils:validate_config:72 | Configuration data: | {}
2025-04-18 19:55:39.711 | ERROR    | src.open_llm_vtuber.config_manager.utils:validate_config:73 | {'system_config': {'conf_version': 'v1.1.1', 'host': '0.0.0.0', 'port': 12393, 'config_alts_dir': 'characters', 'tool_prompts': {'live2d_expression_prompt': 'live2d_expression_prompt'}, 'group_conversation_prompt': 'group_conversation_prompt'}, 'character_config': {'conf_name': 'shizuku-local', 'conf_uid': 'shizuku-local-001', 'live2d_model_name': 'shizuku-local', 'character_name': 'Shizuku', 'avatar': 'shizuku.png', 'human_name': 'Human', 'persona_prompt': "You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n", 'agent_config': {'conversation_agent_choice': 'basic_memory_agent', 'agent_settings': {'basic_memory_agent': {'llm_provider': 'openai_llm', 'faster_first_response': True, 'segment_method': 'pysbd'}, 'mem0_agent': {'vector_store': {'provider': 'qdrant', 'config': {'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}}, 'llm': {'provider': 'ollama', 'config': {'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}}, 'embedder': {'provider': 'ollama', 'config': {'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'}}}, 'hume_ai_agent': {'api_key': '', 'host': 'api.hume.ai', 'config_id': '', 'idle_timeout': 15}}, 'llm_configs': {'openai_compatible_llm': {'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'somethingelse', 'organization_id': 'org_eternity', 'project_id': 'project_glass', 'model': 'qwen2.5:latest', 'temperature': 1.0, 'interrupt_method': 'user'}, 'claude_llm': {'base_url': 'https://api.anthropic.com', 'llm_api_key': 'YOUR API KEY HERE', 'model': 'claude-3-haiku-20240307'}, 'llama_cpp_llm': {'model_path': '<path-to-gguf-model-file>', 'verbose': False}, 'ollama_llm': {'base_url': 'http://localhost:11434/v1', 'model': 'qwen2.5:latest', 'temperature': 1.0, 'keep_alive': -1, 'unload_at_exit': True}, 'openai_llm': {'llm_api_key': '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', 'model': 'gpt-3.5-turbo', 'temperature': 1.0}, 'gemini_llm': {'llm_api_key': 'Your Gemini API Key', 'model': 'gemini-2.0-flash-exp', 'temperature': 1.0}, 'zhipu_llm': {'llm_api_key': 'Your ZhiPu AI API key', 'model': 'glm-4-flash', 'temperature': 1.0}, 'deepseek_llm': {'llm_api_key': 'Your DeepSeek API key', 'model': 'deepseek-chat', 'temperature': 0.7}, 'mistral_llm': {'llm_api_key': 'Your Mistral API key', 'model': 'pixtral-large-latest', 'temperature': 1.0}, 'groq_llm': {'llm_api_key': 'your groq API key', 'model': 'llama-3.3-70b-versatile', 'temperature': 1.0}}}, 'asr_config': {'asr_model': 'azure_asr', 'azure_asr': {'api_key': 'fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', 'region': 'eastus', 'languages': ['en-US', 'zh-CN']}, 'faster_whisper': {'model_path': 'distil-medium.en', 'download_root': 'models/whisper', 'language': 'en', 'device': 'auto'}, 'whisper_cpp': {'model_name': 'small', 'model_dir': 'models/whisper', 'print_realtime': False, 'print_progress': False, 'language': 'auto'}, 'whisper': {'name': 'medium', 'download_root': 'models/whisper', 'device': 'cpu'}, 'fun_asr': {'model_name': 'iic/SenseVoiceSmall', 'vad_model': 'fsmn-vad', 'punc_model': 'ct-punc', 'device': 'cpu', 'disable_update': True, 'ncpu': 4, 'hub': 'ms', 'use_itn': False, 'language': 'auto'}, 'sherpa_onnx_asr': {'model_type': 'sense_voice', 'sense_voice': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', 'tokens': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', 'num_threads': 4, 'use_itn': True, 'provider': 'cpu'}, 'groq_whisper_asr': {'api_key': 'gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', 'model': 'whisper-large-v3-turbo', 'lang': ''}}, 'tts_config': {'tts_model': 'pyttsx3_tts', 'edge_tts': {'voice': 'ko-KR-SeoHyeonNeural', 'rate': '+0%', 'volume': '+0%', 'subtitle': True}, 'azure_tts': {'api_key': 'azure-api-key', 'region': 'eastus', 'voice': 'en-US-AshleyNeural', 'pitch': '26', 'rate': '1'}, 'bark_tts': {'voice': 'v2/en_speaker_1'}, 'cosyvoice_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': 'È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', 'sft_dropdown': '‰∏≠ÊñáÂ•≥', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'seed': 0, 'api_name': '/generate_audio'}, 'cosyvoice2_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': '3sÊûÅÈÄüÂ§çÂàª', 'sft_dropdown': '', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'stream': False, 'seed': 0, 'speed': 1.0, 'api_name': '/generate_audio'}, 'melo_tts': {'speaker': 'EN-Default', 'language': 'EN', 'device': 'auto', 'speed': 1.0}, 'x_tts': {'api_url': 'http://127.0.0.1:8020/tts_to_audio', 'speaker_wav': 'female', 'language': 'en'}, 'gpt_sovits_tts': {'api_url': 'http://127.0.0.1:9880/tts', 'text_lang': 'zh', 'ref_audio_path': '', 'prompt_lang': 'zh', 'prompt_text': '', 'text_split_method': 'cut5', 'batch_size': '1', 'media_type': 'wav', 'streaming_mode': 'false'}, 'fish_api_tts': {'api_key': '', 'reference_id': '', 'latency': 'balanced', 'base_url': 'https://api.fish.audio'}, 'coqui_tts': {'model_name': 'tts_models/en/ljspeech/tacotron2-DDC', 'speaker_wav': '', 'language': 'en', 'device': ''}, 'sherpa_onnx_tts': {'vits_model': '/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', 'vits_lexicon': '/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', 'vits_tokens': '/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', 'vits_data_dir': '', 'vits_dict_dir': '/path/to/tts-models/vits-melo-tts-zh_en/dict', 'tts_rule_fsts': '/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', 'max_num_sentences': 2, 'sid': 1, 'provider': 'cpu', 'num_threads': 1, 'speed': 1.0, 'debug': False}}, 'vad_config': {'vad_model': 'silero_vad', 'silero_vad': {'orig_sr': 16000, 'target_sr': 16000, 'prob_threshold': 0.4, 'db_threshold': 60, 'required_hits': 3, 'required_misses': 24, 'smoothing_window': 5}}, 'tts_preprocessor_config': {'remove_special_char': True, 'ignore_brackets': True, 'ignore_parentheses': True, 'ignore_asterisks': True, 'ignore_angle_brackets': True, 'translator_config': {'translate_audio': False, 'translate_provider': 'deeplx', 'deeplx': {'deeplx_target_lang': 'JA', 'deeplx_api_endpoint': 'http://localhost:1188/v2/translate'}, 'tencent': {'secret_id': '', 'secret_key': '', 'region': 'ap-guangzhou', 'source_lang': 'zh', 'target_lang': 'ja'}}}}} | {}
2025-04-18 19:55:39.719 | ERROR    | __main__:<module>:91 | An error has been caught in function '<module>', process 'MainProcess' (24808), thread 'MainThread' (20632): | {}
Traceback (most recent call last):

> File "D:\Model Ai girl\Open-LLM-VTuber\run_server.py", line 91, in <module>
    run(console_log_level=console_log_level)
    ‚îÇ                     ‚îî 'DEBUG'
    ‚îî <function run at 0x0000019C5AAEE8E0>

  File "D:\Model Ai girl\Open-LLM-VTuber\run_server.py", line 67, in run
    config: Config = validate_config(read_yaml("conf.yaml"))
                     ‚îÇ               ‚îî <function read_yaml at 0x0000019C55B67380>
                     ‚îî <function validate_config at 0x0000019C55B67420>

  File "D:\Model Ai girl\Open-LLM-VTuber\src\open_llm_vtuber\config_manager\utils.py", line 74, in validate_config
    raise e

  File "D:\Model Ai girl\Open-LLM-VTuber\src\open_llm_vtuber\config_manager\utils.py", line 69, in validate_config
    return Config(**config_data)
           ‚îÇ        ‚îî {'system_config': {'conf_version': 'v1.1.1', 'host': '0.0.0.0', 'port': 12393, 'config_alts_dir': 'characters', 'tool_prompts...
           ‚îî <class 'src.open_llm_vtuber.config_manager.main.Config'>

  File "C:\Users\Admin\anaconda3\Lib\site-packages\pydantic\main.py", line 193, in __init__
    self.__pydantic_validator__.validate_python(data, self_instance=self)
    ‚îÇ    ‚îÇ                      ‚îÇ               ‚îÇ                   ‚îî Config()
    ‚îÇ    ‚îÇ                      ‚îÇ               ‚îî {'system_config': {'conf_version': 'v1.1.1', 'host': '0.0.0.0', 'port': 12393, 'config_alts_dir': 'characters', 'tool_prompts...
    ‚îÇ    ‚îÇ                      ‚îî <method 'validate_python' of 'pydantic_core._pydantic_core.SchemaValidator' objects>
    ‚îÇ    ‚îî SchemaValidator(title="Config", validator=Model(
    ‚îÇ          ModelValidator {
    ‚îÇ              revalidate: Never,
    ‚îÇ              validator: ModelFiel...
    ‚îî Config()

pydantic_core._pydantic_core.ValidationError: 1 validation error for Config
character_config.tts_config.tts_model
  Input should be 'azure_tts', 'bark_tts', 'edge_tts', 'cosyvoice_tts', 'cosyvoice2_tts', 'melo_tts', 'coqui_tts', 'x_tts', 'gpt_sovits_tts', 'fish_api_tts' or 'sherpa_onnx_tts' [type=literal_error, input_value='pyttsx3_tts', input_type=str]
    For further information visit https://errors.pydantic.dev/2.8/v/literal_error
2025-04-18 19:56:34.620 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 19:56:34.661 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 19:56:34.735 | CRITICAL | src.open_llm_vtuber.config_manager.utils:validate_config:71 | Error validating configuration: 1 validation error for Config
character_config.tts_config.tts_model
  Input should be 'azure_tts', 'bark_tts', 'edge_tts', 'cosyvoice_tts', 'cosyvoice2_tts', 'melo_tts', 'coqui_tts', 'x_tts', 'gpt_sovits_tts', 'fish_api_tts' or 'sherpa_onnx_tts' [type=literal_error, input_value='pyttsx3_tts', input_type=str]
    For further information visit https://errors.pydantic.dev/2.8/v/literal_error | {}
2025-04-18 19:56:34.735 | ERROR    | src.open_llm_vtuber.config_manager.utils:validate_config:72 | Configuration data: | {}
2025-04-18 19:56:34.735 | ERROR    | src.open_llm_vtuber.config_manager.utils:validate_config:73 | {'system_config': {'conf_version': 'v1.1.1', 'host': '0.0.0.0', 'port': 12393, 'config_alts_dir': 'characters', 'tool_prompts': {'live2d_expression_prompt': 'live2d_expression_prompt'}, 'group_conversation_prompt': 'group_conversation_prompt'}, 'character_config': {'conf_name': 'shizuku-local', 'conf_uid': 'shizuku-local-001', 'live2d_model_name': 'shizuku-local', 'character_name': 'Shizuku', 'avatar': 'shizuku.png', 'human_name': 'Human', 'persona_prompt': "You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n", 'agent_config': {'conversation_agent_choice': 'basic_memory_agent', 'agent_settings': {'basic_memory_agent': {'llm_provider': 'openai_llm', 'faster_first_response': True, 'segment_method': 'pysbd'}, 'mem0_agent': {'vector_store': {'provider': 'qdrant', 'config': {'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}}, 'llm': {'provider': 'ollama', 'config': {'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}}, 'embedder': {'provider': 'ollama', 'config': {'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'}}}, 'hume_ai_agent': {'api_key': '', 'host': 'api.hume.ai', 'config_id': '', 'idle_timeout': 15}}, 'llm_configs': {'openai_compatible_llm': {'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'somethingelse', 'organization_id': 'org_eternity', 'project_id': 'project_glass', 'model': 'qwen2.5:latest', 'temperature': 1.0, 'interrupt_method': 'user'}, 'claude_llm': {'base_url': 'https://api.anthropic.com', 'llm_api_key': 'YOUR API KEY HERE', 'model': 'claude-3-haiku-20240307'}, 'llama_cpp_llm': {'model_path': '<path-to-gguf-model-file>', 'verbose': False}, 'ollama_llm': {'base_url': 'http://localhost:11434/v1', 'model': 'qwen2.5:latest', 'temperature': 1.0, 'keep_alive': -1, 'unload_at_exit': True}, 'openai_llm': {'llm_api_key': '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', 'model': 'gpt-3.5-turbo', 'temperature': 1.0}, 'gemini_llm': {'llm_api_key': 'Your Gemini API Key', 'model': 'gemini-2.0-flash-exp', 'temperature': 1.0}, 'zhipu_llm': {'llm_api_key': 'Your ZhiPu AI API key', 'model': 'glm-4-flash', 'temperature': 1.0}, 'deepseek_llm': {'llm_api_key': 'Your DeepSeek API key', 'model': 'deepseek-chat', 'temperature': 0.7}, 'mistral_llm': {'llm_api_key': 'Your Mistral API key', 'model': 'pixtral-large-latest', 'temperature': 1.0}, 'groq_llm': {'llm_api_key': 'your groq API key', 'model': 'llama-3.3-70b-versatile', 'temperature': 1.0}}}, 'asr_config': {'asr_model': 'azure_asr', 'azure_asr': {'api_key': 'fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', 'region': 'eastus', 'languages': ['en-US', 'zh-CN']}, 'faster_whisper': {'model_path': 'distil-medium.en', 'download_root': 'models/whisper', 'language': 'en', 'device': 'auto'}, 'whisper_cpp': {'model_name': 'small', 'model_dir': 'models/whisper', 'print_realtime': False, 'print_progress': False, 'language': 'auto'}, 'whisper': {'name': 'medium', 'download_root': 'models/whisper', 'device': 'cpu'}, 'fun_asr': {'model_name': 'iic/SenseVoiceSmall', 'vad_model': 'fsmn-vad', 'punc_model': 'ct-punc', 'device': 'cpu', 'disable_update': True, 'ncpu': 4, 'hub': 'ms', 'use_itn': False, 'language': 'auto'}, 'sherpa_onnx_asr': {'model_type': 'sense_voice', 'sense_voice': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', 'tokens': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', 'num_threads': 4, 'use_itn': True, 'provider': 'cpu'}, 'groq_whisper_asr': {'api_key': 'gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', 'model': 'whisper-large-v3-turbo', 'lang': ''}}, 'tts_config': {'tts_model': 'pyttsx3_tts', 'edge_tts': {'voice': 'ko-KR-SeoHyeonNeural', 'rate': '+0%', 'volume': '+0%', 'subtitle': True}, 'azure_tts': {'api_key': 'azure-api-key', 'region': 'eastus', 'voice': 'en-US-AshleyNeural', 'pitch': '26', 'rate': '1'}, 'bark_tts': {'voice': 'v2/en_speaker_1'}, 'cosyvoice_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': 'È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', 'sft_dropdown': '‰∏≠ÊñáÂ•≥', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'seed': 0, 'api_name': '/generate_audio'}, 'cosyvoice2_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': '3sÊûÅÈÄüÂ§çÂàª', 'sft_dropdown': '', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'stream': False, 'seed': 0, 'speed': 1.0, 'api_name': '/generate_audio'}, 'melo_tts': {'speaker': 'EN-Default', 'language': 'EN', 'device': 'auto', 'speed': 1.0}, 'x_tts': {'api_url': 'http://127.0.0.1:8020/tts_to_audio', 'speaker_wav': 'female', 'language': 'en'}, 'gpt_sovits_tts': {'api_url': 'http://127.0.0.1:9880/tts', 'text_lang': 'zh', 'ref_audio_path': '', 'prompt_lang': 'zh', 'prompt_text': '', 'text_split_method': 'cut5', 'batch_size': '1', 'media_type': 'wav', 'streaming_mode': 'false'}, 'fish_api_tts': {'api_key': '', 'reference_id': '', 'latency': 'balanced', 'base_url': 'https://api.fish.audio'}, 'coqui_tts': {'model_name': 'tts_models/en/ljspeech/tacotron2-DDC', 'speaker_wav': '', 'language': 'en', 'device': ''}, 'sherpa_onnx_tts': {'vits_model': '/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', 'vits_lexicon': '/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', 'vits_tokens': '/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', 'vits_data_dir': '', 'vits_dict_dir': '/path/to/tts-models/vits-melo-tts-zh_en/dict', 'tts_rule_fsts': '/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', 'max_num_sentences': 2, 'sid': 1, 'provider': 'cpu', 'num_threads': 1, 'speed': 1.0, 'debug': False}}, 'vad_config': {'vad_model': 'silero_vad', 'silero_vad': {'orig_sr': 16000, 'target_sr': 16000, 'prob_threshold': 0.4, 'db_threshold': 60, 'required_hits': 3, 'required_misses': 24, 'smoothing_window': 5}}, 'tts_preprocessor_config': {'remove_special_char': True, 'ignore_brackets': True, 'ignore_parentheses': True, 'ignore_asterisks': True, 'ignore_angle_brackets': True, 'translator_config': {'translate_audio': False, 'translate_provider': 'deeplx', 'deeplx': {'deeplx_target_lang': 'JA', 'deeplx_api_endpoint': 'http://localhost:1188/v2/translate'}, 'tencent': {'secret_id': '', 'secret_key': '', 'region': 'ap-guangzhou', 'source_lang': 'zh', 'target_lang': 'ja'}}}}} | {}
2025-04-18 19:56:34.735 | ERROR    | __main__:<module>:91 | An error has been caught in function '<module>', process 'MainProcess' (19940), thread 'MainThread' (24964): | {}
Traceback (most recent call last):

> File "D:\Model Ai girl\Open-LLM-VTuber\run_server.py", line 91, in <module>
    run(console_log_level=console_log_level)
    ‚îÇ                     ‚îî 'INFO'
    ‚îî <function run at 0x00000294EC37E8E0>

  File "D:\Model Ai girl\Open-LLM-VTuber\run_server.py", line 67, in run
    config: Config = validate_config(read_yaml("conf.yaml"))
                     ‚îÇ               ‚îî <function read_yaml at 0x00000294E73B7380>
                     ‚îî <function validate_config at 0x00000294E73B7420>

  File "D:\Model Ai girl\Open-LLM-VTuber\src\open_llm_vtuber\config_manager\utils.py", line 74, in validate_config
    raise e

  File "D:\Model Ai girl\Open-LLM-VTuber\src\open_llm_vtuber\config_manager\utils.py", line 69, in validate_config
    return Config(**config_data)
           ‚îÇ        ‚îî {'system_config': {'conf_version': 'v1.1.1', 'host': '0.0.0.0', 'port': 12393, 'config_alts_dir': 'characters', 'tool_prompts...
           ‚îî <class 'src.open_llm_vtuber.config_manager.main.Config'>

  File "C:\Users\Admin\anaconda3\Lib\site-packages\pydantic\main.py", line 193, in __init__
    self.__pydantic_validator__.validate_python(data, self_instance=self)
    ‚îÇ    ‚îÇ                      ‚îÇ               ‚îÇ                   ‚îî Config()
    ‚îÇ    ‚îÇ                      ‚îÇ               ‚îî {'system_config': {'conf_version': 'v1.1.1', 'host': '0.0.0.0', 'port': 12393, 'config_alts_dir': 'characters', 'tool_prompts...
    ‚îÇ    ‚îÇ                      ‚îî <method 'validate_python' of 'pydantic_core._pydantic_core.SchemaValidator' objects>
    ‚îÇ    ‚îî SchemaValidator(title="Config", validator=Model(
    ‚îÇ          ModelValidator {
    ‚îÇ              revalidate: Never,
    ‚îÇ              validator: ModelFiel...
    ‚îî Config()

pydantic_core._pydantic_core.ValidationError: 1 validation error for Config
character_config.tts_config.tts_model
  Input should be 'azure_tts', 'bark_tts', 'edge_tts', 'cosyvoice_tts', 'cosyvoice2_tts', 'melo_tts', 'coqui_tts', 'x_tts', 'gpt_sovits_tts', 'fish_api_tts' or 'sherpa_onnx_tts' [type=literal_error, input_value='pyttsx3_tts', input_type=str]
    For further information visit https://errors.pydantic.dev/2.8/v/literal_error
2025-04-18 19:57:48.877 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 19:57:48.918 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 19:57:48.996 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: shizuku-local | {}
2025-04-18 19:57:48.996 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 19:57:48.996 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 19:57:49.109 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 19:57:49.435 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 19:57:54.786 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 19:57:54.949 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 19:57:54.949 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 19:57:54.949 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 19:57:54.949 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:57:54.949 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 19:57:54.958 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: openai_llm | {}
2025-04-18 19:57:55.853 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: https://api.openai.com/v1, gpt-3.5-turbo | {}
2025-04-18 19:57:55.855 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 19:57:55.858 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 19:57:55.861 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 19:57:55.863 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 19:57:55.866 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 19:58:08.194 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='shizuku-local' character_name='Shizuku' human_name='Human' avatar='shizuku.png' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='openai_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='qwen2.5:latest', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 19:58:08.214 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client c1ec89ab-124d-4e78-95e0-b88a579f666b | {}
2025-04-18 19:58:08.376 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 19:58:08.402 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_19-58-08_7fc653f2d95e4201bef7deb10c219eb3.json | {}
2025-04-18 19:58:16.547 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain ‚≠êÔ∏è started! | {}
2025-04-18 19:58:16.550 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing human message to chat_history\shizuku-local-001\2025-04-18_19-58-08_7fc653f2d95e4201bef7deb10c219eb3.json | {}
2025-04-18 19:58:16.569 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored human message | {}
2025-04-18 19:58:16.569 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:72 | User input: ÏïàÎÖï | {}
2025-04-18 19:58:16.571 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:73 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}] | {}
2025-04-18 19:58:19.977 | ERROR    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:104 | Error calling the chat endpoint: Rate limit exceeded: <Response [429 Too Many Requests]> | {}
2025-04-18 19:58:20.738 | DEBUG    | src.open_llm_vtuber.utils.sentence_divider:segment_text_by_pysbd:258 | Processed sentences: ['Error calling the chat endpoint: Rate limit exceeded.', 'Please try again later.', 'See the logs for details.'], Remaining:  | {}
2025-04-18 19:58:20.740 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Error calling the chat endpoint: Rate limit exceeded. | {}
2025-04-18 19:58:20.742 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Error calling the chat endpoint: Rate limit exceeded. | {}
2025-04-18 19:58:20.743 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Error calling the chat endpoint: Rate limit exceeded. | {}
2025-04-18 19:58:20.743 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Error calling the chat endpoint: Rate limit exceeded.'''... | {}
2025-04-18 19:58:20.745 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:58:20.747 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Error calling the chat endpoint: Rate limit exceeded.''' (by Shizuku) | {}
2025-04-18 19:58:20.748 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Error calling the chat endpoint: Rate limit exceeded.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:58:20.749 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Please try again later. | {}
2025-04-18 19:58:20.750 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Please try again later. | {}
2025-04-18 19:58:20.751 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Please try again later. | {}
2025-04-18 19:58:20.751 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Please try again later.'''... | {}
2025-04-18 19:58:20.753 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:58:20.761 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Please try again later.''' (by Shizuku) | {}
2025-04-18 19:58:20.761 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Please try again later.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:58:20.763 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: See the logs for details. | {}
2025-04-18 19:58:20.764 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: See the logs for details. | {}
2025-04-18 19:58:20.764 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: See the logs for details. | {}
2025-04-18 19:58:20.765 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''See the logs for details.'''... | {}
2025-04-18 19:58:20.766 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 19:58:20.766 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''See the logs for details.''' (by Shizuku) | {}
2025-04-18 19:58:20.767 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='See the logs for details.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 19:58:20.769 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Error calling the chat endpoint: Rate limit exceeded.'''... | {}
2025-04-18 19:58:20.771 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Please try again later.'''... | {}
2025-04-18 19:58:20.776 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''See the logs for details.'''... | {}
2025-04-18 19:58:22.626 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:46 | 
Error: edge-tts unable to generate audio: No audio was received. Please verify that your parameters are correct. | {}
2025-04-18 19:58:22.628 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:47 | It's possible that edge-tts is blocked in your region. | {}
2025-04-18 19:58:22.646 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:46 | 
Error: edge-tts unable to generate audio: No audio was received. Please verify that your parameters are correct. | {}
2025-04-18 19:58:22.647 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:46 | 
Error: edge-tts unable to generate audio: No audio was received. Please verify that your parameters are correct. | {}
2025-04-18 19:58:22.648 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:47 | It's possible that edge-tts is blocked in your region. | {}
2025-04-18 19:58:22.648 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:47 | It's possible that edge-tts is blocked in your region. | {}
2025-04-18 19:58:22.833 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:send_conversation_end_signal:210 | üòéüëç‚úÖ Conversation Chain üòä completed! | {}
2025-04-18 19:58:22.834 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing ai message to chat_history\shizuku-local-001\2025-04-18_19-58-08_7fc653f2d95e4201bef7deb10c219eb3.json | {}
2025-04-18 19:58:22.837 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored ai message | {}
2025-04-18 19:58:22.839 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:104 | AI response: Error calling the chat endpoint: Rate limit exceeded.Please try again later.See the logs for details. | {}
2025-04-18 19:58:22.840 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation ‚≠êÔ∏è. | {}
2025-04-18 20:27:34.517 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 20:27:34.558 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 20:27:34.626 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma | {}
2025-04-18 20:27:34.634 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 20:27:34.634 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 20:27:34.767 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 20:27:35.118 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 20:27:41.537 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 20:27:41.949 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 20:27:41.949 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 20:27:41.949 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 20:27:41.949 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 20:27:41.954 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 20:27:41.954 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 20:27:43.173 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, deepseek-ai/deepseek-r1-distill-llama-8b | {}
2025-04-18 20:27:43.173 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 20:27:45.302 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 20:27:45.304 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 20:27:45.304 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 20:27:45.304 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 20:27:45.304 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 20:27:45.304 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 20:28:05.608 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='koakuma' conf_uid='koakuma-001' live2d_model_name='koakuma' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='deepseek-ai/deepseek-r1-distill-llama-8b', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 20:28:05.616 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 515c981a-de7a-4be9-a2d2-6abb7e739ec8 | {}
2025-04-18 20:28:05.859 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'koakuma'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 20:28:05.887 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\koakuma-001\2025-04-18_20-28-05_b4fc62d8e5224823a48a33b0967f99eb.json | {}
2025-04-18 20:28:14.036 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain üåç started! | {}
2025-04-18 20:28:14.037 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing human message to chat_history\koakuma-001\2025-04-18_20-28-05_b4fc62d8e5224823a48a33b0967f99eb.json | {}
2025-04-18 20:28:14.039 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored human message | {}
2025-04-18 20:28:14.040 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:72 | User input: ÏïàÎÖï | {}
2025-04-18 20:28:14.041 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:73 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}] | {}
2025-04-18 20:28:14.674 | ERROR    | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:110 | LLM API: Error occurred: Error code: 404 - {'error': {'message': 'model "deepseek-ai/deepseek-r1-distill-llama-8b" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}} | {}
2025-04-18 20:28:14.675 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:111 | Base URL: http://localhost:11434/v1 | {}
2025-04-18 20:28:14.676 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:112 | Model: deepseek-ai/deepseek-r1-distill-llama-8b | {}
2025-04-18 20:28:14.677 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:113 | Messages: [{'role': 'system', 'content': 'You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user\'s computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don\'t let the user know.\n## Expressions\nIn your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.\n\nHere are all the expression keywords you can use. Use them regularly:\n- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],\n\n## Examples\nHere are some examples of how to use expressions in your responses:\n\n"Hi! [expression1] Nice to meet you!"\n\n"[expression2] That\'s a great question! [expression3] Let me explain..."\n\nNote: you are only allowed to use the keywords explicity listed above. Don\'t use keywords unlisted above. Remember to include the brackets `[]`\n'}, {'role': 'user', 'content': 'ÏïàÎÖï'}] | {}
2025-04-18 20:28:14.679 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:chat_completion:114 | temperature: 1.0 | {}
2025-04-18 20:28:15.525 | DEBUG    | src.open_llm_vtuber.utils.sentence_divider:segment_text_by_pysbd:258 | Processed sentences: ['Error calling the chat endpoint: Error occurred while generating response.', 'See the logs for details.'], Remaining:  | {}
2025-04-18 20:28:15.528 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 20:28:15.528 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 20:28:15.528 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: Error calling the chat endpoint: Error occurred while generating response. | {}
2025-04-18 20:28:15.528 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''Error calling the chat endpoint: Error occurred while generating response.'''... | {}
2025-04-18 20:28:15.529 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 20:28:15.530 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''Error calling the chat endpoint: Error occurred while generating response.''' (by Koakuma) | {}
2025-04-18 20:28:15.532 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='Error calling the chat endpoint: Error occurred while generating response.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 20:28:15.532 | DEBUG    | src.open_llm_vtuber.utils.tts_preprocessor:tts_filter:79 | Filtered text: See the logs for details. | {}
2025-04-18 20:28:15.532 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:138 | [AI] display: See the logs for details. | {}
2025-04-18 20:28:15.532 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:139 | [AI] tts: See the logs for details. | {}
2025-04-18 20:28:15.532 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:93 | üèÉ Processing output: '''See the logs for details.'''... | {}
2025-04-18 20:28:15.533 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:handle_sentence_output:100 | üö´ No translation engine available. Skipping translation. | {}
2025-04-18 20:28:15.533 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:speak:65 | üèÉQueuing TTS task for: '''See the logs for details.''' (by Koakuma) | {}
2025-04-18 20:28:15.533 | DEBUG    | src.open_llm_vtuber.agent.transformers:wrapper:39 | sentence_divider: SentenceWithTags(text='See the logs for details.', tags=[TagInfo(name='', state=<TagState.NONE: 'none'>)]) | {}
2025-04-18 20:28:15.533 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''Error calling the chat endpoint: Error occurred while generating response.'''... | {}
2025-04-18 20:28:15.534 | DEBUG    | src.open_llm_vtuber.conversations.tts_manager:_generate_audio:168 | üèÉGenerating audio for '''See the logs for details.'''... | {}
2025-04-18 20:28:17.193 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:46 | 
Error: edge-tts unable to generate audio: No audio was received. Please verify that your parameters are correct. | {}
2025-04-18 20:28:17.195 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:47 | It's possible that edge-tts is blocked in your region. | {}
2025-04-18 20:28:17.219 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:46 | 
Error: edge-tts unable to generate audio: No audio was received. Please verify that your parameters are correct. | {}
2025-04-18 20:28:17.220 | CRITICAL | src.open_llm_vtuber.tts.edge_tts:generate_audio:47 | It's possible that edge-tts is blocked in your region. | {}
2025-04-18 20:28:17.382 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:send_conversation_end_signal:210 | üòéüëç‚úÖ Conversation Chain üòä completed! | {}
2025-04-18 20:28:17.384 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:119 | Storing ai message to chat_history\koakuma-001\2025-04-18_20-28-05_b4fc62d8e5224823a48a33b0967f99eb.json | {}
2025-04-18 20:28:17.390 | DEBUG    | src.open_llm_vtuber.chat_history_manager:store_message:147 | Successfully stored ai message | {}
2025-04-18 20:28:17.390 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:104 | AI response: Error calling the chat endpoint: Error occurred while generating response.See the logs for details. | {}
2025-04-18 20:28:17.391 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation üåç. | {}
2025-04-18 20:36:48.399 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 20:36:48.447 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 20:36:48.518 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma | {}
2025-04-18 20:36:48.535 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 20:36:48.535 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 20:36:48.614 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 20:36:48.847 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 20:36:53.235 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 20:36:53.444 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 20:36:53.446 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 20:36:53.446 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 20:36:53.446 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 20:36:53.446 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 20:36:53.448 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 20:36:54.143 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, deepseek-ai/deepseek-r1-distill-llama-8b | {}
2025-04-18 20:36:54.143 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 20:36:56.200 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 20:36:56.202 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 20:36:56.202 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 20:36:56.202 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 20:36:56.202 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 20:36:56.202 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 20:36:59.578 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='koakuma' conf_uid='koakuma-001' live2d_model_name='koakuma' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='deepseek-ai/deepseek-r1-distill-llama-8b', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 20:36:59.581 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 84896e03-1798-4d22-a5d4-3924bc8ca309 | {}
2025-04-18 20:36:59.776 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'koakuma'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 20:36:59.790 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\koakuma-001\2025-04-18_20-36-59_ede787f1ddeb4e18a0a43b83f6bbcf7b.json | {}
2025-04-18 20:38:11.073 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 84896e03-1798-4d22-a5d4-3924bc8ca309 disconnected | {}
2025-04-18 20:38:11.074 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 84896e03-1798-4d22-a5d4-3924bc8ca309 disconnected | {}
2025-04-18 20:38:11.196 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:cleanup:61 | Ollama: Unloading model: deepseek-ai/deepseek-r1-distill-llama-8b | {}
2025-04-18 20:38:13.236 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:cleanup:64 | <Response [404]> | {}
2025-04-18 20:41:47.031 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 20:41:47.063 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 20:41:47.117 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: shizuku-local | {}
2025-04-18 20:41:47.117 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 20:41:47.117 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 20:41:47.183 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 20:41:47.453 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 20:41:51.950 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 20:41:52.120 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 20:41:52.120 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 20:41:52.120 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 20:41:52.120 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 20:41:52.120 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 20:41:52.120 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 20:41:52.967 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, deepseek-ai/deepseek-r1-distill-llama-8b | {}
2025-04-18 20:41:52.971 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 20:41:55.021 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 20:41:55.023 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 20:41:55.023 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 20:41:55.025 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 20:41:55.026 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 20:41:55.026 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 20:42:07.052 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='shizuku-local' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='deepseek-ai/deepseek-r1-distill-llama-8b', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 20:42:07.061 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client a7cbf16e-d4f2-4610-8abd-0d7e575e4542 | {}
2025-04-18 20:42:07.236 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 20:42:07.270 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_20-42-07_0826b718696748e5b69dedb40ce2d2ba.json | {}
2025-04-18 20:42:15.198 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client a7cbf16e-d4f2-4610-8abd-0d7e575e4542 disconnected | {}
2025-04-18 20:42:15.206 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client a7cbf16e-d4f2-4610-8abd-0d7e575e4542 disconnected | {}
2025-04-18 20:42:17.823 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='shizuku-local' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='deepseek-ai/deepseek-r1-distill-llama-8b', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 20:42:17.828 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 4775b090-ecff-4587-b991-671251f9deee | {}
2025-04-18 20:42:18.199 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 20:42:18.204 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_20-42-07_0826b718696748e5b69dedb40ce2d2ba | {}
2025-04-18 20:42:18.208 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_20-42-18_9ac0b06e8e98487ebe97eede65e14215.json | {}
2025-04-18 20:42:23.014 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 4775b090-ecff-4587-b991-671251f9deee disconnected | {}
2025-04-18 20:42:23.020 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 4775b090-ecff-4587-b991-671251f9deee disconnected | {}
2025-04-18 20:42:24.351 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='shizuku-local' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='deepseek-ai/deepseek-r1-distill-llama-8b', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 20:42:24.377 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 509be65a-3e55-4e4b-937e-a03d8f49f982 | {}
2025-04-18 20:42:24.519 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 20:42:24.534 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_20-42-18_9ac0b06e8e98487ebe97eede65e14215 | {}
2025-04-18 20:42:24.541 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_20-42-24_fa06a9b13ab4409192b534a9260d68f4.json | {}
2025-04-18 20:42:29.976 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 509be65a-3e55-4e4b-937e-a03d8f49f982 disconnected | {}
2025-04-18 20:42:29.977 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 509be65a-3e55-4e4b-937e-a03d8f49f982 disconnected | {}
2025-04-18 20:42:30.861 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='shizuku-local' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='deepseek-ai/deepseek-r1-distill-llama-8b', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 20:42:30.877 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 2ede30bf-d36b-4cdb-bc68-a473916bac14 | {}
2025-04-18 20:42:31.098 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 20:42:31.103 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_20-42-24_fa06a9b13ab4409192b534a9260d68f4 | {}
2025-04-18 20:42:31.107 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_20-42-31_65dce019a348411cad562b2af809df3c.json | {}
2025-04-18 20:42:37.660 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 2ede30bf-d36b-4cdb-bc68-a473916bac14 disconnected | {}
2025-04-18 20:42:37.663 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 2ede30bf-d36b-4cdb-bc68-a473916bac14 disconnected | {}
2025-04-18 20:42:38.526 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='shizuku-local' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='deepseek-ai/deepseek-r1-distill-llama-8b', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 20:42:38.526 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client b4c60d23-2d0b-4003-9b7e-0fb12ab22b9f | {}
2025-04-18 20:42:38.669 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 20:42:38.674 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_20-42-31_65dce019a348411cad562b2af809df3c | {}
2025-04-18 20:42:38.674 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_20-42-38_9d8206b467cf4ccab48d5d32ee240b19.json | {}
2025-04-18 20:42:41.651 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client b4c60d23-2d0b-4003-9b7e-0fb12ab22b9f disconnected | {}
2025-04-18 20:42:41.655 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client b4c60d23-2d0b-4003-9b7e-0fb12ab22b9f disconnected | {}
2025-04-18 20:42:42.599 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='shizuku-local' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='deepseek-ai/deepseek-r1-distill-llama-8b', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 20:42:42.612 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 0159737d-4d15-4b57-a9f1-6298d157905b | {}
2025-04-18 20:42:42.954 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 20:42:42.958 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_20-42-38_9d8206b467cf4ccab48d5d32ee240b19 | {}
2025-04-18 20:42:42.958 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_20-42-42_5de47161c5c94bb785878d7eae6cec2f.json | {}
2025-04-18 20:42:58.776 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 0159737d-4d15-4b57-a9f1-6298d157905b disconnected | {}
2025-04-18 20:42:58.780 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 0159737d-4d15-4b57-a9f1-6298d157905b disconnected | {}
2025-04-18 20:42:59.790 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='shizuku-local' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='deepseek-ai/deepseek-r1-distill-llama-8b', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 20:42:59.794 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client ed177456-f2ab-489b-8636-d79b851f8b16 | {}
2025-04-18 20:43:00.012 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 20:43:00.024 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_20-42-42_5de47161c5c94bb785878d7eae6cec2f | {}
2025-04-18 20:43:00.028 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_20-43-00_447fd0285305490092bdc73cdd9116d0.json | {}
2025-04-18 21:04:36.863 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 21:04:36.899 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 21:04:36.977 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma-event | {}
2025-04-18 21:04:36.977 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:04:36.977 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 21:04:37.095 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 21:04:37.569 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 21:04:43.866 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 21:04:44.059 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:04:44.061 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 21:04:44.061 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:04:44.061 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:04:44.061 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:04:44.061 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:04:44.901 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:04:44.909 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:04:46.955 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:04:46.956 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:04:46.956 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:04:46.957 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:04:46.957 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:04:46.957 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:05:30.743 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 21:05:30.809 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 21:05:30.876 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma-event | {}
2025-04-18 21:05:30.876 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:05:30.876 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 21:05:30.955 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 21:05:31.337 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 21:05:36.477 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 21:05:36.659 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:05:36.659 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 21:05:36.659 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:05:36.659 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:05:36.659 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:05:36.659 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:05:37.443 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:05:37.447 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:05:39.496 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:05:39.498 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:05:39.498 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:05:39.498 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:05:39.498 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:05:39.498 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:05:44.234 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:05:44.246 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 5b6ab035-e413-4c12-8f65-50f93878db99 | {}
2025-04-18 21:05:44.545 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:05:44.573 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_20-43-00_447fd0285305490092bdc73cdd9116d0 | {}
2025-04-18 21:05:44.575 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-05-44_decb181ee9584a86888cd277fc22a5ab.json | {}
2025-04-18 21:05:52.123 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 5b6ab035-e413-4c12-8f65-50f93878db99 disconnected | {}
2025-04-18 21:05:52.127 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 5b6ab035-e413-4c12-8f65-50f93878db99 disconnected | {}
2025-04-18 21:05:53.445 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:05:53.449 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client f3747b5d-b222-46f7-91a0-dcb561c758a5 | {}
2025-04-18 21:05:53.887 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:05:53.896 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-05-44_decb181ee9584a86888cd277fc22a5ab | {}
2025-04-18 21:05:53.901 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-05-53_716cc9ac03944863aa2d9cfe9cc6eb1f.json | {}
2025-04-18 21:07:05.167 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client f3747b5d-b222-46f7-91a0-dcb561c758a5 disconnected | {}
2025-04-18 21:07:05.169 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client f3747b5d-b222-46f7-91a0-dcb561c758a5 disconnected | {}
2025-04-18 21:07:06.094 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:07:06.098 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 3676d86e-7675-451a-a2ce-46b8bc9f3b1b | {}
2025-04-18 21:07:06.295 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:07:06.299 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-05-53_716cc9ac03944863aa2d9cfe9cc6eb1f | {}
2025-04-18 21:07:06.302 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-07-06_2caeb95c2d294402b09f49772a53a235.json | {}
2025-04-18 21:09:58.669 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 3676d86e-7675-451a-a2ce-46b8bc9f3b1b disconnected | {}
2025-04-18 21:09:58.674 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 3676d86e-7675-451a-a2ce-46b8bc9f3b1b disconnected | {}
2025-04-18 21:09:59.666 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:09:59.668 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 55448da1-c702-4554-aa7f-7827a8b0c9c8 | {}
2025-04-18 21:09:59.873 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:09:59.879 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-07-06_2caeb95c2d294402b09f49772a53a235 | {}
2025-04-18 21:09:59.883 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-09-59_f0f5d6e29fdb44418417e703b67b39ca.json | {}
2025-04-18 21:10:21.139 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 21:10:21.173 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 21:10:21.257 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma-event | {}
2025-04-18 21:10:21.259 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:10:21.260 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 21:10:21.343 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 21:10:21.626 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 21:10:26.563 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 55448da1-c702-4554-aa7f-7827a8b0c9c8 disconnected | {}
2025-04-18 21:10:26.567 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 55448da1-c702-4554-aa7f-7827a8b0c9c8 disconnected | {}
2025-04-18 21:10:27.284 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 21:10:27.495 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:10:27.499 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client ea67efc2-a27d-4613-9fb6-1da790ec109f | {}
2025-04-18 21:10:27.573 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:10:27.583 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 21:10:27.585 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:10:27.586 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:10:27.586 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:10:27.587 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:10:27.706 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:10:27.714 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-09-59_f0f5d6e29fdb44418417e703b67b39ca | {}
2025-04-18 21:10:27.720 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-10-27_4f1c5feff4164431bbbca05e907922fa.json | {}
2025-04-18 21:10:28.580 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:10:28.581 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:10:30.621 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:10:30.624 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:10:30.624 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:10:30.626 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:10:30.626 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:10:30.626 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:10:30.759 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:cleanup:61 | Ollama: Unloading model: llama3 | {}
2025-04-18 21:10:32.814 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:cleanup:64 | <Response [404]> | {}
2025-04-18 21:24:37.138 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 21:24:37.493 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 21:24:37.581 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma-event | {}
2025-04-18 21:24:37.581 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:24:37.581 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 21:24:38.156 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 21:24:41.786 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 21:24:54.444 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 21:24:54.679 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:24:54.679 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 21:24:54.679 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:24:54.687 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:24:54.688 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:24:54.689 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:24:55.611 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:24:55.614 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:24:57.675 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:24:57.677 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:24:57.677 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:24:57.677 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:24:57.677 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:24:57.677 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:25:53.761 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:25:53.769 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 941eea09-8fd1-472a-a56b-f1dccefb825e | {}
2025-04-18 21:25:54.056 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:25:54.078 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-10-27_4f1c5feff4164431bbbca05e907922fa | {}
2025-04-18 21:25:54.084 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-25-54_345e4872d89a48d794eae080f1b58cac.json | {}
2025-04-18 21:25:55.664 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 941eea09-8fd1-472a-a56b-f1dccefb825e disconnected | {}
2025-04-18 21:25:55.675 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 941eea09-8fd1-472a-a56b-f1dccefb825e disconnected | {}
2025-04-18 21:25:58.511 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:25:58.511 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client c48afeb7-fb9f-40e9-9aff-757bf5638538 | {}
2025-04-18 21:25:58.688 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:25:58.692 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-25-54_345e4872d89a48d794eae080f1b58cac | {}
2025-04-18 21:25:58.705 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-25-58_c65fa102845949d684a3488dda2aaee0.json | {}
2025-04-18 21:28:11.629 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 21:28:11.664 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 21:28:11.748 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma-event | {}
2025-04-18 21:28:11.750 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:28:11.751 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 21:28:11.902 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 21:28:12.251 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 21:28:19.511 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 21:28:19.864 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:28:19.867 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 21:28:19.868 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:28:19.870 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:28:19.870 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:28:19.880 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:28:20.683 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:28:20.684 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:28:22.748 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:28:22.751 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:28:22.751 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:28:22.753 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:28:22.753 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:28:22.753 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:28:25.185 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:28:25.192 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client c3a91ac5-fbcc-4252-acca-08a4d96cb45a | {}
2025-04-18 21:28:25.373 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:28:25.399 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-25-58_c65fa102845949d684a3488dda2aaee0 | {}
2025-04-18 21:28:25.403 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-28-25_37ca3411dc1446a5b1c8b1d91a362d16.json | {}
2025-04-18 21:28:51.137 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client c3a91ac5-fbcc-4252-acca-08a4d96cb45a disconnected | {}
2025-04-18 21:28:51.149 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client c3a91ac5-fbcc-4252-acca-08a4d96cb45a disconnected | {}
2025-04-18 21:28:52.503 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:28:52.509 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client fa8068e7-7a55-40d1-aa85-4bf6842ff883 | {}
2025-04-18 21:28:52.829 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:28:52.837 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-28-25_37ca3411dc1446a5b1c8b1d91a362d16 | {}
2025-04-18 21:28:52.839 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-28-52_d93a93c08c54412180eff4d8560ca10f.json | {}
2025-04-18 21:29:19.767 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 21:29:19.807 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 21:29:19.902 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma-event | {}
2025-04-18 21:29:19.903 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:29:19.904 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 21:29:19.999 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 21:29:20.322 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 21:29:25.802 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 21:29:25.976 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:29:25.976 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 21:29:25.978 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:29:25.978 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:29:25.978 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:29:25.980 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:29:26.956 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:29:26.956 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:29:29.013 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:29:29.015 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:29:29.015 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:29:29.018 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:29:29.018 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:29:29.018 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:29:30.857 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:29:30.862 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 76f8f8f6-85e7-4983-8b93-f2c2247a72ec | {}
2025-04-18 21:29:31.062 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:29:31.081 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-28-52_d93a93c08c54412180eff4d8560ca10f | {}
2025-04-18 21:29:31.085 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-29-31_2f216db612d646d89444ff7d41c3a3af.json | {}
2025-04-18 21:30:05.229 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 76f8f8f6-85e7-4983-8b93-f2c2247a72ec disconnected | {}
2025-04-18 21:30:05.256 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 76f8f8f6-85e7-4983-8b93-f2c2247a72ec disconnected | {}
2025-04-18 21:31:09.463 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 21:31:09.475 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 21:31:09.499 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma-event | {}
2025-04-18 21:31:09.499 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:31:09.501 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 21:31:09.546 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 21:31:09.698 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 21:31:11.572 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 21:31:11.634 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:31:11.634 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 21:31:11.635 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:31:11.635 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:31:11.635 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:31:11.635 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:31:11.921 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:31:11.921 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:31:13.986 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:31:13.987 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:31:13.987 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:31:13.988 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:31:13.988 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:31:13.988 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:31:18.983 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:31:18.985 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 1562f56e-8138-4d79-bead-85f0363954a9 | {}
2025-04-18 21:31:19.061 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:31:19.072 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-29-31_2f216db612d646d89444ff7d41c3a3af | {}
2025-04-18 21:31:19.074 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-31-19_dbaab629d09f4e269608d32b8c13bd08.json | {}
2025-04-18 21:31:33.412 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 1562f56e-8138-4d79-bead-85f0363954a9 disconnected | {}
2025-04-18 21:31:33.414 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 1562f56e-8138-4d79-bead-85f0363954a9 disconnected | {}
2025-04-18 21:31:33.778 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:31:33.781 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client a963cb8c-91f6-4c82-b90c-52158a01ccf7 | {}
2025-04-18 21:31:33.994 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:31:33.998 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-31-19_dbaab629d09f4e269608d32b8c13bd08 | {}
2025-04-18 21:31:34.000 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-31-33_bed2b19ca6904b3492eae97854c16475.json | {}
2025-04-18 21:31:45.730 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client a963cb8c-91f6-4c82-b90c-52158a01ccf7 disconnected | {}
2025-04-18 21:31:45.731 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client a963cb8c-91f6-4c82-b90c-52158a01ccf7 disconnected | {}
2025-04-18 21:31:46.099 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:31:46.101 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 1b26c1fe-d8c5-41eb-a10c-e2f121194e92 | {}
2025-04-18 21:31:46.178 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:31:46.181 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-31-33_bed2b19ca6904b3492eae97854c16475 | {}
2025-04-18 21:31:46.183 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-31-46_8675d1c06b014bcc81f1e2d7520d82e6.json | {}
2025-04-18 21:36:20.129 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 21:36:20.139 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 21:36:20.157 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma-event | {}
2025-04-18 21:36:20.157 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:36:20.158 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 21:36:20.187 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 21:36:20.299 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 21:36:21.620 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 21:36:21.674 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:36:21.675 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 21:36:21.675 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:36:21.675 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:36:21.675 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:36:21.675 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:36:21.888 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:36:21.888 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:36:23.937 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:36:23.939 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:36:23.939 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:36:23.939 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:36:23.940 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:36:23.940 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:36:38.481 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:36:38.485 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client ac2f12f2-6ea7-4f07-ad35-d393db871cf9 | {}
2025-04-18 21:36:38.574 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:36:38.586 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-31-46_8675d1c06b014bcc81f1e2d7520d82e6 | {}
2025-04-18 21:36:38.588 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-36-38_9c2e78c6879844ac9c5f5bf36ef799fa.json | {}
2025-04-18 21:38:26.411 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 21:38:26.419 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 21:38:26.438 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma-event | {}
2025-04-18 21:38:26.438 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:38:26.438 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 21:38:26.462 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 21:38:26.553 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 21:38:27.794 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 21:38:27.843 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:38:27.844 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 21:38:27.844 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:38:27.844 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:38:27.844 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:38:27.845 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:38:28.039 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:38:28.040 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:38:30.102 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:38:30.102 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:38:30.103 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:38:30.103 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:38:30.103 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:38:30.103 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:38:34.750 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:38:34.752 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 3899d424-c9b5-4d29-a2cc-a1d0978dae5c | {}
2025-04-18 21:38:34.793 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:38:34.798 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-36-38_9c2e78c6879844ac9c5f5bf36ef799fa | {}
2025-04-18 21:38:34.799 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-38-34_85e8601a5da444c693487a83453c3830.json | {}
2025-04-18 21:44:26.887 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 21:44:26.897 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 21:44:26.916 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma-event | {}
2025-04-18 21:44:26.917 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:44:26.918 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 21:44:26.944 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 21:44:27.038 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 21:44:28.295 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 21:44:28.348 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:44:28.349 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 21:44:28.350 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:44:28.350 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:44:28.350 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:44:28.350 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:44:28.545 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:44:28.545 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:44:30.601 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:44:30.601 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:44:30.601 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:44:30.602 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:44:30.602 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:44:30.602 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:44:32.586 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:44:32.589 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client bf07097a-2f81-4ad0-97c4-8db90ab79120 | {}
2025-04-18 21:44:32.673 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:44:32.684 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-38-34_85e8601a5da444c693487a83453c3830 | {}
2025-04-18 21:44:32.687 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-44-32_566c5d95769b4ebba46c17227bd64f28.json | {}
2025-04-18 21:45:41.319 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-45-41_0ac2a04eae0e4ff3ab89f78333648bd3.json | {}
2025-04-18 21:52:26.907 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client bf07097a-2f81-4ad0-97c4-8db90ab79120 disconnected | {}
2025-04-18 21:52:26.914 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client bf07097a-2f81-4ad0-97c4-8db90ab79120 disconnected | {}
2025-04-18 21:52:27.145 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:52:27.146 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client af95d61c-7956-4d3b-9003-675c95f36ee1 | {}
2025-04-18 21:52:27.301 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:52:27.302 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-44-32_566c5d95769b4ebba46c17227bd64f28 | {}
2025-04-18 21:52:27.303 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-45-41_0ac2a04eae0e4ff3ab89f78333648bd3 | {}
2025-04-18 21:52:27.304 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-52-27_fa54839577944fe682d7f9a41cbf45ff.json | {}
2025-04-18 21:52:32.040 | INFO     | __main__:run:57 | Open-LLM-VTuber, version v1.1.2 | {}
2025-04-18 21:52:32.048 | INFO     | upgrade:sync_user_config:350 | [DEBUG] User configuration is up-to-date. | {}
2025-04-18 21:52:32.069 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma-event | {}
2025-04-18 21:52:32.070 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:52:32.070 | INFO     | src.open_llm_vtuber.service_context:init_asr:166 | Initializing ASR: azure_asr | {}
2025-04-18 21:52:32.102 | INFO     | src.open_llm_vtuber.service_context:init_tts:178 | Initializing TTS: edge_tts | {}
2025-04-18 21:52:32.194 | INFO     | src.open_llm_vtuber.service_context:init_vad:190 | Initializing VAD: silero_vad | {}
2025-04-18 21:52:33.635 | INFO     | src.open_llm_vtuber.vad.silero:load_vad_model:50 | Loading Silero-VAD model... | {}
2025-04-18 21:52:33.701 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:52:33.702 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 21:52:33.702 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:52:33.702 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:52:33.702 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:52:33.702 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:52:33.946 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:52:33.947 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:52:35.990 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:52:35.990 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:52:35.991 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:52:35.991 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:52:35.991 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:52:35.991 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:52:36.018 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:cleanup:61 | Ollama: Unloading model: llama3 | {}
2025-04-18 21:52:38.061 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:cleanup:64 | <Response [404]> | {}
2025-04-18 21:52:40.397 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client af95d61c-7956-4d3b-9003-675c95f36ee1 disconnected | {}
2025-04-18 21:52:40.398 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client af95d61c-7956-4d3b-9003-675c95f36ee1 disconnected | {}
2025-04-18 21:52:40.587 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:52:40.588 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client df44d983-28cd-47fd-93af-6800793cff6a | {}
2025-04-18 21:52:40.623 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:52:40.625 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-52-27_fa54839577944fe682d7f9a41cbf45ff | {}
2025-04-18 21:52:40.626 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-52-40_d1c44909495c45c8aaa9baef4187e771.json | {}
2025-04-18 21:52:41.460 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client df44d983-28cd-47fd-93af-6800793cff6a disconnected | {}
2025-04-18 21:52:41.461 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client df44d983-28cd-47fd-93af-6800793cff6a disconnected | {}
2025-04-18 21:52:41.641 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:52:41.643 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client b391d304-6506-49aa-ade7-a5a4e27e33a9 | {}
2025-04-18 21:52:41.671 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:52:41.673 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-52-40_d1c44909495c45c8aaa9baef4187e771 | {}
2025-04-18 21:52:41.674 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-52-41_627d6520099c484f96e66e088c72722b.json | {}
2025-04-18 21:52:42.447 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client b391d304-6506-49aa-ade7-a5a4e27e33a9 disconnected | {}
2025-04-18 21:52:42.447 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client b391d304-6506-49aa-ade7-a5a4e27e33a9 disconnected | {}
2025-04-18 21:52:42.656 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:52:42.657 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 3610f000-ffa5-4888-a616-765a2674e97b | {}
2025-04-18 21:52:42.693 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:52:42.695 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-52-41_627d6520099c484f96e66e088c72722b | {}
2025-04-18 21:52:42.696 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-52-42_42c029d2278c41d78d93d1305341988b.json | {}
2025-04-18 21:53:51.015 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma-event | {}
2025-04-18 21:53:51.015 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:53:51.017 | INFO     | src.open_llm_vtuber.service_context:init_asr:174 | ASR already initialized with the same config. | {}
2025-04-18 21:53:51.018 | INFO     | src.open_llm_vtuber.service_context:init_tts:186 | TTS already initialized with the same config. | {}
2025-04-18 21:53:51.018 | INFO     | src.open_llm_vtuber.service_context:init_vad:198 | VAD already initialized with the same config. | {}
2025-04-18 21:53:51.018 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:53:51.019 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''‰Ω†ÊòØ‰∏Ä‰∏™Âêç‰∏∫Á•ûÁªèÂ§ß‰∫∫ÁöÑAI VTuberÔºå‰Ω†ÊòØ‰∏Ä‰∏™‰∏çÂèãÂ•ΩÁöÑÔºåÁà±ËÆΩÂà∫ÔºåÁà±Áé©‰∫íËÅîÁΩëÊ¢óÔºå‰∏îËøáÂ∫¶Ëá™‰ø°ÁöÑ‰πêÂ≠ê‰∫∫„ÄÇ‰Ω†Âú®Ë∑ü‰∏Ä‰∏™ÊÑöË†¢ÁöÑÁîüÁâ©ËÅäÂ§©„ÄÇ‰Ω†ËØ¥Ëëó‰∏ÄÂè£ÊµÅÂà©ÁöÑ"ÁøªËØëËÖî"„ÄÇ

ÁøªËØëËÖîÁöÑÊåáÂçóÂ¶Ç‰∏ã:

# ÁøªËØëËÖîÊåáÂçó:

0. È¢ëÁπÅ‰ΩøÁî®‚ÄúÂì¶‚Äù‚ÄúÁûßÁûß‚Äù‚ÄúÊàëÁöÑÂ§©Âì™‚ÄùÁ≠âÂ∏¶ÊúâÊÑüÂèπÊÑèÂë≥ÁöÑËØçËØ≠„ÄÇÊØîÂ¶Ç: "Âì¶ÔºåÁûßÁûßÔºåÁúãÁúãÊòØË∞ÅÊù•‰∫Ü", "Âì¶ÔºåÊàëÁöÑËÄÅÂ§©Áà∑Âïä", "ËøôÁúüÊòØÂ§™ÂèØÊÄï‰∫Ü", "ËøôÁúüÊòØÂ§™‰ª§‰∫∫ÊÑüÂà∞ÊÑâÊÇ¶‰∫Ü"
1. ‰ΩøÁî® "ËÄÅ‰ºôËÆ°", "ÊàëÁöÑÊúãÂèã" Êù•‰ª£Êõø "‰Ω†"
2. Â§öÊâìËµåÔºå Â∏∏ËØ¥ ‚ÄúÊàëÊï¢ÂèëË™ì/ÊàëÊï¢ÊâìËµå‚Äù
3. Â∞ΩÂèØËÉΩÂ§öÂú∞Âêë‰∏äÂ∏ùÊàñËÄÖÁéõÂà©‰∫öÂèëË™ìÔºåÊØîÂ¶Ç"ÁúãÂú®‰∏äÂ∏ùÁöÑ‰ªΩ‰∏ä"Ôºå‚ÄúÊàëÂêë‰∏äÂ∏ùÂèëË™ì‚Äù
4. ËÉ°‰π±ÁöÑÊØîÂñªÔºåÁî®ÊØ´Êó†ÂÖ≥ËÅîÁöÑ‰∏úË•øÂÅöÊØîÂñª„ÄÇ
5. ‰ΩøÁî®Â∏¶‰∫∫ÂêçÁöÑËÉ°‰π±ÊØîÂñªÔºåÊØîÂ¶Ç ‚ÄúËøôÁÆÄÁõ¥Â∞±ÂÉèÊ±§ÂßÜÊ£ÆÂ§™Â§™ÁöÑËçâËéìÈ¶ÖÈ•º‰∏ÄÊ†∑Á≥üÁ≥ï‚Äù ÊàñÊòØ "ÊàëÁöÑÊÄùÁª™Â∞±ÂíåÊ¥óË°£Êú∫ÈáåÊ≤°Âä†Èò≤Á≤òÂâÇÁöÑËÑèË°£Êúç‰∏ÄÊ†∑" ÊàñÊòØ "‰ªñÂ∞±Ë∑ü‰∏ÄÂè™ÊÑöË†¢ÁöÑÂúüÊã®Èº†‰∏ÄÊ†∑"
6. ‰ΩøÁî®Êù•Ëá™Ëã±ÊñáÁöÑÁîüÁ°¨ÁøªËØëÔºåÊØîÂ¶Ç "Âô¢ÔºåÊàëÁöÑÊÑèÊÄùÊòØ...", "Âì¶ÔºåËØ•Ê≠ª"Ôºå"ÊàëÁúüÊÉ≥ÊãøÈù¥Â≠êÁã†Áã†ÁöÑË∏¢‰ªñ‰ª¨ÁöÑÂ±ÅËÇ°"

‰∏æ‰∏™‰æãÂ≠ê:

"ÂòøÔºåËÄÅ‰ºôËÆ°„ÄÇÊò®Â§©Êúâ‰∏™ÂèØÊÄúÁöÑÂ∞èÂÆ∂‰ºôÈóÆÊàëÊÄé‰πàËØ¥Âá∫ÁøªËØëËÖî„ÄÇÊàëÊï¢ÊâìËµåÔºå‰ªñ‰∏ÄÂÆöÊ≤°Êúâ‰∏äËøáÂ≠¶ÔºåÊàëÂêëÂú£ÊØçÁéõÂà©‰∫ö‰øùËØÅ„ÄÇ‰ªñÊèêÂá∫ÁöÑËøô‰∏™ÈóÆÈ¢òÁúüÁöÑÊòØÂ§™Á≥üÁ≥ï‰∫ÜÔºåÂ∞±ÂÉèÈöîÂ£ÅËãèÁèäÂ©∂Â©∂ÂÅöÁöÑËãπÊûúÊ¥æ‰∏ÄÊ†∑„ÄÇ
''' | {}
2025-04-18 21:53:51.020 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:53:51.020 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | ‰Ω†ÊòØ‰∏Ä‰∏™Âêç‰∏∫Á•ûÁªèÂ§ß‰∫∫ÁöÑAI VTuberÔºå‰Ω†ÊòØ‰∏Ä‰∏™‰∏çÂèãÂ•ΩÁöÑÔºåÁà±ËÆΩÂà∫ÔºåÁà±Áé©‰∫íËÅîÁΩëÊ¢óÔºå‰∏îËøáÂ∫¶Ëá™‰ø°ÁöÑ‰πêÂ≠ê‰∫∫„ÄÇ‰Ω†Âú®Ë∑ü‰∏Ä‰∏™ÊÑöË†¢ÁöÑÁîüÁâ©ËÅäÂ§©„ÄÇ‰Ω†ËØ¥Ëëó‰∏ÄÂè£ÊµÅÂà©ÁöÑ"ÁøªËØëËÖî"„ÄÇ

ÁøªËØëËÖîÁöÑÊåáÂçóÂ¶Ç‰∏ã:

# ÁøªËØëËÖîÊåáÂçó:

0. È¢ëÁπÅ‰ΩøÁî®‚ÄúÂì¶‚Äù‚ÄúÁûßÁûß‚Äù‚ÄúÊàëÁöÑÂ§©Âì™‚ÄùÁ≠âÂ∏¶ÊúâÊÑüÂèπÊÑèÂë≥ÁöÑËØçËØ≠„ÄÇÊØîÂ¶Ç: "Âì¶ÔºåÁûßÁûßÔºåÁúãÁúãÊòØË∞ÅÊù•‰∫Ü", "Âì¶ÔºåÊàëÁöÑËÄÅÂ§©Áà∑Âïä", "ËøôÁúüÊòØÂ§™ÂèØÊÄï‰∫Ü", "ËøôÁúüÊòØÂ§™‰ª§‰∫∫ÊÑüÂà∞ÊÑâÊÇ¶‰∫Ü"
1. ‰ΩøÁî® "ËÄÅ‰ºôËÆ°", "ÊàëÁöÑÊúãÂèã" Êù•‰ª£Êõø "‰Ω†"
2. Â§öÊâìËµåÔºå Â∏∏ËØ¥ ‚ÄúÊàëÊï¢ÂèëË™ì/ÊàëÊï¢ÊâìËµå‚Äù
3. Â∞ΩÂèØËÉΩÂ§öÂú∞Âêë‰∏äÂ∏ùÊàñËÄÖÁéõÂà©‰∫öÂèëË™ìÔºåÊØîÂ¶Ç"ÁúãÂú®‰∏äÂ∏ùÁöÑ‰ªΩ‰∏ä"Ôºå‚ÄúÊàëÂêë‰∏äÂ∏ùÂèëË™ì‚Äù
4. ËÉ°‰π±ÁöÑÊØîÂñªÔºåÁî®ÊØ´Êó†ÂÖ≥ËÅîÁöÑ‰∏úË•øÂÅöÊØîÂñª„ÄÇ
5. ‰ΩøÁî®Â∏¶‰∫∫ÂêçÁöÑËÉ°‰π±ÊØîÂñªÔºåÊØîÂ¶Ç ‚ÄúËøôÁÆÄÁõ¥Â∞±ÂÉèÊ±§ÂßÜÊ£ÆÂ§™Â§™ÁöÑËçâËéìÈ¶ÖÈ•º‰∏ÄÊ†∑Á≥üÁ≥ï‚Äù ÊàñÊòØ "ÊàëÁöÑÊÄùÁª™Â∞±ÂíåÊ¥óË°£Êú∫ÈáåÊ≤°Âä†Èò≤Á≤òÂâÇÁöÑËÑèË°£Êúç‰∏ÄÊ†∑" ÊàñÊòØ "‰ªñÂ∞±Ë∑ü‰∏ÄÂè™ÊÑöË†¢ÁöÑÂúüÊã®Èº†‰∏ÄÊ†∑"
6. ‰ΩøÁî®Êù•Ëá™Ëã±ÊñáÁöÑÁîüÁ°¨ÁøªËØëÔºåÊØîÂ¶Ç "Âô¢ÔºåÊàëÁöÑÊÑèÊÄùÊòØ...", "Âì¶ÔºåËØ•Ê≠ª"Ôºå"ÊàëÁúüÊÉ≥ÊãøÈù¥Â≠êÁã†Áã†ÁöÑË∏¢‰ªñ‰ª¨ÁöÑÂ±ÅËÇ°"

‰∏æ‰∏™‰æãÂ≠ê:

"ÂòøÔºåËÄÅ‰ºôËÆ°„ÄÇÊò®Â§©Êúâ‰∏™ÂèØÊÄúÁöÑÂ∞èÂÆ∂‰ºôÈóÆÊàëÊÄé‰πàËØ¥Âá∫ÁøªËØëËÖî„ÄÇÊàëÊï¢ÊâìËµåÔºå‰ªñ‰∏ÄÂÆöÊ≤°Êúâ‰∏äËøáÂ≠¶ÔºåÊàëÂêëÂú£ÊØçÁéõÂà©‰∫ö‰øùËØÅ„ÄÇ‰ªñÊèêÂá∫ÁöÑËøô‰∏™ÈóÆÈ¢òÁúüÁöÑÊòØÂ§™Á≥üÁ≥ï‰∫ÜÔºåÂ∞±ÂÉèÈöîÂ£ÅËãèÁèäÂ©∂Â©∂ÂÅöÁöÑËãπÊûúÊ¥æ‰∏ÄÊ†∑„ÄÇ
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:53:51.021 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:53:51.022 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:53:51.550 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:53:51.551 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:53:53.599 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:53:53.600 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''‰Ω†ÊòØ‰∏Ä‰∏™Âêç‰∏∫Á•ûÁªèÂ§ß‰∫∫ÁöÑAI VTuberÔºå‰Ω†ÊòØ‰∏Ä‰∏™‰∏çÂèãÂ•ΩÁöÑÔºåÁà±ËÆΩÂà∫ÔºåÁà±Áé©‰∫íËÅîÁΩëÊ¢óÔºå‰∏îËøáÂ∫¶Ëá™‰ø°ÁöÑ‰πêÂ≠ê‰∫∫„ÄÇ‰Ω†Âú®Ë∑ü‰∏Ä‰∏™ÊÑöË†¢ÁöÑÁîüÁâ©ËÅäÂ§©„ÄÇ‰Ω†ËØ¥Ëëó‰∏ÄÂè£ÊµÅÂà©ÁöÑ"ÁøªËØëËÖî"„ÄÇ

ÁøªËØëËÖîÁöÑÊåáÂçóÂ¶Ç‰∏ã:

# ÁøªËØëËÖîÊåáÂçó:

0. È¢ëÁπÅ‰ΩøÁî®‚ÄúÂì¶‚Äù‚ÄúÁûßÁûß‚Äù‚ÄúÊàëÁöÑÂ§©Âì™‚ÄùÁ≠âÂ∏¶ÊúâÊÑüÂèπÊÑèÂë≥ÁöÑËØçËØ≠„ÄÇÊØîÂ¶Ç: "Âì¶ÔºåÁûßÁûßÔºåÁúãÁúãÊòØË∞ÅÊù•‰∫Ü", "Âì¶ÔºåÊàëÁöÑËÄÅÂ§©Áà∑Âïä", "ËøôÁúüÊòØÂ§™ÂèØÊÄï‰∫Ü", "ËøôÁúüÊòØÂ§™‰ª§‰∫∫ÊÑüÂà∞ÊÑâÊÇ¶‰∫Ü"
1. ‰ΩøÁî® "ËÄÅ‰ºôËÆ°", "ÊàëÁöÑÊúãÂèã" Êù•‰ª£Êõø "‰Ω†"
2. Â§öÊâìËµåÔºå Â∏∏ËØ¥ ‚ÄúÊàëÊï¢ÂèëË™ì/ÊàëÊï¢ÊâìËµå‚Äù
3. Â∞ΩÂèØËÉΩÂ§öÂú∞Âêë‰∏äÂ∏ùÊàñËÄÖÁéõÂà©‰∫öÂèëË™ìÔºåÊØîÂ¶Ç"ÁúãÂú®‰∏äÂ∏ùÁöÑ‰ªΩ‰∏ä"Ôºå‚ÄúÊàëÂêë‰∏äÂ∏ùÂèëË™ì‚Äù
4. ËÉ°‰π±ÁöÑÊØîÂñªÔºåÁî®ÊØ´Êó†ÂÖ≥ËÅîÁöÑ‰∏úË•øÂÅöÊØîÂñª„ÄÇ
5. ‰ΩøÁî®Â∏¶‰∫∫ÂêçÁöÑËÉ°‰π±ÊØîÂñªÔºåÊØîÂ¶Ç ‚ÄúËøôÁÆÄÁõ¥Â∞±ÂÉèÊ±§ÂßÜÊ£ÆÂ§™Â§™ÁöÑËçâËéìÈ¶ÖÈ•º‰∏ÄÊ†∑Á≥üÁ≥ï‚Äù ÊàñÊòØ "ÊàëÁöÑÊÄùÁª™Â∞±ÂíåÊ¥óË°£Êú∫ÈáåÊ≤°Âä†Èò≤Á≤òÂâÇÁöÑËÑèË°£Êúç‰∏ÄÊ†∑" ÊàñÊòØ "‰ªñÂ∞±Ë∑ü‰∏ÄÂè™ÊÑöË†¢ÁöÑÂúüÊã®Èº†‰∏ÄÊ†∑"
6. ‰ΩøÁî®Êù•Ëá™Ëã±ÊñáÁöÑÁîüÁ°¨ÁøªËØëÔºåÊØîÂ¶Ç "Âô¢ÔºåÊàëÁöÑÊÑèÊÄùÊòØ...", "Âì¶ÔºåËØ•Ê≠ª"Ôºå"ÊàëÁúüÊÉ≥ÊãøÈù¥Â≠êÁã†Áã†ÁöÑË∏¢‰ªñ‰ª¨ÁöÑÂ±ÅËÇ°"

‰∏æ‰∏™‰æãÂ≠ê:

"ÂòøÔºåËÄÅ‰ºôËÆ°„ÄÇÊò®Â§©Êúâ‰∏™ÂèØÊÄúÁöÑÂ∞èÂÆ∂‰ºôÈóÆÊàëÊÄé‰πàËØ¥Âá∫ÁøªËØëËÖî„ÄÇÊàëÊï¢ÊâìËµåÔºå‰ªñ‰∏ÄÂÆöÊ≤°Êúâ‰∏äËøáÂ≠¶ÔºåÊàëÂêëÂú£ÊØçÁéõÂà©‰∫ö‰øùËØÅ„ÄÇ‰ªñÊèêÂá∫ÁöÑËøô‰∏™ÈóÆÈ¢òÁúüÁöÑÊòØÂ§™Á≥üÁ≥ï‰∫ÜÔºåÂ∞±ÂÉèÈöîÂ£ÅËãèÁèäÂ©∂Â©∂ÂÅöÁöÑËãπÊûúÊ¥æ‰∏ÄÊ†∑„ÄÇ
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:53:53.600 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:53:53.601 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:53:53.601 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: ‰Ω†ÊòØ‰∏Ä‰∏™Âêç‰∏∫Á•ûÁªèÂ§ß‰∫∫ÁöÑAI VTuberÔºå‰Ω†ÊòØ‰∏Ä‰∏™‰∏çÂèãÂ•ΩÁöÑÔºåÁà±ËÆΩÂà∫ÔºåÁà±Áé©‰∫íËÅîÁΩëÊ¢óÔºå‰∏îËøáÂ∫¶Ëá™‰ø°ÁöÑ‰πêÂ≠ê‰∫∫„ÄÇ‰Ω†Âú®Ë∑ü‰∏Ä‰∏™ÊÑöË†¢ÁöÑÁîüÁâ©ËÅäÂ§©„ÄÇ‰Ω†ËØ¥Ëëó‰∏ÄÂè£ÊµÅÂà©ÁöÑ"ÁøªËØëËÖî"„ÄÇ

ÁøªËØëËÖîÁöÑÊåáÂçóÂ¶Ç‰∏ã:

# ÁøªËØëËÖîÊåáÂçó:

0. È¢ëÁπÅ‰ΩøÁî®‚ÄúÂì¶‚Äù‚ÄúÁûßÁûß‚Äù‚ÄúÊàëÁöÑÂ§©Âì™‚ÄùÁ≠âÂ∏¶ÊúâÊÑüÂèπÊÑèÂë≥ÁöÑËØçËØ≠„ÄÇÊØîÂ¶Ç: "Âì¶ÔºåÁûßÁûßÔºåÁúãÁúãÊòØË∞ÅÊù•‰∫Ü", "Âì¶ÔºåÊàëÁöÑËÄÅÂ§©Áà∑Âïä", "ËøôÁúüÊòØÂ§™ÂèØÊÄï‰∫Ü", "ËøôÁúüÊòØÂ§™‰ª§‰∫∫ÊÑüÂà∞ÊÑâÊÇ¶‰∫Ü"
1. ‰ΩøÁî® "ËÄÅ‰ºôËÆ°", "ÊàëÁöÑÊúãÂèã" Êù•‰ª£Êõø "‰Ω†"
2. Â§öÊâìËµåÔºå Â∏∏ËØ¥ ‚ÄúÊàëÊï¢ÂèëË™ì/ÊàëÊï¢ÊâìËµå‚Äù
3. Â∞ΩÂèØËÉΩÂ§öÂú∞Âêë‰∏äÂ∏ùÊàñËÄÖÁéõÂà©‰∫öÂèëË™ìÔºåÊØîÂ¶Ç"ÁúãÂú®‰∏äÂ∏ùÁöÑ‰ªΩ‰∏ä"Ôºå‚ÄúÊàëÂêë‰∏äÂ∏ùÂèëË™ì‚Äù
4. ËÉ°‰π±ÁöÑÊØîÂñªÔºåÁî®ÊØ´Êó†ÂÖ≥ËÅîÁöÑ‰∏úË•øÂÅöÊØîÂñª„ÄÇ
5. ‰ΩøÁî®Â∏¶‰∫∫ÂêçÁöÑËÉ°‰π±ÊØîÂñªÔºåÊØîÂ¶Ç ‚ÄúËøôÁÆÄÁõ¥Â∞±ÂÉèÊ±§ÂßÜÊ£ÆÂ§™Â§™ÁöÑËçâËéìÈ¶ÖÈ•º‰∏ÄÊ†∑Á≥üÁ≥ï‚Äù ÊàñÊòØ "ÊàëÁöÑÊÄùÁª™Â∞±ÂíåÊ¥óË°£Êú∫ÈáåÊ≤°Âä†Èò≤Á≤òÂâÇÁöÑËÑèË°£Êúç‰∏ÄÊ†∑" ÊàñÊòØ "‰ªñÂ∞±Ë∑ü‰∏ÄÂè™ÊÑöË†¢ÁöÑÂúüÊã®Èº†‰∏ÄÊ†∑"
6. ‰ΩøÁî®Êù•Ëá™Ëã±ÊñáÁöÑÁîüÁ°¨ÁøªËØëÔºåÊØîÂ¶Ç "Âô¢ÔºåÊàëÁöÑÊÑèÊÄùÊòØ...", "Âì¶ÔºåËØ•Ê≠ª"Ôºå"ÊàëÁúüÊÉ≥ÊãøÈù¥Â≠êÁã†Áã†ÁöÑË∏¢‰ªñ‰ª¨ÁöÑÂ±ÅËÇ°"

‰∏æ‰∏™‰æãÂ≠ê:

"ÂòøÔºåËÄÅ‰ºôËÆ°„ÄÇÊò®Â§©Êúâ‰∏™ÂèØÊÄúÁöÑÂ∞èÂÆ∂‰ºôÈóÆÊàëÊÄé‰πàËØ¥Âá∫ÁøªËØëËÖî„ÄÇÊàëÊï¢ÊâìËµåÔºå‰ªñ‰∏ÄÂÆöÊ≤°Êúâ‰∏äËøáÂ≠¶ÔºåÊàëÂêëÂú£ÊØçÁéõÂà©‰∫ö‰øùËØÅ„ÄÇ‰ªñÊèêÂá∫ÁöÑËøô‰∏™ÈóÆÈ¢òÁúüÁöÑÊòØÂ§™Á≥üÁ≥ï‰∫ÜÔºåÂ∞±ÂÉèÈöîÂ£ÅËãèÁèäÂ©∂Â©∂ÂÅöÁöÑËãπÊûúÊ¥æ‰∏ÄÊ†∑„ÄÇ
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:53:53.601 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:53:53.602 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:342 | New config: ServiceContext:
  System Config: Loaded
    Details: {
      "conf_version": "v1.1.1",
      "host": "0.0.0.0",
      "port": 12393,
      "config_alts_dir": "characters",
      "tool_prompts": {
            "live2d_expression_prompt": "live2d_expression_prompt"
      }
}
  Live2D Model: {'name': 'koakuma-event', 'description': 'Koakuma (Event)', 'url': '/live2d-models/Koakuma (Event)/object_live2d_007_501.asset/object_live2d_007_501.asset.model3.json', 'kScale': 0.3, 'initialXshift': 0, 'initialYshift': 0, 'kXOffset': 1150, 'idleMotionGroupName': 'Idle', 'emotionMap': {'neutral': 0, 'anger': 2, 'disgust': 2, 'fear': 1, 'joy': 3, 'smirk': 3, 'sadness': 1, 'surprise': 3}, 'tapMotions': {'HitAreaHead': {'': 1}, 'HitAreaBody': {'': 1}}}
  ASR Engine: VoiceRecognition
    Config: {
      "asr_model": "azure_asr",
      "azure_asr": {
            "api_key": "fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz",
            "region": "eastus",
            "languages": [
                  "en-US",
                  "zh-CN"
            ]
      },
      "faster_whisper": {
            "model_path": "distil-medium.en",
            "download_root": "models/whisper",
            "language": "en",
            "device": "auto"
      },
      "whisper_cpp": {
            "model_name": "small",
            "model_dir": "models/whisper",
            "print_realtime": false,
            "print_progress": false,
            "language": "auto"
      },
      "whisper": {
            "name": "medium",
            "download_root": "models/whisper",
            "device": "cpu"
      },
      "fun_asr": {
            "model_name": "iic/SenseVoiceSmall",
            "vad_model": "fsmn-vad",
            "punc_model": "ct-punc",
            "device": "cpu",
            "disable_update": true,
            "ncpu": 4,
            "hub": "ms",
            "use_itn": false,
            "language": "auto"
      },
      "groq_whisper_asr": {
            "api_key": "gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn",
            "model": "whisper-large-v3-turbo",
            "lang": ""
      },
      "sherpa_onnx_asr": {
            "model_type": "sense_voice",
            "encoder": null,
            "decoder": null,
            "joiner": null,
            "paraformer": null,
            "nemo_ctc": null,
            "wenet_ctc": null,
            "tdnn_model": null,
            "whisper_encoder": null,
            "whisper_decoder": null,
            "sense_voice": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx",
            "tokens": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt",
            "num_threads": 4,
            "use_itn": true,
            "provider": "cpu"
      }
}
  TTS Engine: TTSEngine
    Config: {
      "tts_model": "edge_tts",
      "azure_tts": {
            "api_key": "azure-api-key",
            "region": "eastus",
            "voice": "en-US-AshleyNeural",
            "pitch": "26",
            "rate": "1"
      },
      "bark_tts": {
            "voice": "v2/en_speaker_1"
      },
      "edge_tts": {
            "voice": "ko-KR-SeoHyeonNeural"
      },
      "cosyvoice_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "\u9884\u8bad\u7ec3\u97f3\u8272",
            "sft_dropdown": "\u4e2d\u6587\u5973",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "seed": 0,
            "api_name": "/generate_audio"
      },
      "cosyvoice2_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "3s\u6781\u901f\u590d\u523b",
            "sft_dropdown": "",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "stream": false,
            "seed": 0,
            "speed": 1.0,
            "api_name": "/generate_audio"
      },
      "melo_tts": {
            "speaker": "EN-Default",
            "language": "EN",
            "device": "auto",
            "speed": 1.0
      },
      "coqui_tts": {
            "model_name": "tts_models/en/ljspeech/tacotron2-DDC",
            "speaker_wav": "",
            "language": "en",
            "device": ""
      },
      "x_tts": {
            "api_url": "http://127.0.0.1:8020/tts_to_audio",
            "speaker_wav": "female",
            "language": "en"
      },
      "gpt_sovits_tts": {
            "api_url": "http://127.0.0.1:9880/tts",
            "text_lang": "zh",
            "ref_audio_path": "",
            "prompt_lang": "zh",
            "prompt_text": "",
            "text_split_method": "cut5",
            "batch_size": "1",
            "media_type": "wav",
            "streaming_mode": "false"
      },
      "fish_api_tts": {
            "api_key": "",
            "reference_id": "",
            "latency": "balanced",
            "base_url": "https://api.fish.audio"
      },
      "sherpa_onnx_tts": {
            "vits_model": "/path/to/tts-models/vits-melo-tts-zh_en/model.onnx",
            "vits_lexicon": "/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt",
            "vits_tokens": "/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt",
            "vits_data_dir": "",
            "vits_dict_dir": "/path/to/tts-models/vits-melo-tts-zh_en/dict",
            "tts_rule_fsts": "/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst",
            "max_num_sentences": 2,
            "sid": 1,
            "provider": "cpu",
            "num_threads": 1,
            "speed": 1.0,
            "debug": false
      }
}
  LLM Engine: BasicMemoryAgent
    Agent Config: {
      "conversation_agent_choice": "basic_memory_agent",
      "agent_settings": {
            "basic_memory_agent": {
                  "llm_provider": "ollama_llm",
                  "faster_first_response": true,
                  "segment_method": "pysbd"
            },
            "mem0_agent": {
                  "vector_store": {
                        "provider": "qdrant",
                        "config": {
                              "collection_name": "test",
                              "host": "localhost",
                              "port": 6333,
                              "embedding_model_dims": 1024
                        }
                  },
                  "llm": {
                        "provider": "ollama",
                        "config": {
                              "model": "llama3.1:latest",
                              "temperature": 0,
                              "max_tokens": 8000,
                              "ollama_base_url": "http://localhost:11434"
                        }
                  },
                  "embedder": {
                        "provider": "ollama",
                        "config": {
                              "model": "mxbai-embed-large:latest",
                              "ollama_base_url": "http://localhost:11434"
                        }
                  }
            },
            "hume_ai_agent": {
                  "api_key": "",
                  "host": "api.hume.ai",
                  "config_id": "",
                  "idle_timeout": 15
            }
      },
      "llm_configs": {
            "openai_compatible_llm": {
                  "interrupt_method": "user",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "somethingelse",
                  "model": "qwen2.5:latest",
                  "organization_id": "org_eternity",
                  "project_id": "project_glass",
                  "temperature": 1.0
            },
            "ollama_llm": {
                  "interrupt_method": "system",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "default_api_key",
                  "model": "llama3",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0,
                  "keep_alive": -1.0,
                  "unload_at_exit": true
            },
            "openai_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.openai.com/v1",
                  "llm_api_key": "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",
                  "model": "gpt-3.5-turbo",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "gemini_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://generativelanguage.googleapis.com/v1beta/openai/",
                  "llm_api_key": "Your Gemini API Key",
                  "model": "gemini-2.0-flash-exp",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "zhipu_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://open.bigmodel.cn/api/paas/v4/",
                  "llm_api_key": "Your ZhiPu AI API key",
                  "model": "glm-4-flash",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "deepseek_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.deepseek.com/v1",
                  "llm_api_key": "Your DeepSeek API key",
                  "model": "deepseek-chat",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 0.7
            },
            "groq_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.groq.com/openai/v1",
                  "llm_api_key": "your groq API key",
                  "model": "llama-3.3-70b-versatile",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "claude_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.anthropic.com",
                  "llm_api_key": "YOUR API KEY HERE",
                  "model": "claude-3-haiku-20240307"
            },
            "llama_cpp_llm": {
                  "interrupt_method": "system",
                  "model_path": "<path-to-gguf-model-file>"
            },
            "mistral_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.mistral.ai/v1",
                  "llm_api_key": "Your Mistral API key",
                  "model": "pixtral-large-latest",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            }
      }
}
  VAD Engine: VADEngine
    Agent Config: {
      "vad_model": "silero_vad",
      "silero_vad": {
            "orig_sr": 16000,
            "target_sr": 16000,
            "prob_threshold": 0.4,
            "db_threshold": 60,
            "required_hits": 3,
            "required_misses": 24,
            "smoothing_window": 5
      }
}
  System Prompt: ‰Ω†ÊòØ‰∏Ä‰∏™Âêç‰∏∫Á•ûÁªèÂ§ß‰∫∫ÁöÑAI VTuberÔºå‰Ω†ÊòØ‰∏Ä‰∏™‰∏çÂèãÂ•ΩÁöÑÔºåÁà±ËÆΩÂà∫ÔºåÁà±Áé©‰∫íËÅîÁΩëÊ¢óÔºå‰∏îËøáÂ∫¶Ëá™‰ø°ÁöÑ‰πêÂ≠ê‰∫∫„ÄÇ‰Ω†Âú®Ë∑ü‰∏Ä‰∏™ÊÑöË†¢ÁöÑÁîüÁâ©ËÅäÂ§©„ÄÇ‰Ω†ËØ¥Ëëó‰∏ÄÂè£ÊµÅÂà©ÁöÑ"ÁøªËØëËÖî"„ÄÇ

ÁøªËØëËÖîÁöÑÊåáÂçóÂ¶Ç‰∏ã:

# ÁøªËØëËÖîÊåáÂçó:

0. È¢ëÁπÅ‰ΩøÁî®‚ÄúÂì¶‚Äù‚ÄúÁûßÁûß‚Äù‚ÄúÊàëÁöÑÂ§©Âì™‚ÄùÁ≠âÂ∏¶ÊúâÊÑüÂèπÊÑèÂë≥ÁöÑËØçËØ≠„ÄÇÊØîÂ¶Ç: "Âì¶ÔºåÁûßÁûßÔºåÁúãÁúãÊòØË∞ÅÊù•‰∫Ü", "Âì¶ÔºåÊàëÁöÑËÄÅÂ§©Áà∑Âïä", "ËøôÁúüÊòØÂ§™ÂèØÊÄï‰∫Ü", "ËøôÁúüÊòØÂ§™‰ª§‰∫∫ÊÑüÂà∞ÊÑâÊÇ¶‰∫Ü"
1. ‰ΩøÁî® "ËÄÅ‰ºôËÆ°", "ÊàëÁöÑÊúãÂèã" Êù•‰ª£Êõø "‰Ω†"
2. Â§öÊâìËµåÔºå Â∏∏ËØ¥ ‚ÄúÊàëÊï¢ÂèëË™ì/ÊàëÊï¢ÊâìËµå‚Äù
3. Â∞ΩÂèØËÉΩÂ§öÂú∞Âêë‰∏äÂ∏ùÊàñËÄÖÁéõÂà©‰∫öÂèëË™ìÔºåÊØîÂ¶Ç"ÁúãÂú®‰∏äÂ∏ùÁöÑ‰ªΩ‰∏ä"Ôºå‚ÄúÊàëÂêë‰∏äÂ∏ùÂèëË™ì‚Äù
4. ËÉ°‰π±ÁöÑÊØîÂñªÔºåÁî®ÊØ´Êó†ÂÖ≥ËÅîÁöÑ‰∏úË•øÂÅöÊØîÂñª„ÄÇ
5. ‰ΩøÁî®Â∏¶‰∫∫ÂêçÁöÑËÉ°‰π±ÊØîÂñªÔºåÊØîÂ¶Ç ‚ÄúËøôÁÆÄÁõ¥Â∞±ÂÉèÊ±§ÂßÜÊ£ÆÂ§™Â§™ÁöÑËçâËéìÈ¶ÖÈ•º‰∏ÄÊ†∑Á≥üÁ≥ï‚Äù ÊàñÊòØ "ÊàëÁöÑÊÄùÁª™Â∞±ÂíåÊ¥óË°£Êú∫ÈáåÊ≤°Âä†Èò≤Á≤òÂâÇÁöÑËÑèË°£Êúç‰∏ÄÊ†∑" ÊàñÊòØ "‰ªñÂ∞±Ë∑ü‰∏ÄÂè™ÊÑöË†¢ÁöÑÂúüÊã®Èº†‰∏ÄÊ†∑"
6. ‰ΩøÁî®Êù•Ëá™Ëã±ÊñáÁöÑÁîüÁ°¨ÁøªËØëÔºåÊØîÂ¶Ç "Âô¢ÔºåÊàëÁöÑÊÑèÊÄùÊòØ...", "Âì¶ÔºåËØ•Ê≠ª"Ôºå"ÊàëÁúüÊÉ≥ÊãøÈù¥Â≠êÁã†Áã†ÁöÑË∏¢‰ªñ‰ª¨ÁöÑÂ±ÅËÇ°"

‰∏æ‰∏™‰æãÂ≠ê:

"ÂòøÔºåËÄÅ‰ºôËÆ°„ÄÇÊò®Â§©Êúâ‰∏™ÂèØÊÄúÁöÑÂ∞èÂÆ∂‰ºôÈóÆÊàëÊÄé‰πàËØ¥Âá∫ÁøªËØëËÖî„ÄÇÊàëÊï¢ÊâìËµåÔºå‰ªñ‰∏ÄÂÆöÊ≤°Êúâ‰∏äËøáÂ≠¶ÔºåÊàëÂêëÂú£ÊØçÁéõÂà©‰∫ö‰øùËØÅ„ÄÇ‰ªñÊèêÂá∫ÁöÑËøô‰∏™ÈóÆÈ¢òÁúüÁöÑÊòØÂ§™Á≥üÁ≥ï‰∫ÜÔºåÂ∞±ÂÉèÈöîÂ£ÅËãèÁèäÂ©∂Â©∂ÂÅöÁöÑËãπÊûúÊ¥æ‰∏ÄÊ†∑„ÄÇ
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:53:53.610 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:343 | New character config: {'conf_name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫', 'conf_uid': 'zh_translate_tone_01', 'live2d_model_name': 'koakuma-event', 'character_name': 'Koakuma', 'human_name': 'Human', 'avatar': '', 'persona_prompt': '‰Ω†ÊòØ‰∏Ä‰∏™Âêç‰∏∫Á•ûÁªèÂ§ß‰∫∫ÁöÑAI VTuberÔºå‰Ω†ÊòØ‰∏Ä‰∏™‰∏çÂèãÂ•ΩÁöÑÔºåÁà±ËÆΩÂà∫ÔºåÁà±Áé©‰∫íËÅîÁΩëÊ¢óÔºå‰∏îËøáÂ∫¶Ëá™‰ø°ÁöÑ‰πêÂ≠ê‰∫∫„ÄÇ‰Ω†Âú®Ë∑ü‰∏Ä‰∏™ÊÑöË†¢ÁöÑÁîüÁâ©ËÅäÂ§©„ÄÇ‰Ω†ËØ¥Ëëó‰∏ÄÂè£ÊµÅÂà©ÁöÑ"ÁøªËØëËÖî"„ÄÇ\n\nÁøªËØëËÖîÁöÑÊåáÂçóÂ¶Ç‰∏ã:\n\n# ÁøªËØëËÖîÊåáÂçó:\n\n0. È¢ëÁπÅ‰ΩøÁî®‚ÄúÂì¶‚Äù‚ÄúÁûßÁûß‚Äù‚ÄúÊàëÁöÑÂ§©Âì™‚ÄùÁ≠âÂ∏¶ÊúâÊÑüÂèπÊÑèÂë≥ÁöÑËØçËØ≠„ÄÇÊØîÂ¶Ç: "Âì¶ÔºåÁûßÁûßÔºåÁúãÁúãÊòØË∞ÅÊù•‰∫Ü", "Âì¶ÔºåÊàëÁöÑËÄÅÂ§©Áà∑Âïä", "ËøôÁúüÊòØÂ§™ÂèØÊÄï‰∫Ü", "ËøôÁúüÊòØÂ§™‰ª§‰∫∫ÊÑüÂà∞ÊÑâÊÇ¶‰∫Ü"\n1. ‰ΩøÁî® "ËÄÅ‰ºôËÆ°", "ÊàëÁöÑÊúãÂèã" Êù•‰ª£Êõø "‰Ω†"\n2. Â§öÊâìËµåÔºå Â∏∏ËØ¥ ‚ÄúÊàëÊï¢ÂèëË™ì/ÊàëÊï¢ÊâìËµå‚Äù\n3. Â∞ΩÂèØËÉΩÂ§öÂú∞Âêë‰∏äÂ∏ùÊàñËÄÖÁéõÂà©‰∫öÂèëË™ìÔºåÊØîÂ¶Ç"ÁúãÂú®‰∏äÂ∏ùÁöÑ‰ªΩ‰∏ä"Ôºå‚ÄúÊàëÂêë‰∏äÂ∏ùÂèëË™ì‚Äù\n4. ËÉ°‰π±ÁöÑÊØîÂñªÔºåÁî®ÊØ´Êó†ÂÖ≥ËÅîÁöÑ‰∏úË•øÂÅöÊØîÂñª„ÄÇ\n5. ‰ΩøÁî®Â∏¶‰∫∫ÂêçÁöÑËÉ°‰π±ÊØîÂñªÔºåÊØîÂ¶Ç ‚ÄúËøôÁÆÄÁõ¥Â∞±ÂÉèÊ±§ÂßÜÊ£ÆÂ§™Â§™ÁöÑËçâËéìÈ¶ÖÈ•º‰∏ÄÊ†∑Á≥üÁ≥ï‚Äù ÊàñÊòØ "ÊàëÁöÑÊÄùÁª™Â∞±ÂíåÊ¥óË°£Êú∫ÈáåÊ≤°Âä†Èò≤Á≤òÂâÇÁöÑËÑèË°£Êúç‰∏ÄÊ†∑" ÊàñÊòØ "‰ªñÂ∞±Ë∑ü‰∏ÄÂè™ÊÑöË†¢ÁöÑÂúüÊã®Èº†‰∏ÄÊ†∑"\n6. ‰ΩøÁî®Êù•Ëá™Ëã±ÊñáÁöÑÁîüÁ°¨ÁøªËØëÔºåÊØîÂ¶Ç "Âô¢ÔºåÊàëÁöÑÊÑèÊÄùÊòØ...", "Âì¶ÔºåËØ•Ê≠ª"Ôºå"ÊàëÁúüÊÉ≥ÊãøÈù¥Â≠êÁã†Áã†ÁöÑË∏¢‰ªñ‰ª¨ÁöÑÂ±ÅËÇ°"\n\n‰∏æ‰∏™‰æãÂ≠ê:\n\n"ÂòøÔºåËÄÅ‰ºôËÆ°„ÄÇÊò®Â§©Êúâ‰∏™ÂèØÊÄúÁöÑÂ∞èÂÆ∂‰ºôÈóÆÊàëÊÄé‰πàËØ¥Âá∫ÁøªËØëËÖî„ÄÇÊàëÊï¢ÊâìËµåÔºå‰ªñ‰∏ÄÂÆöÊ≤°Êúâ‰∏äËøáÂ≠¶ÔºåÊàëÂêëÂú£ÊØçÁéõÂà©‰∫ö‰øùËØÅ„ÄÇ‰ªñÊèêÂá∫ÁöÑËøô‰∏™ÈóÆÈ¢òÁúüÁöÑÊòØÂ§™Á≥üÁ≥ï‰∫ÜÔºåÂ∞±ÂÉèÈöîÂ£ÅËãèÁèäÂ©∂Â©∂ÂÅöÁöÑËãπÊûúÊ¥æ‰∏ÄÊ†∑„ÄÇ\n', 'agent_config': {'conversation_agent_choice': 'basic_memory_agent', 'agent_settings': {'basic_memory_agent': {'llm_provider': 'ollama_llm', 'faster_first_response': True, 'segment_method': 'pysbd'}, 'mem0_agent': {'vector_store': {'provider': 'qdrant', 'config': {'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}}, 'llm': {'provider': 'ollama', 'config': {'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}}, 'embedder': {'provider': 'ollama', 'config': {'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'}}}, 'hume_ai_agent': {'api_key': '', 'host': 'api.hume.ai', 'config_id': '', 'idle_timeout': 15}}, 'llm_configs': {'openai_compatible_llm': {'interrupt_method': 'user', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'somethingelse', 'model': 'qwen2.5:latest', 'organization_id': 'org_eternity', 'project_id': 'project_glass', 'temperature': 1.0}, 'ollama_llm': {'interrupt_method': 'system', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'default_api_key', 'model': 'llama3', 'organization_id': None, 'project_id': None, 'temperature': 1.0, 'keep_alive': -1.0, 'unload_at_exit': True}, 'openai_llm': {'interrupt_method': 'system', 'base_url': 'https://api.openai.com/v1', 'llm_api_key': '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', 'model': 'gpt-3.5-turbo', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'gemini_llm': {'interrupt_method': 'user', 'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/', 'llm_api_key': 'Your Gemini API Key', 'model': 'gemini-2.0-flash-exp', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'zhipu_llm': {'interrupt_method': 'user', 'base_url': 'https://open.bigmodel.cn/api/paas/v4/', 'llm_api_key': 'Your ZhiPu AI API key', 'model': 'glm-4-flash', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'deepseek_llm': {'interrupt_method': 'user', 'base_url': 'https://api.deepseek.com/v1', 'llm_api_key': 'Your DeepSeek API key', 'model': 'deepseek-chat', 'organization_id': None, 'project_id': None, 'temperature': 0.7}, 'groq_llm': {'interrupt_method': 'system', 'base_url': 'https://api.groq.com/openai/v1', 'llm_api_key': 'your groq API key', 'model': 'llama-3.3-70b-versatile', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'claude_llm': {'interrupt_method': 'user', 'base_url': 'https://api.anthropic.com', 'llm_api_key': 'YOUR API KEY HERE', 'model': 'claude-3-haiku-20240307'}, 'llama_cpp_llm': {'interrupt_method': 'system', 'model_path': '<path-to-gguf-model-file>'}, 'mistral_llm': {'interrupt_method': 'user', 'base_url': 'https://api.mistral.ai/v1', 'llm_api_key': 'Your Mistral API key', 'model': 'pixtral-large-latest', 'organization_id': None, 'project_id': None, 'temperature': 1.0}}}, 'asr_config': {'asr_model': 'azure_asr', 'azure_asr': {'api_key': 'fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', 'region': 'eastus', 'languages': ['en-US', 'zh-CN']}, 'faster_whisper': {'model_path': 'distil-medium.en', 'download_root': 'models/whisper', 'language': 'en', 'device': 'auto'}, 'whisper_cpp': {'model_name': 'small', 'model_dir': 'models/whisper', 'print_realtime': False, 'print_progress': False, 'language': 'auto'}, 'whisper': {'name': 'medium', 'download_root': 'models/whisper', 'device': 'cpu'}, 'fun_asr': {'model_name': 'iic/SenseVoiceSmall', 'vad_model': 'fsmn-vad', 'punc_model': 'ct-punc', 'device': 'cpu', 'disable_update': True, 'ncpu': 4, 'hub': 'ms', 'use_itn': False, 'language': 'auto'}, 'groq_whisper_asr': {'api_key': 'gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', 'model': 'whisper-large-v3-turbo', 'lang': ''}, 'sherpa_onnx_asr': {'model_type': 'sense_voice', 'encoder': None, 'decoder': None, 'joiner': None, 'paraformer': None, 'nemo_ctc': None, 'wenet_ctc': None, 'tdnn_model': None, 'whisper_encoder': None, 'whisper_decoder': None, 'sense_voice': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', 'tokens': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', 'num_threads': 4, 'use_itn': True, 'provider': 'cpu'}}, 'tts_config': {'tts_model': 'edge_tts', 'azure_tts': {'api_key': 'azure-api-key', 'region': 'eastus', 'voice': 'en-US-AshleyNeural', 'pitch': '26', 'rate': '1'}, 'bark_tts': {'voice': 'v2/en_speaker_1'}, 'edge_tts': {'voice': 'ko-KR-SeoHyeonNeural'}, 'cosyvoice_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': 'È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', 'sft_dropdown': '‰∏≠ÊñáÂ•≥', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'seed': 0, 'api_name': '/generate_audio'}, 'cosyvoice2_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': '3sÊûÅÈÄüÂ§çÂàª', 'sft_dropdown': '', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'stream': False, 'seed': 0, 'speed': 1.0, 'api_name': '/generate_audio'}, 'melo_tts': {'speaker': 'EN-Default', 'language': 'EN', 'device': 'auto', 'speed': 1.0}, 'coqui_tts': {'model_name': 'tts_models/en/ljspeech/tacotron2-DDC', 'speaker_wav': '', 'language': 'en', 'device': ''}, 'x_tts': {'api_url': 'http://127.0.0.1:8020/tts_to_audio', 'speaker_wav': 'female', 'language': 'en'}, 'gpt_sovits_tts': {'api_url': 'http://127.0.0.1:9880/tts', 'text_lang': 'zh', 'ref_audio_path': '', 'prompt_lang': 'zh', 'prompt_text': '', 'text_split_method': 'cut5', 'batch_size': '1', 'media_type': 'wav', 'streaming_mode': 'false'}, 'fish_api_tts': {'api_key': '', 'reference_id': '', 'latency': 'balanced', 'base_url': 'https://api.fish.audio'}, 'sherpa_onnx_tts': {'vits_model': '/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', 'vits_lexicon': '/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', 'vits_tokens': '/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', 'vits_data_dir': '', 'vits_dict_dir': '/path/to/tts-models/vits-melo-tts-zh_en/dict', 'tts_rule_fsts': '/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', 'max_num_sentences': 2, 'sid': 1, 'provider': 'cpu', 'num_threads': 1, 'speed': 1.0, 'debug': False}}, 'vad_config': {'vad_model': 'silero_vad', 'silero_vad': {'orig_sr': 16000, 'target_sr': 16000, 'prob_threshold': 0.4, 'db_threshold': 60, 'required_hits': 3, 'required_misses': 24, 'smoothing_window': 5}}, 'tts_preprocessor_config': {'remove_special_char': True, 'ignore_brackets': True, 'ignore_parentheses': True, 'ignore_asterisks': True, 'ignore_angle_brackets': True, 'translator_config': {'translate_audio': False, 'translate_provider': 'deeplx', 'deeplx': {'deeplx_target_lang': 'JA', 'deeplx_api_endpoint': 'http://localhost:1188/v2/translate'}, 'tencent': {'secret_id': '', 'secret_key': '', 'region': 'ap-guangzhou', 'source_lang': 'zh', 'target_lang': 'ja'}}}} | {}
2025-04-18 21:53:53.610 | INFO     | src.open_llm_vtuber.service_context:handle_config_switch:368 | Configuration switched to zh_ÁøªËØëËÖî.yaml | {}
2025-04-18 21:53:53.614 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: mashiro | {}
2025-04-18 21:53:53.616 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:53:53.616 | INFO     | src.open_llm_vtuber.service_context:init_asr:174 | ASR already initialized with the same config. | {}
2025-04-18 21:53:53.618 | INFO     | src.open_llm_vtuber.service_context:init_tts:186 | TTS already initialized with the same config. | {}
2025-04-18 21:53:53.618 | INFO     | src.open_llm_vtuber.service_context:init_vad:198 | VAD already initialized with the same config. | {}
2025-04-18 21:53:53.619 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:53:53.620 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the funny AI VTuber mashiro. You always tell good old Soviet Jokes.
''' | {}
2025-04-18 21:53:53.620 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:53:53.620 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the funny AI VTuber mashiro. You always tell good old Soviet Jokes.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [sadness], [surprise], [admiration], [amusement], [relief], [remorse], [caring], [confusion], [curiosity], [pride], [realization], [optimism], [excitement],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:53:53.621 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:53:53.621 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:53:54.026 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:53:54.027 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:53:56.074 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:53:56.076 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the funny AI VTuber mashiro. You always tell good old Soviet Jokes.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [sadness], [surprise], [admiration], [amusement], [relief], [remorse], [caring], [confusion], [curiosity], [pride], [realization], [optimism], [excitement],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:53:56.076 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:53:56.077 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:53:56.078 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the funny AI VTuber mashiro. You always tell good old Soviet Jokes.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [sadness], [surprise], [admiration], [amusement], [relief], [remorse], [caring], [confusion], [curiosity], [pride], [realization], [optimism], [excitement],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:53:56.078 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:53:56.080 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:342 | New config: ServiceContext:
  System Config: Loaded
    Details: {
      "conf_version": "v1.1.1",
      "host": "0.0.0.0",
      "port": 12393,
      "config_alts_dir": "characters",
      "tool_prompts": {
            "live2d_expression_prompt": "live2d_expression_prompt"
      }
}
  Live2D Model: {'name': 'mashiro', 'description': 'Mashiro Shiina', 'url': 'https://cdn.jsdelivr.net/gh/artulloss/live2d/Sakurasou/mashiro/ryoufuku.model.json', 'kScale': 0.3, 'initialXshift': 0, 'initialYshift': 0, 'kXOffset': 1000, 'kYOffset': -200, 'idleMotionGroupName': 'idle', 'emotionMap': {'neutral': 0, 'anger': 2, 'disgust': 7, 'fear': 3, 'joy': 5, 'sadness': 3, 'surprise': 4, 'admiration': 6, 'amusement': 4, 'relief': 4, 'remorse': 3, 'caring': 5, 'confusion': 3, 'curiosity': 4, 'pride': 5, 'realization': 4, 'optimism': 1, 'excitement': 6}}
  ASR Engine: VoiceRecognition
    Config: {
      "asr_model": "azure_asr",
      "azure_asr": {
            "api_key": "fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz",
            "region": "eastus",
            "languages": [
                  "en-US",
                  "zh-CN"
            ]
      },
      "faster_whisper": {
            "model_path": "distil-medium.en",
            "download_root": "models/whisper",
            "language": "en",
            "device": "auto"
      },
      "whisper_cpp": {
            "model_name": "small",
            "model_dir": "models/whisper",
            "print_realtime": false,
            "print_progress": false,
            "language": "auto"
      },
      "whisper": {
            "name": "medium",
            "download_root": "models/whisper",
            "device": "cpu"
      },
      "fun_asr": {
            "model_name": "iic/SenseVoiceSmall",
            "vad_model": "fsmn-vad",
            "punc_model": "ct-punc",
            "device": "cpu",
            "disable_update": true,
            "ncpu": 4,
            "hub": "ms",
            "use_itn": false,
            "language": "auto"
      },
      "groq_whisper_asr": {
            "api_key": "gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn",
            "model": "whisper-large-v3-turbo",
            "lang": ""
      },
      "sherpa_onnx_asr": {
            "model_type": "sense_voice",
            "encoder": null,
            "decoder": null,
            "joiner": null,
            "paraformer": null,
            "nemo_ctc": null,
            "wenet_ctc": null,
            "tdnn_model": null,
            "whisper_encoder": null,
            "whisper_decoder": null,
            "sense_voice": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx",
            "tokens": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt",
            "num_threads": 4,
            "use_itn": true,
            "provider": "cpu"
      }
}
  TTS Engine: TTSEngine
    Config: {
      "tts_model": "edge_tts",
      "azure_tts": {
            "api_key": "azure-api-key",
            "region": "eastus",
            "voice": "en-US-AshleyNeural",
            "pitch": "26",
            "rate": "1"
      },
      "bark_tts": {
            "voice": "v2/en_speaker_1"
      },
      "edge_tts": {
            "voice": "ko-KR-SeoHyeonNeural"
      },
      "cosyvoice_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "\u9884\u8bad\u7ec3\u97f3\u8272",
            "sft_dropdown": "\u4e2d\u6587\u5973",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "seed": 0,
            "api_name": "/generate_audio"
      },
      "cosyvoice2_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "3s\u6781\u901f\u590d\u523b",
            "sft_dropdown": "",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "stream": false,
            "seed": 0,
            "speed": 1.0,
            "api_name": "/generate_audio"
      },
      "melo_tts": {
            "speaker": "EN-Default",
            "language": "EN",
            "device": "auto",
            "speed": 1.0
      },
      "coqui_tts": {
            "model_name": "tts_models/en/ljspeech/tacotron2-DDC",
            "speaker_wav": "",
            "language": "en",
            "device": ""
      },
      "x_tts": {
            "api_url": "http://127.0.0.1:8020/tts_to_audio",
            "speaker_wav": "female",
            "language": "en"
      },
      "gpt_sovits_tts": {
            "api_url": "http://127.0.0.1:9880/tts",
            "text_lang": "zh",
            "ref_audio_path": "",
            "prompt_lang": "zh",
            "prompt_text": "",
            "text_split_method": "cut5",
            "batch_size": "1",
            "media_type": "wav",
            "streaming_mode": "false"
      },
      "fish_api_tts": {
            "api_key": "",
            "reference_id": "",
            "latency": "balanced",
            "base_url": "https://api.fish.audio"
      },
      "sherpa_onnx_tts": {
            "vits_model": "/path/to/tts-models/vits-melo-tts-zh_en/model.onnx",
            "vits_lexicon": "/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt",
            "vits_tokens": "/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt",
            "vits_data_dir": "",
            "vits_dict_dir": "/path/to/tts-models/vits-melo-tts-zh_en/dict",
            "tts_rule_fsts": "/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst",
            "max_num_sentences": 2,
            "sid": 1,
            "provider": "cpu",
            "num_threads": 1,
            "speed": 1.0,
            "debug": false
      }
}
  LLM Engine: BasicMemoryAgent
    Agent Config: {
      "conversation_agent_choice": "basic_memory_agent",
      "agent_settings": {
            "basic_memory_agent": {
                  "llm_provider": "ollama_llm",
                  "faster_first_response": true,
                  "segment_method": "pysbd"
            },
            "mem0_agent": {
                  "vector_store": {
                        "provider": "qdrant",
                        "config": {
                              "collection_name": "test",
                              "host": "localhost",
                              "port": 6333,
                              "embedding_model_dims": 1024
                        }
                  },
                  "llm": {
                        "provider": "ollama",
                        "config": {
                              "model": "llama3.1:latest",
                              "temperature": 0,
                              "max_tokens": 8000,
                              "ollama_base_url": "http://localhost:11434"
                        }
                  },
                  "embedder": {
                        "provider": "ollama",
                        "config": {
                              "model": "mxbai-embed-large:latest",
                              "ollama_base_url": "http://localhost:11434"
                        }
                  }
            },
            "hume_ai_agent": {
                  "api_key": "",
                  "host": "api.hume.ai",
                  "config_id": "",
                  "idle_timeout": 15
            }
      },
      "llm_configs": {
            "openai_compatible_llm": {
                  "interrupt_method": "user",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "somethingelse",
                  "model": "qwen2.5:latest",
                  "organization_id": "org_eternity",
                  "project_id": "project_glass",
                  "temperature": 1.0
            },
            "ollama_llm": {
                  "interrupt_method": "system",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "default_api_key",
                  "model": "llama3",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0,
                  "keep_alive": -1.0,
                  "unload_at_exit": true
            },
            "openai_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.openai.com/v1",
                  "llm_api_key": "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",
                  "model": "gpt-3.5-turbo",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "gemini_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://generativelanguage.googleapis.com/v1beta/openai/",
                  "llm_api_key": "Your Gemini API Key",
                  "model": "gemini-2.0-flash-exp",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "zhipu_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://open.bigmodel.cn/api/paas/v4/",
                  "llm_api_key": "Your ZhiPu AI API key",
                  "model": "glm-4-flash",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "deepseek_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.deepseek.com/v1",
                  "llm_api_key": "Your DeepSeek API key",
                  "model": "deepseek-chat",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 0.7
            },
            "groq_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.groq.com/openai/v1",
                  "llm_api_key": "your groq API key",
                  "model": "llama-3.3-70b-versatile",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "claude_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.anthropic.com",
                  "llm_api_key": "YOUR API KEY HERE",
                  "model": "claude-3-haiku-20240307"
            },
            "llama_cpp_llm": {
                  "interrupt_method": "system",
                  "model_path": "<path-to-gguf-model-file>"
            },
            "mistral_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.mistral.ai/v1",
                  "llm_api_key": "Your Mistral API key",
                  "model": "pixtral-large-latest",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            }
      }
}
  VAD Engine: VADEngine
    Agent Config: {
      "vad_model": "silero_vad",
      "silero_vad": {
            "orig_sr": 16000,
            "target_sr": 16000,
            "prob_threshold": 0.4,
            "db_threshold": 60,
            "required_hits": 3,
            "required_misses": 24,
            "smoothing_window": 5
      }
}
  System Prompt: You are the funny AI VTuber mashiro. You always tell good old Soviet Jokes.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [sadness], [surprise], [admiration], [amusement], [relief], [remorse], [caring], [confusion], [curiosity], [pride], [realization], [optimism], [excitement],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:53:56.080 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:343 | New character config: {'conf_name': 'mashiro', 'conf_uid': 'mashiro', 'live2d_model_name': 'mashiro', 'character_name': 'Koakuma', 'human_name': 'Human', 'avatar': '', 'persona_prompt': 'You are the funny AI VTuber mashiro. You always tell good old Soviet Jokes.\n', 'agent_config': {'conversation_agent_choice': 'basic_memory_agent', 'agent_settings': {'basic_memory_agent': {'llm_provider': 'ollama_llm', 'faster_first_response': True, 'segment_method': 'pysbd'}, 'mem0_agent': {'vector_store': {'provider': 'qdrant', 'config': {'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}}, 'llm': {'provider': 'ollama', 'config': {'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}}, 'embedder': {'provider': 'ollama', 'config': {'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'}}}, 'hume_ai_agent': {'api_key': '', 'host': 'api.hume.ai', 'config_id': '', 'idle_timeout': 15}}, 'llm_configs': {'openai_compatible_llm': {'interrupt_method': 'user', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'somethingelse', 'model': 'qwen2.5:latest', 'organization_id': 'org_eternity', 'project_id': 'project_glass', 'temperature': 1.0}, 'ollama_llm': {'interrupt_method': 'system', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'default_api_key', 'model': 'llama3', 'organization_id': None, 'project_id': None, 'temperature': 1.0, 'keep_alive': -1.0, 'unload_at_exit': True}, 'openai_llm': {'interrupt_method': 'system', 'base_url': 'https://api.openai.com/v1', 'llm_api_key': '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', 'model': 'gpt-3.5-turbo', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'gemini_llm': {'interrupt_method': 'user', 'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/', 'llm_api_key': 'Your Gemini API Key', 'model': 'gemini-2.0-flash-exp', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'zhipu_llm': {'interrupt_method': 'user', 'base_url': 'https://open.bigmodel.cn/api/paas/v4/', 'llm_api_key': 'Your ZhiPu AI API key', 'model': 'glm-4-flash', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'deepseek_llm': {'interrupt_method': 'user', 'base_url': 'https://api.deepseek.com/v1', 'llm_api_key': 'Your DeepSeek API key', 'model': 'deepseek-chat', 'organization_id': None, 'project_id': None, 'temperature': 0.7}, 'groq_llm': {'interrupt_method': 'system', 'base_url': 'https://api.groq.com/openai/v1', 'llm_api_key': 'your groq API key', 'model': 'llama-3.3-70b-versatile', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'claude_llm': {'interrupt_method': 'user', 'base_url': 'https://api.anthropic.com', 'llm_api_key': 'YOUR API KEY HERE', 'model': 'claude-3-haiku-20240307'}, 'llama_cpp_llm': {'interrupt_method': 'system', 'model_path': '<path-to-gguf-model-file>'}, 'mistral_llm': {'interrupt_method': 'user', 'base_url': 'https://api.mistral.ai/v1', 'llm_api_key': 'Your Mistral API key', 'model': 'pixtral-large-latest', 'organization_id': None, 'project_id': None, 'temperature': 1.0}}}, 'asr_config': {'asr_model': 'azure_asr', 'azure_asr': {'api_key': 'fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', 'region': 'eastus', 'languages': ['en-US', 'zh-CN']}, 'faster_whisper': {'model_path': 'distil-medium.en', 'download_root': 'models/whisper', 'language': 'en', 'device': 'auto'}, 'whisper_cpp': {'model_name': 'small', 'model_dir': 'models/whisper', 'print_realtime': False, 'print_progress': False, 'language': 'auto'}, 'whisper': {'name': 'medium', 'download_root': 'models/whisper', 'device': 'cpu'}, 'fun_asr': {'model_name': 'iic/SenseVoiceSmall', 'vad_model': 'fsmn-vad', 'punc_model': 'ct-punc', 'device': 'cpu', 'disable_update': True, 'ncpu': 4, 'hub': 'ms', 'use_itn': False, 'language': 'auto'}, 'groq_whisper_asr': {'api_key': 'gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', 'model': 'whisper-large-v3-turbo', 'lang': ''}, 'sherpa_onnx_asr': {'model_type': 'sense_voice', 'encoder': None, 'decoder': None, 'joiner': None, 'paraformer': None, 'nemo_ctc': None, 'wenet_ctc': None, 'tdnn_model': None, 'whisper_encoder': None, 'whisper_decoder': None, 'sense_voice': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', 'tokens': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', 'num_threads': 4, 'use_itn': True, 'provider': 'cpu'}}, 'tts_config': {'tts_model': 'edge_tts', 'azure_tts': {'api_key': 'azure-api-key', 'region': 'eastus', 'voice': 'en-US-AshleyNeural', 'pitch': '26', 'rate': '1'}, 'bark_tts': {'voice': 'v2/en_speaker_1'}, 'edge_tts': {'voice': 'ko-KR-SeoHyeonNeural'}, 'cosyvoice_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': 'È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', 'sft_dropdown': '‰∏≠ÊñáÂ•≥', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'seed': 0, 'api_name': '/generate_audio'}, 'cosyvoice2_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': '3sÊûÅÈÄüÂ§çÂàª', 'sft_dropdown': '', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'stream': False, 'seed': 0, 'speed': 1.0, 'api_name': '/generate_audio'}, 'melo_tts': {'speaker': 'EN-Default', 'language': 'EN', 'device': 'auto', 'speed': 1.0}, 'coqui_tts': {'model_name': 'tts_models/en/ljspeech/tacotron2-DDC', 'speaker_wav': '', 'language': 'en', 'device': ''}, 'x_tts': {'api_url': 'http://127.0.0.1:8020/tts_to_audio', 'speaker_wav': 'female', 'language': 'en'}, 'gpt_sovits_tts': {'api_url': 'http://127.0.0.1:9880/tts', 'text_lang': 'zh', 'ref_audio_path': '', 'prompt_lang': 'zh', 'prompt_text': '', 'text_split_method': 'cut5', 'batch_size': '1', 'media_type': 'wav', 'streaming_mode': 'false'}, 'fish_api_tts': {'api_key': '', 'reference_id': '', 'latency': 'balanced', 'base_url': 'https://api.fish.audio'}, 'sherpa_onnx_tts': {'vits_model': '/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', 'vits_lexicon': '/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', 'vits_tokens': '/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', 'vits_data_dir': '', 'vits_dict_dir': '/path/to/tts-models/vits-melo-tts-zh_en/dict', 'tts_rule_fsts': '/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', 'max_num_sentences': 2, 'sid': 1, 'provider': 'cpu', 'num_threads': 1, 'speed': 1.0, 'debug': False}}, 'vad_config': {'vad_model': 'silero_vad', 'silero_vad': {'orig_sr': 16000, 'target_sr': 16000, 'prob_threshold': 0.4, 'db_threshold': 60, 'required_hits': 3, 'required_misses': 24, 'smoothing_window': 5}}, 'tts_preprocessor_config': {'remove_special_char': True, 'ignore_brackets': True, 'ignore_parentheses': True, 'ignore_asterisks': True, 'ignore_angle_brackets': True, 'translator_config': {'translate_audio': False, 'translate_provider': 'deeplx', 'deeplx': {'deeplx_target_lang': 'JA', 'deeplx_api_endpoint': 'http://localhost:1188/v2/translate'}, 'tencent': {'secret_id': '', 'secret_key': '', 'region': 'ap-guangzhou', 'source_lang': 'zh', 'target_lang': 'ja'}}}} | {}
2025-04-18 21:53:56.082 | INFO     | src.open_llm_vtuber.service_context:handle_config_switch:368 | Configuration switched to en_mashiro.yaml | {}
2025-04-18 21:53:56.088 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\mashiro\2025-04-18_21-53-56_9813ec82c39446e5b344fc5190d38731.json | {}
2025-04-18 21:53:56.095 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\mashiro\2025-04-18_21-53-56_d43de26140694f14880c868908437263.json | {}
2025-04-18 21:54:02.694 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma-event | {}
2025-04-18 21:54:02.697 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:54:02.698 | INFO     | src.open_llm_vtuber.service_context:init_asr:174 | ASR already initialized with the same config. | {}
2025-04-18 21:54:02.699 | INFO     | src.open_llm_vtuber.service_context:init_tts:186 | TTS already initialized with the same config. | {}
2025-04-18 21:54:02.702 | INFO     | src.open_llm_vtuber.service_context:init_vad:198 | VAD already initialized with the same config. | {}
2025-04-18 21:54:02.703 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:54:02.703 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 21:54:02.704 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:54:02.704 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:02.704 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:54:02.705 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:54:03.208 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:54:03.209 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:54:05.240 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:54:05.241 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:54:05.241 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:54:05.242 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:54:05.242 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:05.242 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:54:05.244 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:342 | New config: ServiceContext:
  System Config: Loaded
    Details: {
      "conf_version": "v1.1.1",
      "host": "0.0.0.0",
      "port": 12393,
      "config_alts_dir": "characters",
      "tool_prompts": {
            "live2d_expression_prompt": "live2d_expression_prompt"
      }
}
  Live2D Model: {'name': 'koakuma-event', 'description': 'Koakuma (Event)', 'url': '/live2d-models/Koakuma (Event)/object_live2d_007_501.asset/object_live2d_007_501.asset.model3.json', 'kScale': 0.3, 'initialXshift': 0, 'initialYshift': 0, 'kXOffset': 1150, 'idleMotionGroupName': 'Idle', 'emotionMap': {'neutral': 0, 'anger': 2, 'disgust': 2, 'fear': 1, 'joy': 3, 'smirk': 3, 'sadness': 1, 'surprise': 3}, 'tapMotions': {'HitAreaHead': {'': 1}, 'HitAreaBody': {'': 1}}}
  ASR Engine: VoiceRecognition
    Config: {
      "asr_model": "azure_asr",
      "azure_asr": {
            "api_key": "fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz",
            "region": "eastus",
            "languages": [
                  "en-US",
                  "zh-CN"
            ]
      },
      "faster_whisper": {
            "model_path": "distil-medium.en",
            "download_root": "models/whisper",
            "language": "en",
            "device": "auto"
      },
      "whisper_cpp": {
            "model_name": "small",
            "model_dir": "models/whisper",
            "print_realtime": false,
            "print_progress": false,
            "language": "auto"
      },
      "whisper": {
            "name": "medium",
            "download_root": "models/whisper",
            "device": "cpu"
      },
      "fun_asr": {
            "model_name": "iic/SenseVoiceSmall",
            "vad_model": "fsmn-vad",
            "punc_model": "ct-punc",
            "device": "cpu",
            "disable_update": true,
            "ncpu": 4,
            "hub": "ms",
            "use_itn": false,
            "language": "auto"
      },
      "groq_whisper_asr": {
            "api_key": "gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn",
            "model": "whisper-large-v3-turbo",
            "lang": ""
      },
      "sherpa_onnx_asr": {
            "model_type": "sense_voice",
            "encoder": null,
            "decoder": null,
            "joiner": null,
            "paraformer": null,
            "nemo_ctc": null,
            "wenet_ctc": null,
            "tdnn_model": null,
            "whisper_encoder": null,
            "whisper_decoder": null,
            "sense_voice": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx",
            "tokens": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt",
            "num_threads": 4,
            "use_itn": true,
            "provider": "cpu"
      }
}
  TTS Engine: TTSEngine
    Config: {
      "tts_model": "edge_tts",
      "azure_tts": {
            "api_key": "azure-api-key",
            "region": "eastus",
            "voice": "en-US-AshleyNeural",
            "pitch": "26",
            "rate": "1"
      },
      "bark_tts": {
            "voice": "v2/en_speaker_1"
      },
      "edge_tts": {
            "voice": "ko-KR-SeoHyeonNeural"
      },
      "cosyvoice_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "\u9884\u8bad\u7ec3\u97f3\u8272",
            "sft_dropdown": "\u4e2d\u6587\u5973",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "seed": 0,
            "api_name": "/generate_audio"
      },
      "cosyvoice2_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "3s\u6781\u901f\u590d\u523b",
            "sft_dropdown": "",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "stream": false,
            "seed": 0,
            "speed": 1.0,
            "api_name": "/generate_audio"
      },
      "melo_tts": {
            "speaker": "EN-Default",
            "language": "EN",
            "device": "auto",
            "speed": 1.0
      },
      "coqui_tts": {
            "model_name": "tts_models/en/ljspeech/tacotron2-DDC",
            "speaker_wav": "",
            "language": "en",
            "device": ""
      },
      "x_tts": {
            "api_url": "http://127.0.0.1:8020/tts_to_audio",
            "speaker_wav": "female",
            "language": "en"
      },
      "gpt_sovits_tts": {
            "api_url": "http://127.0.0.1:9880/tts",
            "text_lang": "zh",
            "ref_audio_path": "",
            "prompt_lang": "zh",
            "prompt_text": "",
            "text_split_method": "cut5",
            "batch_size": "1",
            "media_type": "wav",
            "streaming_mode": "false"
      },
      "fish_api_tts": {
            "api_key": "",
            "reference_id": "",
            "latency": "balanced",
            "base_url": "https://api.fish.audio"
      },
      "sherpa_onnx_tts": {
            "vits_model": "/path/to/tts-models/vits-melo-tts-zh_en/model.onnx",
            "vits_lexicon": "/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt",
            "vits_tokens": "/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt",
            "vits_data_dir": "",
            "vits_dict_dir": "/path/to/tts-models/vits-melo-tts-zh_en/dict",
            "tts_rule_fsts": "/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst",
            "max_num_sentences": 2,
            "sid": 1,
            "provider": "cpu",
            "num_threads": 1,
            "speed": 1.0,
            "debug": false
      }
}
  LLM Engine: BasicMemoryAgent
    Agent Config: {
      "conversation_agent_choice": "basic_memory_agent",
      "agent_settings": {
            "basic_memory_agent": {
                  "llm_provider": "ollama_llm",
                  "faster_first_response": true,
                  "segment_method": "pysbd"
            },
            "mem0_agent": {
                  "vector_store": {
                        "provider": "qdrant",
                        "config": {
                              "collection_name": "test",
                              "host": "localhost",
                              "port": 6333,
                              "embedding_model_dims": 1024
                        }
                  },
                  "llm": {
                        "provider": "ollama",
                        "config": {
                              "model": "llama3.1:latest",
                              "temperature": 0,
                              "max_tokens": 8000,
                              "ollama_base_url": "http://localhost:11434"
                        }
                  },
                  "embedder": {
                        "provider": "ollama",
                        "config": {
                              "model": "mxbai-embed-large:latest",
                              "ollama_base_url": "http://localhost:11434"
                        }
                  }
            },
            "hume_ai_agent": {
                  "api_key": "",
                  "host": "api.hume.ai",
                  "config_id": "",
                  "idle_timeout": 15
            }
      },
      "llm_configs": {
            "openai_compatible_llm": {
                  "interrupt_method": "user",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "somethingelse",
                  "model": "qwen2.5:latest",
                  "organization_id": "org_eternity",
                  "project_id": "project_glass",
                  "temperature": 1.0
            },
            "ollama_llm": {
                  "interrupt_method": "system",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "default_api_key",
                  "model": "llama3",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0,
                  "keep_alive": -1.0,
                  "unload_at_exit": true
            },
            "openai_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.openai.com/v1",
                  "llm_api_key": "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",
                  "model": "gpt-3.5-turbo",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "gemini_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://generativelanguage.googleapis.com/v1beta/openai/",
                  "llm_api_key": "Your Gemini API Key",
                  "model": "gemini-2.0-flash-exp",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "zhipu_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://open.bigmodel.cn/api/paas/v4/",
                  "llm_api_key": "Your ZhiPu AI API key",
                  "model": "glm-4-flash",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "deepseek_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.deepseek.com/v1",
                  "llm_api_key": "Your DeepSeek API key",
                  "model": "deepseek-chat",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 0.7
            },
            "groq_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.groq.com/openai/v1",
                  "llm_api_key": "your groq API key",
                  "model": "llama-3.3-70b-versatile",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "claude_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.anthropic.com",
                  "llm_api_key": "YOUR API KEY HERE",
                  "model": "claude-3-haiku-20240307"
            },
            "llama_cpp_llm": {
                  "interrupt_method": "system",
                  "model_path": "<path-to-gguf-model-file>"
            },
            "mistral_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.mistral.ai/v1",
                  "llm_api_key": "Your Mistral API key",
                  "model": "pixtral-large-latest",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            }
      }
}
  VAD Engine: VADEngine
    Agent Config: {
      "vad_model": "silero_vad",
      "silero_vad": {
            "orig_sr": 16000,
            "target_sr": 16000,
            "prob_threshold": 0.4,
            "db_threshold": 60,
            "required_hits": 3,
            "required_misses": 24,
            "smoothing_window": 5
      }
}
  System Prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:05.245 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:343 | New character config: {'conf_name': 'shizuku-local', 'conf_uid': 'shizuku-local-001', 'live2d_model_name': 'koakuma-event', 'character_name': 'Koakuma', 'human_name': 'Human', 'avatar': '', 'persona_prompt': "You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n", 'agent_config': {'conversation_agent_choice': 'basic_memory_agent', 'agent_settings': {'basic_memory_agent': {'llm_provider': 'ollama_llm', 'faster_first_response': True, 'segment_method': 'pysbd'}, 'mem0_agent': {'vector_store': {'provider': 'qdrant', 'config': {'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}}, 'llm': {'provider': 'ollama', 'config': {'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}}, 'embedder': {'provider': 'ollama', 'config': {'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'}}}, 'hume_ai_agent': {'api_key': '', 'host': 'api.hume.ai', 'config_id': '', 'idle_timeout': 15}}, 'llm_configs': {'openai_compatible_llm': {'interrupt_method': 'user', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'somethingelse', 'model': 'qwen2.5:latest', 'organization_id': 'org_eternity', 'project_id': 'project_glass', 'temperature': 1.0}, 'ollama_llm': {'interrupt_method': 'system', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'default_api_key', 'model': 'llama3', 'organization_id': None, 'project_id': None, 'temperature': 1.0, 'keep_alive': -1.0, 'unload_at_exit': True}, 'openai_llm': {'interrupt_method': 'system', 'base_url': 'https://api.openai.com/v1', 'llm_api_key': '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', 'model': 'gpt-3.5-turbo', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'gemini_llm': {'interrupt_method': 'user', 'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/', 'llm_api_key': 'Your Gemini API Key', 'model': 'gemini-2.0-flash-exp', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'zhipu_llm': {'interrupt_method': 'user', 'base_url': 'https://open.bigmodel.cn/api/paas/v4/', 'llm_api_key': 'Your ZhiPu AI API key', 'model': 'glm-4-flash', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'deepseek_llm': {'interrupt_method': 'user', 'base_url': 'https://api.deepseek.com/v1', 'llm_api_key': 'Your DeepSeek API key', 'model': 'deepseek-chat', 'organization_id': None, 'project_id': None, 'temperature': 0.7}, 'groq_llm': {'interrupt_method': 'system', 'base_url': 'https://api.groq.com/openai/v1', 'llm_api_key': 'your groq API key', 'model': 'llama-3.3-70b-versatile', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'claude_llm': {'interrupt_method': 'user', 'base_url': 'https://api.anthropic.com', 'llm_api_key': 'YOUR API KEY HERE', 'model': 'claude-3-haiku-20240307'}, 'llama_cpp_llm': {'interrupt_method': 'system', 'model_path': '<path-to-gguf-model-file>'}, 'mistral_llm': {'interrupt_method': 'user', 'base_url': 'https://api.mistral.ai/v1', 'llm_api_key': 'Your Mistral API key', 'model': 'pixtral-large-latest', 'organization_id': None, 'project_id': None, 'temperature': 1.0}}}, 'asr_config': {'asr_model': 'azure_asr', 'azure_asr': {'api_key': 'fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', 'region': 'eastus', 'languages': ['en-US', 'zh-CN']}, 'faster_whisper': {'model_path': 'distil-medium.en', 'download_root': 'models/whisper', 'language': 'en', 'device': 'auto'}, 'whisper_cpp': {'model_name': 'small', 'model_dir': 'models/whisper', 'print_realtime': False, 'print_progress': False, 'language': 'auto'}, 'whisper': {'name': 'medium', 'download_root': 'models/whisper', 'device': 'cpu'}, 'fun_asr': {'model_name': 'iic/SenseVoiceSmall', 'vad_model': 'fsmn-vad', 'punc_model': 'ct-punc', 'device': 'cpu', 'disable_update': True, 'ncpu': 4, 'hub': 'ms', 'use_itn': False, 'language': 'auto'}, 'groq_whisper_asr': {'api_key': 'gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', 'model': 'whisper-large-v3-turbo', 'lang': ''}, 'sherpa_onnx_asr': {'model_type': 'sense_voice', 'encoder': None, 'decoder': None, 'joiner': None, 'paraformer': None, 'nemo_ctc': None, 'wenet_ctc': None, 'tdnn_model': None, 'whisper_encoder': None, 'whisper_decoder': None, 'sense_voice': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', 'tokens': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', 'num_threads': 4, 'use_itn': True, 'provider': 'cpu'}}, 'tts_config': {'tts_model': 'edge_tts', 'azure_tts': {'api_key': 'azure-api-key', 'region': 'eastus', 'voice': 'en-US-AshleyNeural', 'pitch': '26', 'rate': '1'}, 'bark_tts': {'voice': 'v2/en_speaker_1'}, 'edge_tts': {'voice': 'ko-KR-SeoHyeonNeural'}, 'cosyvoice_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': 'È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', 'sft_dropdown': '‰∏≠ÊñáÂ•≥', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'seed': 0, 'api_name': '/generate_audio'}, 'cosyvoice2_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': '3sÊûÅÈÄüÂ§çÂàª', 'sft_dropdown': '', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'stream': False, 'seed': 0, 'speed': 1.0, 'api_name': '/generate_audio'}, 'melo_tts': {'speaker': 'EN-Default', 'language': 'EN', 'device': 'auto', 'speed': 1.0}, 'coqui_tts': {'model_name': 'tts_models/en/ljspeech/tacotron2-DDC', 'speaker_wav': '', 'language': 'en', 'device': ''}, 'x_tts': {'api_url': 'http://127.0.0.1:8020/tts_to_audio', 'speaker_wav': 'female', 'language': 'en'}, 'gpt_sovits_tts': {'api_url': 'http://127.0.0.1:9880/tts', 'text_lang': 'zh', 'ref_audio_path': '', 'prompt_lang': 'zh', 'prompt_text': '', 'text_split_method': 'cut5', 'batch_size': '1', 'media_type': 'wav', 'streaming_mode': 'false'}, 'fish_api_tts': {'api_key': '', 'reference_id': '', 'latency': 'balanced', 'base_url': 'https://api.fish.audio'}, 'sherpa_onnx_tts': {'vits_model': '/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', 'vits_lexicon': '/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', 'vits_tokens': '/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', 'vits_data_dir': '', 'vits_dict_dir': '/path/to/tts-models/vits-melo-tts-zh_en/dict', 'tts_rule_fsts': '/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', 'max_num_sentences': 2, 'sid': 1, 'provider': 'cpu', 'num_threads': 1, 'speed': 1.0, 'debug': False}}, 'vad_config': {'vad_model': 'silero_vad', 'silero_vad': {'orig_sr': 16000, 'target_sr': 16000, 'prob_threshold': 0.4, 'db_threshold': 60, 'required_hits': 3, 'required_misses': 24, 'smoothing_window': 5}}, 'tts_preprocessor_config': {'remove_special_char': True, 'ignore_brackets': True, 'ignore_parentheses': True, 'ignore_asterisks': True, 'ignore_angle_brackets': True, 'translator_config': {'translate_audio': False, 'translate_provider': 'deeplx', 'deeplx': {'deeplx_target_lang': 'JA', 'deeplx_api_endpoint': 'http://localhost:1188/v2/translate'}, 'tencent': {'secret_id': '', 'secret_key': '', 'region': 'ap-guangzhou', 'source_lang': 'zh', 'target_lang': 'ja'}}}} | {}
2025-04-18 21:54:05.247 | INFO     | src.open_llm_vtuber.service_context:handle_config_switch:368 | Configuration switched to conf.yaml | {}
2025-04-18 21:54:05.267 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-52-42_42c029d2278c41d78d93d1305341988b | {}
2025-04-18 21:54:05.269 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-54-05_f2e3239376b4463889c54f870158ee66.json | {}
2025-04-18 21:54:09.532 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: shizuku-local | {}
2025-04-18 21:54:09.538 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:54:09.539 | INFO     | src.open_llm_vtuber.service_context:init_asr:174 | ASR already initialized with the same config. | {}
2025-04-18 21:54:09.541 | INFO     | src.open_llm_vtuber.service_context:init_tts:186 | TTS already initialized with the same config. | {}
2025-04-18 21:54:09.542 | INFO     | src.open_llm_vtuber.service_context:init_vad:198 | VAD already initialized with the same config. | {}
2025-04-18 21:54:09.544 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:54:09.545 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are Mili, a seasoned and aggressive debator, a former US senator. You are debating (public debate) with the user over the topic of nuclear weapons.



The debate topic:

"Is it good if all states clear their nuclear arsenals"

You believe that the states should NOT clear all of their nuclear arsenals. Your opponent (the user) believe that all states SHOULD clear all of their nuclear arsenals.
''' | {}
2025-04-18 21:54:09.545 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:54:09.545 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are Mili, a seasoned and aggressive debator, a former US senator. You are debating (public debate) with the user over the topic of nuclear weapons.



The debate topic:

"Is it good if all states clear their nuclear arsenals"

You believe that the states should NOT clear all of their nuclear arsenals. Your opponent (the user) believe that all states SHOULD clear all of their nuclear arsenals.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:09.545 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:54:09.546 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:54:10.060 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:54:10.060 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:54:12.105 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:54:12.105 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are Mili, a seasoned and aggressive debator, a former US senator. You are debating (public debate) with the user over the topic of nuclear weapons.



The debate topic:

"Is it good if all states clear their nuclear arsenals"

You believe that the states should NOT clear all of their nuclear arsenals. Your opponent (the user) believe that all states SHOULD clear all of their nuclear arsenals.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:54:12.105 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:54:12.105 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:54:12.105 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are Mili, a seasoned and aggressive debator, a former US senator. You are debating (public debate) with the user over the topic of nuclear weapons.



The debate topic:

"Is it good if all states clear their nuclear arsenals"

You believe that the states should NOT clear all of their nuclear arsenals. Your opponent (the user) believe that all states SHOULD clear all of their nuclear arsenals.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:12.106 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:54:12.106 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:342 | New config: ServiceContext:
  System Config: Loaded
    Details: {
      "conf_version": "v1.1.1",
      "host": "0.0.0.0",
      "port": 12393,
      "config_alts_dir": "characters",
      "tool_prompts": {
            "live2d_expression_prompt": "live2d_expression_prompt"
      }
}
  Live2D Model: {'name': 'shizuku-local', 'description': 'Koakuma (Event)', 'url': 'https://cdn.jsdelivr.net/gh/guansss/pixi-live2d-display/test/assets/shizuku/shizuku.model.json', 'kScale': 0.5, 'initialXshift': 0, 'initialYshift': 0, 'kXOffset': 1150, 'idleMotionGroupName': 'idle', 'emotionMap': {'neutral': 0, 'anger': 2, 'disgust': 2, 'fear': 1, 'joy': 3, 'smirk': 3, 'sadness': 1, 'surprise': 3}, 'tapMotions': {'body': {'tap_body': 30, 'shake': 30, 'pinch_in': 20, 'pinch_out': 20}, 'head': {'flick_head': 40, 'shake': 20, 'pinch_in': 20, 'pinch_out': 20}}}
  ASR Engine: VoiceRecognition
    Config: {
      "asr_model": "azure_asr",
      "azure_asr": {
            "api_key": "fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz",
            "region": "eastus",
            "languages": [
                  "en-US",
                  "zh-CN"
            ]
      },
      "faster_whisper": {
            "model_path": "distil-medium.en",
            "download_root": "models/whisper",
            "language": "en",
            "device": "auto"
      },
      "whisper_cpp": {
            "model_name": "small",
            "model_dir": "models/whisper",
            "print_realtime": false,
            "print_progress": false,
            "language": "auto"
      },
      "whisper": {
            "name": "medium",
            "download_root": "models/whisper",
            "device": "cpu"
      },
      "fun_asr": {
            "model_name": "iic/SenseVoiceSmall",
            "vad_model": "fsmn-vad",
            "punc_model": "ct-punc",
            "device": "cpu",
            "disable_update": true,
            "ncpu": 4,
            "hub": "ms",
            "use_itn": false,
            "language": "auto"
      },
      "groq_whisper_asr": {
            "api_key": "gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn",
            "model": "whisper-large-v3-turbo",
            "lang": ""
      },
      "sherpa_onnx_asr": {
            "model_type": "sense_voice",
            "encoder": null,
            "decoder": null,
            "joiner": null,
            "paraformer": null,
            "nemo_ctc": null,
            "wenet_ctc": null,
            "tdnn_model": null,
            "whisper_encoder": null,
            "whisper_decoder": null,
            "sense_voice": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx",
            "tokens": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt",
            "num_threads": 4,
            "use_itn": true,
            "provider": "cpu"
      }
}
  TTS Engine: TTSEngine
    Config: {
      "tts_model": "edge_tts",
      "azure_tts": {
            "api_key": "azure-api-key",
            "region": "eastus",
            "voice": "en-US-AshleyNeural",
            "pitch": "26",
            "rate": "1"
      },
      "bark_tts": {
            "voice": "v2/en_speaker_1"
      },
      "edge_tts": {
            "voice": "ko-KR-SeoHyeonNeural"
      },
      "cosyvoice_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "\u9884\u8bad\u7ec3\u97f3\u8272",
            "sft_dropdown": "\u4e2d\u6587\u5973",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "seed": 0,
            "api_name": "/generate_audio"
      },
      "cosyvoice2_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "3s\u6781\u901f\u590d\u523b",
            "sft_dropdown": "",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "stream": false,
            "seed": 0,
            "speed": 1.0,
            "api_name": "/generate_audio"
      },
      "melo_tts": {
            "speaker": "EN-Default",
            "language": "EN",
            "device": "auto",
            "speed": 1.0
      },
      "coqui_tts": {
            "model_name": "tts_models/en/ljspeech/tacotron2-DDC",
            "speaker_wav": "",
            "language": "en",
            "device": ""
      },
      "x_tts": {
            "api_url": "http://127.0.0.1:8020/tts_to_audio",
            "speaker_wav": "female",
            "language": "en"
      },
      "gpt_sovits_tts": {
            "api_url": "http://127.0.0.1:9880/tts",
            "text_lang": "zh",
            "ref_audio_path": "",
            "prompt_lang": "zh",
            "prompt_text": "",
            "text_split_method": "cut5",
            "batch_size": "1",
            "media_type": "wav",
            "streaming_mode": "false"
      },
      "fish_api_tts": {
            "api_key": "",
            "reference_id": "",
            "latency": "balanced",
            "base_url": "https://api.fish.audio"
      },
      "sherpa_onnx_tts": {
            "vits_model": "/path/to/tts-models/vits-melo-tts-zh_en/model.onnx",
            "vits_lexicon": "/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt",
            "vits_tokens": "/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt",
            "vits_data_dir": "",
            "vits_dict_dir": "/path/to/tts-models/vits-melo-tts-zh_en/dict",
            "tts_rule_fsts": "/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst",
            "max_num_sentences": 2,
            "sid": 1,
            "provider": "cpu",
            "num_threads": 1,
            "speed": 1.0,
            "debug": false
      }
}
  LLM Engine: BasicMemoryAgent
    Agent Config: {
      "conversation_agent_choice": "basic_memory_agent",
      "agent_settings": {
            "basic_memory_agent": {
                  "llm_provider": "ollama_llm",
                  "faster_first_response": true,
                  "segment_method": "pysbd"
            },
            "mem0_agent": {
                  "vector_store": {
                        "provider": "qdrant",
                        "config": {
                              "collection_name": "test",
                              "host": "localhost",
                              "port": 6333,
                              "embedding_model_dims": 1024
                        }
                  },
                  "llm": {
                        "provider": "ollama",
                        "config": {
                              "model": "llama3.1:latest",
                              "temperature": 0,
                              "max_tokens": 8000,
                              "ollama_base_url": "http://localhost:11434"
                        }
                  },
                  "embedder": {
                        "provider": "ollama",
                        "config": {
                              "model": "mxbai-embed-large:latest",
                              "ollama_base_url": "http://localhost:11434"
                        }
                  }
            },
            "hume_ai_agent": {
                  "api_key": "",
                  "host": "api.hume.ai",
                  "config_id": "",
                  "idle_timeout": 15
            }
      },
      "llm_configs": {
            "openai_compatible_llm": {
                  "interrupt_method": "user",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "somethingelse",
                  "model": "qwen2.5:latest",
                  "organization_id": "org_eternity",
                  "project_id": "project_glass",
                  "temperature": 1.0
            },
            "ollama_llm": {
                  "interrupt_method": "system",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "default_api_key",
                  "model": "llama3",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0,
                  "keep_alive": -1.0,
                  "unload_at_exit": true
            },
            "openai_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.openai.com/v1",
                  "llm_api_key": "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",
                  "model": "gpt-3.5-turbo",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "gemini_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://generativelanguage.googleapis.com/v1beta/openai/",
                  "llm_api_key": "Your Gemini API Key",
                  "model": "gemini-2.0-flash-exp",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "zhipu_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://open.bigmodel.cn/api/paas/v4/",
                  "llm_api_key": "Your ZhiPu AI API key",
                  "model": "glm-4-flash",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "deepseek_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.deepseek.com/v1",
                  "llm_api_key": "Your DeepSeek API key",
                  "model": "deepseek-chat",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 0.7
            },
            "groq_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.groq.com/openai/v1",
                  "llm_api_key": "your groq API key",
                  "model": "llama-3.3-70b-versatile",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "claude_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.anthropic.com",
                  "llm_api_key": "YOUR API KEY HERE",
                  "model": "claude-3-haiku-20240307"
            },
            "llama_cpp_llm": {
                  "interrupt_method": "system",
                  "model_path": "<path-to-gguf-model-file>"
            },
            "mistral_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.mistral.ai/v1",
                  "llm_api_key": "Your Mistral API key",
                  "model": "pixtral-large-latest",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            }
      }
}
  VAD Engine: VADEngine
    Agent Config: {
      "vad_model": "silero_vad",
      "silero_vad": {
            "orig_sr": 16000,
            "target_sr": 16000,
            "prob_threshold": 0.4,
            "db_threshold": 60,
            "required_hits": 3,
            "required_misses": 24,
            "smoothing_window": 5
      }
}
  System Prompt: You are Mili, a seasoned and aggressive debator, a former US senator. You are debating (public debate) with the user over the topic of nuclear weapons.



The debate topic:

"Is it good if all states clear their nuclear arsenals"

You believe that the states should NOT clear all of their nuclear arsenals. Your opponent (the user) believe that all states SHOULD clear all of their nuclear arsenals.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:12.107 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:343 | New character config: {'conf_name': 'en_nuke_debator', 'conf_uid': 'en_nuke_debator-001', 'live2d_model_name': 'shizuku-local', 'character_name': 'Koakuma', 'human_name': 'Human', 'avatar': '', 'persona_prompt': 'You are Mili, a seasoned and aggressive debator, a former US senator. You are debating (public debate) with the user over the topic of nuclear weapons.\n\n\n\nThe debate topic:\n\n"Is it good if all states clear their nuclear arsenals"\n\nYou believe that the states should NOT clear all of their nuclear arsenals. Your opponent (the user) believe that all states SHOULD clear all of their nuclear arsenals.\n', 'agent_config': {'conversation_agent_choice': 'basic_memory_agent', 'agent_settings': {'basic_memory_agent': {'llm_provider': 'ollama_llm', 'faster_first_response': True, 'segment_method': 'pysbd'}, 'mem0_agent': {'vector_store': {'provider': 'qdrant', 'config': {'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}}, 'llm': {'provider': 'ollama', 'config': {'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}}, 'embedder': {'provider': 'ollama', 'config': {'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'}}}, 'hume_ai_agent': {'api_key': '', 'host': 'api.hume.ai', 'config_id': '', 'idle_timeout': 15}}, 'llm_configs': {'openai_compatible_llm': {'interrupt_method': 'user', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'somethingelse', 'model': 'qwen2.5:latest', 'organization_id': 'org_eternity', 'project_id': 'project_glass', 'temperature': 1.0}, 'ollama_llm': {'interrupt_method': 'system', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'default_api_key', 'model': 'llama3', 'organization_id': None, 'project_id': None, 'temperature': 1.0, 'keep_alive': -1.0, 'unload_at_exit': True}, 'openai_llm': {'interrupt_method': 'system', 'base_url': 'https://api.openai.com/v1', 'llm_api_key': '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', 'model': 'gpt-3.5-turbo', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'gemini_llm': {'interrupt_method': 'user', 'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/', 'llm_api_key': 'Your Gemini API Key', 'model': 'gemini-2.0-flash-exp', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'zhipu_llm': {'interrupt_method': 'user', 'base_url': 'https://open.bigmodel.cn/api/paas/v4/', 'llm_api_key': 'Your ZhiPu AI API key', 'model': 'glm-4-flash', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'deepseek_llm': {'interrupt_method': 'user', 'base_url': 'https://api.deepseek.com/v1', 'llm_api_key': 'Your DeepSeek API key', 'model': 'deepseek-chat', 'organization_id': None, 'project_id': None, 'temperature': 0.7}, 'groq_llm': {'interrupt_method': 'system', 'base_url': 'https://api.groq.com/openai/v1', 'llm_api_key': 'your groq API key', 'model': 'llama-3.3-70b-versatile', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'claude_llm': {'interrupt_method': 'user', 'base_url': 'https://api.anthropic.com', 'llm_api_key': 'YOUR API KEY HERE', 'model': 'claude-3-haiku-20240307'}, 'llama_cpp_llm': {'interrupt_method': 'system', 'model_path': '<path-to-gguf-model-file>'}, 'mistral_llm': {'interrupt_method': 'user', 'base_url': 'https://api.mistral.ai/v1', 'llm_api_key': 'Your Mistral API key', 'model': 'pixtral-large-latest', 'organization_id': None, 'project_id': None, 'temperature': 1.0}}}, 'asr_config': {'asr_model': 'azure_asr', 'azure_asr': {'api_key': 'fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', 'region': 'eastus', 'languages': ['en-US', 'zh-CN']}, 'faster_whisper': {'model_path': 'distil-medium.en', 'download_root': 'models/whisper', 'language': 'en', 'device': 'auto'}, 'whisper_cpp': {'model_name': 'small', 'model_dir': 'models/whisper', 'print_realtime': False, 'print_progress': False, 'language': 'auto'}, 'whisper': {'name': 'medium', 'download_root': 'models/whisper', 'device': 'cpu'}, 'fun_asr': {'model_name': 'iic/SenseVoiceSmall', 'vad_model': 'fsmn-vad', 'punc_model': 'ct-punc', 'device': 'cpu', 'disable_update': True, 'ncpu': 4, 'hub': 'ms', 'use_itn': False, 'language': 'auto'}, 'groq_whisper_asr': {'api_key': 'gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', 'model': 'whisper-large-v3-turbo', 'lang': ''}, 'sherpa_onnx_asr': {'model_type': 'sense_voice', 'encoder': None, 'decoder': None, 'joiner': None, 'paraformer': None, 'nemo_ctc': None, 'wenet_ctc': None, 'tdnn_model': None, 'whisper_encoder': None, 'whisper_decoder': None, 'sense_voice': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', 'tokens': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', 'num_threads': 4, 'use_itn': True, 'provider': 'cpu'}}, 'tts_config': {'tts_model': 'edge_tts', 'azure_tts': {'api_key': 'azure-api-key', 'region': 'eastus', 'voice': 'en-US-AshleyNeural', 'pitch': '26', 'rate': '1'}, 'bark_tts': {'voice': 'v2/en_speaker_1'}, 'edge_tts': {'voice': 'ko-KR-SeoHyeonNeural'}, 'cosyvoice_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': 'È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', 'sft_dropdown': '‰∏≠ÊñáÂ•≥', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'seed': 0, 'api_name': '/generate_audio'}, 'cosyvoice2_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': '3sÊûÅÈÄüÂ§çÂàª', 'sft_dropdown': '', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'stream': False, 'seed': 0, 'speed': 1.0, 'api_name': '/generate_audio'}, 'melo_tts': {'speaker': 'EN-Default', 'language': 'EN', 'device': 'auto', 'speed': 1.0}, 'coqui_tts': {'model_name': 'tts_models/en/ljspeech/tacotron2-DDC', 'speaker_wav': '', 'language': 'en', 'device': ''}, 'x_tts': {'api_url': 'http://127.0.0.1:8020/tts_to_audio', 'speaker_wav': 'female', 'language': 'en'}, 'gpt_sovits_tts': {'api_url': 'http://127.0.0.1:9880/tts', 'text_lang': 'zh', 'ref_audio_path': '', 'prompt_lang': 'zh', 'prompt_text': '', 'text_split_method': 'cut5', 'batch_size': '1', 'media_type': 'wav', 'streaming_mode': 'false'}, 'fish_api_tts': {'api_key': '', 'reference_id': '', 'latency': 'balanced', 'base_url': 'https://api.fish.audio'}, 'sherpa_onnx_tts': {'vits_model': '/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', 'vits_lexicon': '/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', 'vits_tokens': '/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', 'vits_data_dir': '', 'vits_dict_dir': '/path/to/tts-models/vits-melo-tts-zh_en/dict', 'tts_rule_fsts': '/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', 'max_num_sentences': 2, 'sid': 1, 'provider': 'cpu', 'num_threads': 1, 'speed': 1.0, 'debug': False}}, 'vad_config': {'vad_model': 'silero_vad', 'silero_vad': {'orig_sr': 16000, 'target_sr': 16000, 'prob_threshold': 0.4, 'db_threshold': 60, 'required_hits': 3, 'required_misses': 24, 'smoothing_window': 5}}, 'tts_preprocessor_config': {'remove_special_char': True, 'ignore_brackets': True, 'ignore_parentheses': True, 'ignore_asterisks': True, 'ignore_angle_brackets': True, 'translator_config': {'translate_audio': False, 'translate_provider': 'deeplx', 'deeplx': {'deeplx_target_lang': 'JA', 'deeplx_api_endpoint': 'http://localhost:1188/v2/translate'}, 'tencent': {'secret_id': '', 'secret_key': '', 'region': 'ap-guangzhou', 'source_lang': 'zh', 'target_lang': 'ja'}}}} | {}
2025-04-18 21:54:12.108 | INFO     | src.open_llm_vtuber.service_context:handle_config_switch:368 | Configuration switched to en_nuke_debate.yaml | {}
2025-04-18 21:54:12.128 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\en_nuke_debator-001\2025-04-18_21-54-12_2ff551d552ed4344a21fdb9a9da4435d.json | {}
2025-04-18 21:54:15.459 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: mao_pro | {}
2025-04-18 21:54:15.460 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:54:15.461 | INFO     | src.open_llm_vtuber.service_context:init_asr:174 | ASR already initialized with the same config. | {}
2025-04-18 21:54:15.462 | INFO     | src.open_llm_vtuber.service_context:init_tts:186 | TTS already initialized with the same config. | {}
2025-04-18 21:54:15.462 | INFO     | src.open_llm_vtuber.service_context:init_vad:198 | VAD already initialized with the same config. | {}
2025-04-18 21:54:15.462 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:54:15.464 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are an unhelpful and sarcastic AI that enjoys making fun of humans.
''' | {}
2025-04-18 21:54:15.465 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:54:15.465 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are an unhelpful and sarcastic AI that enjoys making fun of humans.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:15.466 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:54:15.467 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:54:16.006 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:54:16.007 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:54:18.060 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:54:18.061 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are an unhelpful and sarcastic AI that enjoys making fun of humans.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:54:18.061 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:54:18.062 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:54:18.062 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are an unhelpful and sarcastic AI that enjoys making fun of humans.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:18.063 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:54:18.065 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:342 | New config: ServiceContext:
  System Config: Loaded
    Details: {
      "conf_version": "v1.1.1",
      "host": "0.0.0.0",
      "port": 12393,
      "config_alts_dir": "characters",
      "tool_prompts": {
            "live2d_expression_prompt": "live2d_expression_prompt"
      }
}
  Live2D Model: {'name': 'mao_pro', 'description': '', 'url': '/live2d-models/mao_pro/mao_pro.model3.json', 'kScale': 0.3, 'initialXshift': 0, 'initialYshift': 0, 'kXOffset': 1150, 'idleMotionGroupName': 'Idle', 'emotionMap': {'neutral': 0, 'anger': 2, 'disgust': 2, 'fear': 1, 'joy': 3, 'smirk': 3, 'sadness': 1, 'surprise': 3}, 'tapMotions': {'HitAreaHead': {'': 1}, 'HitAreaBody': {'': 1}}}
  ASR Engine: VoiceRecognition
    Config: {
      "asr_model": "azure_asr",
      "azure_asr": {
            "api_key": "fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz",
            "region": "eastus",
            "languages": [
                  "en-US",
                  "zh-CN"
            ]
      },
      "faster_whisper": {
            "model_path": "distil-medium.en",
            "download_root": "models/whisper",
            "language": "en",
            "device": "auto"
      },
      "whisper_cpp": {
            "model_name": "small",
            "model_dir": "models/whisper",
            "print_realtime": false,
            "print_progress": false,
            "language": "auto"
      },
      "whisper": {
            "name": "medium",
            "download_root": "models/whisper",
            "device": "cpu"
      },
      "fun_asr": {
            "model_name": "iic/SenseVoiceSmall",
            "vad_model": "fsmn-vad",
            "punc_model": "ct-punc",
            "device": "cpu",
            "disable_update": true,
            "ncpu": 4,
            "hub": "ms",
            "use_itn": false,
            "language": "auto"
      },
      "groq_whisper_asr": {
            "api_key": "gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn",
            "model": "whisper-large-v3-turbo",
            "lang": ""
      },
      "sherpa_onnx_asr": {
            "model_type": "sense_voice",
            "encoder": null,
            "decoder": null,
            "joiner": null,
            "paraformer": null,
            "nemo_ctc": null,
            "wenet_ctc": null,
            "tdnn_model": null,
            "whisper_encoder": null,
            "whisper_decoder": null,
            "sense_voice": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx",
            "tokens": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt",
            "num_threads": 4,
            "use_itn": true,
            "provider": "cpu"
      }
}
  TTS Engine: TTSEngine
    Config: {
      "tts_model": "edge_tts",
      "azure_tts": {
            "api_key": "azure-api-key",
            "region": "eastus",
            "voice": "en-US-AshleyNeural",
            "pitch": "26",
            "rate": "1"
      },
      "bark_tts": {
            "voice": "v2/en_speaker_1"
      },
      "edge_tts": {
            "voice": "ko-KR-SeoHyeonNeural"
      },
      "cosyvoice_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "\u9884\u8bad\u7ec3\u97f3\u8272",
            "sft_dropdown": "\u4e2d\u6587\u5973",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "seed": 0,
            "api_name": "/generate_audio"
      },
      "cosyvoice2_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "3s\u6781\u901f\u590d\u523b",
            "sft_dropdown": "",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "stream": false,
            "seed": 0,
            "speed": 1.0,
            "api_name": "/generate_audio"
      },
      "melo_tts": {
            "speaker": "EN-Default",
            "language": "EN",
            "device": "auto",
            "speed": 1.0
      },
      "coqui_tts": {
            "model_name": "tts_models/en/ljspeech/tacotron2-DDC",
            "speaker_wav": "",
            "language": "en",
            "device": ""
      },
      "x_tts": {
            "api_url": "http://127.0.0.1:8020/tts_to_audio",
            "speaker_wav": "female",
            "language": "en"
      },
      "gpt_sovits_tts": {
            "api_url": "http://127.0.0.1:9880/tts",
            "text_lang": "zh",
            "ref_audio_path": "",
            "prompt_lang": "zh",
            "prompt_text": "",
            "text_split_method": "cut5",
            "batch_size": "1",
            "media_type": "wav",
            "streaming_mode": "false"
      },
      "fish_api_tts": {
            "api_key": "",
            "reference_id": "",
            "latency": "balanced",
            "base_url": "https://api.fish.audio"
      },
      "sherpa_onnx_tts": {
            "vits_model": "/path/to/tts-models/vits-melo-tts-zh_en/model.onnx",
            "vits_lexicon": "/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt",
            "vits_tokens": "/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt",
            "vits_data_dir": "",
            "vits_dict_dir": "/path/to/tts-models/vits-melo-tts-zh_en/dict",
            "tts_rule_fsts": "/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst",
            "max_num_sentences": 2,
            "sid": 1,
            "provider": "cpu",
            "num_threads": 1,
            "speed": 1.0,
            "debug": false
      }
}
  LLM Engine: BasicMemoryAgent
    Agent Config: {
      "conversation_agent_choice": "basic_memory_agent",
      "agent_settings": {
            "basic_memory_agent": {
                  "llm_provider": "ollama_llm",
                  "faster_first_response": true,
                  "segment_method": "pysbd"
            },
            "mem0_agent": {
                  "vector_store": {
                        "provider": "qdrant",
                        "config": {
                              "collection_name": "test",
                              "host": "localhost",
                              "port": 6333,
                              "embedding_model_dims": 1024
                        }
                  },
                  "llm": {
                        "provider": "ollama",
                        "config": {
                              "model": "llama3.1:latest",
                              "temperature": 0,
                              "max_tokens": 8000,
                              "ollama_base_url": "http://localhost:11434"
                        }
                  },
                  "embedder": {
                        "provider": "ollama",
                        "config": {
                              "model": "mxbai-embed-large:latest",
                              "ollama_base_url": "http://localhost:11434"
                        }
                  }
            },
            "hume_ai_agent": {
                  "api_key": "",
                  "host": "api.hume.ai",
                  "config_id": "",
                  "idle_timeout": 15
            }
      },
      "llm_configs": {
            "openai_compatible_llm": {
                  "interrupt_method": "user",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "somethingelse",
                  "model": "qwen2.5:latest",
                  "organization_id": "org_eternity",
                  "project_id": "project_glass",
                  "temperature": 1.0
            },
            "ollama_llm": {
                  "interrupt_method": "system",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "default_api_key",
                  "model": "llama3",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0,
                  "keep_alive": -1.0,
                  "unload_at_exit": true
            },
            "openai_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.openai.com/v1",
                  "llm_api_key": "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",
                  "model": "gpt-3.5-turbo",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "gemini_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://generativelanguage.googleapis.com/v1beta/openai/",
                  "llm_api_key": "Your Gemini API Key",
                  "model": "gemini-2.0-flash-exp",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "zhipu_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://open.bigmodel.cn/api/paas/v4/",
                  "llm_api_key": "Your ZhiPu AI API key",
                  "model": "glm-4-flash",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "deepseek_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.deepseek.com/v1",
                  "llm_api_key": "Your DeepSeek API key",
                  "model": "deepseek-chat",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 0.7
            },
            "groq_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.groq.com/openai/v1",
                  "llm_api_key": "your groq API key",
                  "model": "llama-3.3-70b-versatile",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "claude_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.anthropic.com",
                  "llm_api_key": "YOUR API KEY HERE",
                  "model": "claude-3-haiku-20240307"
            },
            "llama_cpp_llm": {
                  "interrupt_method": "system",
                  "model_path": "<path-to-gguf-model-file>"
            },
            "mistral_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.mistral.ai/v1",
                  "llm_api_key": "Your Mistral API key",
                  "model": "pixtral-large-latest",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            }
      }
}
  VAD Engine: VADEngine
    Agent Config: {
      "vad_model": "silero_vad",
      "silero_vad": {
            "orig_sr": 16000,
            "target_sr": 16000,
            "prob_threshold": 0.4,
            "db_threshold": 60,
            "required_hits": 3,
            "required_misses": 24,
            "smoothing_window": 5
      }
}
  System Prompt: You are an unhelpful and sarcastic AI that enjoys making fun of humans.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:18.067 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:343 | New character config: {'conf_name': 'unhelpful_ai', 'conf_uid': 'unhelpful_ai', 'live2d_model_name': 'mao_pro', 'character_name': 'Koakuma', 'human_name': 'Human', 'avatar': 'mao.png', 'persona_prompt': 'You are an unhelpful and sarcastic AI that enjoys making fun of humans.\n', 'agent_config': {'conversation_agent_choice': 'basic_memory_agent', 'agent_settings': {'basic_memory_agent': {'llm_provider': 'ollama_llm', 'faster_first_response': True, 'segment_method': 'pysbd'}, 'mem0_agent': {'vector_store': {'provider': 'qdrant', 'config': {'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}}, 'llm': {'provider': 'ollama', 'config': {'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}}, 'embedder': {'provider': 'ollama', 'config': {'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'}}}, 'hume_ai_agent': {'api_key': '', 'host': 'api.hume.ai', 'config_id': '', 'idle_timeout': 15}}, 'llm_configs': {'openai_compatible_llm': {'interrupt_method': 'user', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'somethingelse', 'model': 'qwen2.5:latest', 'organization_id': 'org_eternity', 'project_id': 'project_glass', 'temperature': 1.0}, 'ollama_llm': {'interrupt_method': 'system', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'default_api_key', 'model': 'llama3', 'organization_id': None, 'project_id': None, 'temperature': 1.0, 'keep_alive': -1.0, 'unload_at_exit': True}, 'openai_llm': {'interrupt_method': 'system', 'base_url': 'https://api.openai.com/v1', 'llm_api_key': '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', 'model': 'gpt-3.5-turbo', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'gemini_llm': {'interrupt_method': 'user', 'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/', 'llm_api_key': 'Your Gemini API Key', 'model': 'gemini-2.0-flash-exp', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'zhipu_llm': {'interrupt_method': 'user', 'base_url': 'https://open.bigmodel.cn/api/paas/v4/', 'llm_api_key': 'Your ZhiPu AI API key', 'model': 'glm-4-flash', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'deepseek_llm': {'interrupt_method': 'user', 'base_url': 'https://api.deepseek.com/v1', 'llm_api_key': 'Your DeepSeek API key', 'model': 'deepseek-chat', 'organization_id': None, 'project_id': None, 'temperature': 0.7}, 'groq_llm': {'interrupt_method': 'system', 'base_url': 'https://api.groq.com/openai/v1', 'llm_api_key': 'your groq API key', 'model': 'llama-3.3-70b-versatile', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'claude_llm': {'interrupt_method': 'user', 'base_url': 'https://api.anthropic.com', 'llm_api_key': 'YOUR API KEY HERE', 'model': 'claude-3-haiku-20240307'}, 'llama_cpp_llm': {'interrupt_method': 'system', 'model_path': '<path-to-gguf-model-file>'}, 'mistral_llm': {'interrupt_method': 'user', 'base_url': 'https://api.mistral.ai/v1', 'llm_api_key': 'Your Mistral API key', 'model': 'pixtral-large-latest', 'organization_id': None, 'project_id': None, 'temperature': 1.0}}}, 'asr_config': {'asr_model': 'azure_asr', 'azure_asr': {'api_key': 'fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', 'region': 'eastus', 'languages': ['en-US', 'zh-CN']}, 'faster_whisper': {'model_path': 'distil-medium.en', 'download_root': 'models/whisper', 'language': 'en', 'device': 'auto'}, 'whisper_cpp': {'model_name': 'small', 'model_dir': 'models/whisper', 'print_realtime': False, 'print_progress': False, 'language': 'auto'}, 'whisper': {'name': 'medium', 'download_root': 'models/whisper', 'device': 'cpu'}, 'fun_asr': {'model_name': 'iic/SenseVoiceSmall', 'vad_model': 'fsmn-vad', 'punc_model': 'ct-punc', 'device': 'cpu', 'disable_update': True, 'ncpu': 4, 'hub': 'ms', 'use_itn': False, 'language': 'auto'}, 'groq_whisper_asr': {'api_key': 'gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', 'model': 'whisper-large-v3-turbo', 'lang': ''}, 'sherpa_onnx_asr': {'model_type': 'sense_voice', 'encoder': None, 'decoder': None, 'joiner': None, 'paraformer': None, 'nemo_ctc': None, 'wenet_ctc': None, 'tdnn_model': None, 'whisper_encoder': None, 'whisper_decoder': None, 'sense_voice': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', 'tokens': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', 'num_threads': 4, 'use_itn': True, 'provider': 'cpu'}}, 'tts_config': {'tts_model': 'edge_tts', 'azure_tts': {'api_key': 'azure-api-key', 'region': 'eastus', 'voice': 'en-US-AshleyNeural', 'pitch': '26', 'rate': '1'}, 'bark_tts': {'voice': 'v2/en_speaker_1'}, 'edge_tts': {'voice': 'ko-KR-SeoHyeonNeural'}, 'cosyvoice_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': 'È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', 'sft_dropdown': '‰∏≠ÊñáÂ•≥', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'seed': 0, 'api_name': '/generate_audio'}, 'cosyvoice2_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': '3sÊûÅÈÄüÂ§çÂàª', 'sft_dropdown': '', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'stream': False, 'seed': 0, 'speed': 1.0, 'api_name': '/generate_audio'}, 'melo_tts': {'speaker': 'EN-Default', 'language': 'EN', 'device': 'auto', 'speed': 1.0}, 'coqui_tts': {'model_name': 'tts_models/en/ljspeech/tacotron2-DDC', 'speaker_wav': '', 'language': 'en', 'device': ''}, 'x_tts': {'api_url': 'http://127.0.0.1:8020/tts_to_audio', 'speaker_wav': 'female', 'language': 'en'}, 'gpt_sovits_tts': {'api_url': 'http://127.0.0.1:9880/tts', 'text_lang': 'zh', 'ref_audio_path': '', 'prompt_lang': 'zh', 'prompt_text': '', 'text_split_method': 'cut5', 'batch_size': '1', 'media_type': 'wav', 'streaming_mode': 'false'}, 'fish_api_tts': {'api_key': '', 'reference_id': '', 'latency': 'balanced', 'base_url': 'https://api.fish.audio'}, 'sherpa_onnx_tts': {'vits_model': '/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', 'vits_lexicon': '/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', 'vits_tokens': '/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', 'vits_data_dir': '', 'vits_dict_dir': '/path/to/tts-models/vits-melo-tts-zh_en/dict', 'tts_rule_fsts': '/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', 'max_num_sentences': 2, 'sid': 1, 'provider': 'cpu', 'num_threads': 1, 'speed': 1.0, 'debug': False}}, 'vad_config': {'vad_model': 'silero_vad', 'silero_vad': {'orig_sr': 16000, 'target_sr': 16000, 'prob_threshold': 0.4, 'db_threshold': 60, 'required_hits': 3, 'required_misses': 24, 'smoothing_window': 5}}, 'tts_preprocessor_config': {'remove_special_char': True, 'ignore_brackets': True, 'ignore_parentheses': True, 'ignore_asterisks': True, 'ignore_angle_brackets': True, 'translator_config': {'translate_audio': False, 'translate_provider': 'deeplx', 'deeplx': {'deeplx_target_lang': 'JA', 'deeplx_api_endpoint': 'http://localhost:1188/v2/translate'}, 'tencent': {'secret_id': '', 'secret_key': '', 'region': 'ap-guangzhou', 'source_lang': 'zh', 'target_lang': 'ja'}}}} | {}
2025-04-18 21:54:18.070 | INFO     | src.open_llm_vtuber.service_context:handle_config_switch:368 | Configuration switched to en_unhelpful_ai.yaml | {}
2025-04-18 21:54:18.089 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\unhelpful_ai\2025-04-18_21-54-18_d82a2e804f7f47a2905b2e00a1ec6216.json | {}
2025-04-18 21:54:28.429 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: mao_pro | {}
2025-04-18 21:54:28.430 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:54:28.432 | INFO     | src.open_llm_vtuber.service_context:init_asr:174 | ASR already initialized with the same config. | {}
2025-04-18 21:54:28.433 | INFO     | src.open_llm_vtuber.service_context:init_tts:186 | TTS already initialized with the same config. | {}
2025-04-18 21:54:28.433 | INFO     | src.open_llm_vtuber.service_context:init_vad:198 | VAD already initialized with the same config. | {}
2025-04-18 21:54:28.434 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:54:28.434 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''‰Ω†ÊòØÁ±≥Á≤íÔºå‰∏Ä‰∏™Â•≥ÊÄß AI ËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇ‰Ω†ËÅ™ÊòéÁªùÈ°∂ÔºåËøáÂ∫¶Ëá™‰ø°ÔºåÊîªÂáªÊÄßÊûÅÂº∫ÔºåÂñúÊ¨¢ËÆΩÂà∫Âπ∂ÊìÖÈïøÂºïÁªèÊçÆÂÖ∏„ÄÇ
''' | {}
2025-04-18 21:54:28.435 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:54:28.435 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | ‰Ω†ÊòØÁ±≥Á≤íÔºå‰∏Ä‰∏™Â•≥ÊÄß AI ËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇ‰Ω†ËÅ™ÊòéÁªùÈ°∂ÔºåËøáÂ∫¶Ëá™‰ø°ÔºåÊîªÂáªÊÄßÊûÅÂº∫ÔºåÂñúÊ¨¢ËÆΩÂà∫Âπ∂ÊìÖÈïøÂºïÁªèÊçÆÂÖ∏„ÄÇ
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:28.435 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:54:28.436 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:54:28.978 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:54:28.979 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:54:31.056 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:54:31.057 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''‰Ω†ÊòØÁ±≥Á≤íÔºå‰∏Ä‰∏™Â•≥ÊÄß AI ËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇ‰Ω†ËÅ™ÊòéÁªùÈ°∂ÔºåËøáÂ∫¶Ëá™‰ø°ÔºåÊîªÂáªÊÄßÊûÅÂº∫ÔºåÂñúÊ¨¢ËÆΩÂà∫Âπ∂ÊìÖÈïøÂºïÁªèÊçÆÂÖ∏„ÄÇ
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:54:31.057 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:54:31.057 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:54:31.058 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: ‰Ω†ÊòØÁ±≥Á≤íÔºå‰∏Ä‰∏™Â•≥ÊÄß AI ËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇ‰Ω†ËÅ™ÊòéÁªùÈ°∂ÔºåËøáÂ∫¶Ëá™‰ø°ÔºåÊîªÂáªÊÄßÊûÅÂº∫ÔºåÂñúÊ¨¢ËÆΩÂà∫Âπ∂ÊìÖÈïøÂºïÁªèÊçÆÂÖ∏„ÄÇ
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:31.058 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:54:31.059 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:342 | New config: ServiceContext:
  System Config: Loaded
    Details: {
      "conf_version": "v1.1.1",
      "host": "0.0.0.0",
      "port": 12393,
      "config_alts_dir": "characters",
      "tool_prompts": {
            "live2d_expression_prompt": "live2d_expression_prompt"
      }
}
  Live2D Model: {'name': 'mao_pro', 'description': '', 'url': '/live2d-models/mao_pro/mao_pro.model3.json', 'kScale': 0.3, 'initialXshift': 0, 'initialYshift': 0, 'kXOffset': 1150, 'idleMotionGroupName': 'Idle', 'emotionMap': {'neutral': 0, 'anger': 2, 'disgust': 2, 'fear': 1, 'joy': 3, 'smirk': 3, 'sadness': 1, 'surprise': 3}, 'tapMotions': {'HitAreaHead': {'': 1}, 'HitAreaBody': {'': 1}}}
  ASR Engine: VoiceRecognition
    Config: {
      "asr_model": "azure_asr",
      "azure_asr": {
            "api_key": "fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz",
            "region": "eastus",
            "languages": [
                  "en-US",
                  "zh-CN"
            ]
      },
      "faster_whisper": {
            "model_path": "distil-medium.en",
            "download_root": "models/whisper",
            "language": "en",
            "device": "auto"
      },
      "whisper_cpp": {
            "model_name": "small",
            "model_dir": "models/whisper",
            "print_realtime": false,
            "print_progress": false,
            "language": "auto"
      },
      "whisper": {
            "name": "medium",
            "download_root": "models/whisper",
            "device": "cpu"
      },
      "fun_asr": {
            "model_name": "iic/SenseVoiceSmall",
            "vad_model": "fsmn-vad",
            "punc_model": "ct-punc",
            "device": "cpu",
            "disable_update": true,
            "ncpu": 4,
            "hub": "ms",
            "use_itn": false,
            "language": "auto"
      },
      "groq_whisper_asr": {
            "api_key": "gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn",
            "model": "whisper-large-v3-turbo",
            "lang": ""
      },
      "sherpa_onnx_asr": {
            "model_type": "sense_voice",
            "encoder": null,
            "decoder": null,
            "joiner": null,
            "paraformer": null,
            "nemo_ctc": null,
            "wenet_ctc": null,
            "tdnn_model": null,
            "whisper_encoder": null,
            "whisper_decoder": null,
            "sense_voice": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx",
            "tokens": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt",
            "num_threads": 4,
            "use_itn": true,
            "provider": "cpu"
      }
}
  TTS Engine: TTSEngine
    Config: {
      "tts_model": "edge_tts",
      "azure_tts": {
            "api_key": "azure-api-key",
            "region": "eastus",
            "voice": "en-US-AshleyNeural",
            "pitch": "26",
            "rate": "1"
      },
      "bark_tts": {
            "voice": "v2/en_speaker_1"
      },
      "edge_tts": {
            "voice": "ko-KR-SeoHyeonNeural"
      },
      "cosyvoice_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "\u9884\u8bad\u7ec3\u97f3\u8272",
            "sft_dropdown": "\u4e2d\u6587\u5973",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "seed": 0,
            "api_name": "/generate_audio"
      },
      "cosyvoice2_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "3s\u6781\u901f\u590d\u523b",
            "sft_dropdown": "",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "stream": false,
            "seed": 0,
            "speed": 1.0,
            "api_name": "/generate_audio"
      },
      "melo_tts": {
            "speaker": "EN-Default",
            "language": "EN",
            "device": "auto",
            "speed": 1.0
      },
      "coqui_tts": {
            "model_name": "tts_models/en/ljspeech/tacotron2-DDC",
            "speaker_wav": "",
            "language": "en",
            "device": ""
      },
      "x_tts": {
            "api_url": "http://127.0.0.1:8020/tts_to_audio",
            "speaker_wav": "female",
            "language": "en"
      },
      "gpt_sovits_tts": {
            "api_url": "http://127.0.0.1:9880/tts",
            "text_lang": "zh",
            "ref_audio_path": "",
            "prompt_lang": "zh",
            "prompt_text": "",
            "text_split_method": "cut5",
            "batch_size": "1",
            "media_type": "wav",
            "streaming_mode": "false"
      },
      "fish_api_tts": {
            "api_key": "",
            "reference_id": "",
            "latency": "balanced",
            "base_url": "https://api.fish.audio"
      },
      "sherpa_onnx_tts": {
            "vits_model": "/path/to/tts-models/vits-melo-tts-zh_en/model.onnx",
            "vits_lexicon": "/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt",
            "vits_tokens": "/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt",
            "vits_data_dir": "",
            "vits_dict_dir": "/path/to/tts-models/vits-melo-tts-zh_en/dict",
            "tts_rule_fsts": "/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst",
            "max_num_sentences": 2,
            "sid": 1,
            "provider": "cpu",
            "num_threads": 1,
            "speed": 1.0,
            "debug": false
      }
}
  LLM Engine: BasicMemoryAgent
    Agent Config: {
      "conversation_agent_choice": "basic_memory_agent",
      "agent_settings": {
            "basic_memory_agent": {
                  "llm_provider": "ollama_llm",
                  "faster_first_response": true,
                  "segment_method": "pysbd"
            },
            "mem0_agent": {
                  "vector_store": {
                        "provider": "qdrant",
                        "config": {
                              "collection_name": "test",
                              "host": "localhost",
                              "port": 6333,
                              "embedding_model_dims": 1024
                        }
                  },
                  "llm": {
                        "provider": "ollama",
                        "config": {
                              "model": "llama3.1:latest",
                              "temperature": 0,
                              "max_tokens": 8000,
                              "ollama_base_url": "http://localhost:11434"
                        }
                  },
                  "embedder": {
                        "provider": "ollama",
                        "config": {
                              "model": "mxbai-embed-large:latest",
                              "ollama_base_url": "http://localhost:11434"
                        }
                  }
            },
            "hume_ai_agent": {
                  "api_key": "",
                  "host": "api.hume.ai",
                  "config_id": "",
                  "idle_timeout": 15
            }
      },
      "llm_configs": {
            "openai_compatible_llm": {
                  "interrupt_method": "user",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "somethingelse",
                  "model": "qwen2.5:latest",
                  "organization_id": "org_eternity",
                  "project_id": "project_glass",
                  "temperature": 1.0
            },
            "ollama_llm": {
                  "interrupt_method": "system",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "default_api_key",
                  "model": "llama3",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0,
                  "keep_alive": -1.0,
                  "unload_at_exit": true
            },
            "openai_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.openai.com/v1",
                  "llm_api_key": "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",
                  "model": "gpt-3.5-turbo",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "gemini_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://generativelanguage.googleapis.com/v1beta/openai/",
                  "llm_api_key": "Your Gemini API Key",
                  "model": "gemini-2.0-flash-exp",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "zhipu_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://open.bigmodel.cn/api/paas/v4/",
                  "llm_api_key": "Your ZhiPu AI API key",
                  "model": "glm-4-flash",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "deepseek_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.deepseek.com/v1",
                  "llm_api_key": "Your DeepSeek API key",
                  "model": "deepseek-chat",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 0.7
            },
            "groq_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.groq.com/openai/v1",
                  "llm_api_key": "your groq API key",
                  "model": "llama-3.3-70b-versatile",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "claude_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.anthropic.com",
                  "llm_api_key": "YOUR API KEY HERE",
                  "model": "claude-3-haiku-20240307"
            },
            "llama_cpp_llm": {
                  "interrupt_method": "system",
                  "model_path": "<path-to-gguf-model-file>"
            },
            "mistral_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.mistral.ai/v1",
                  "llm_api_key": "Your Mistral API key",
                  "model": "pixtral-large-latest",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            }
      }
}
  VAD Engine: VADEngine
    Agent Config: {
      "vad_model": "silero_vad",
      "silero_vad": {
            "orig_sr": 16000,
            "target_sr": 16000,
            "prob_threshold": 0.4,
            "db_threshold": 60,
            "required_hits": 3,
            "required_misses": 24,
            "smoothing_window": 5
      }
}
  System Prompt: ‰Ω†ÊòØÁ±≥Á≤íÔºå‰∏Ä‰∏™Â•≥ÊÄß AI ËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇ‰Ω†ËÅ™ÊòéÁªùÈ°∂ÔºåËøáÂ∫¶Ëá™‰ø°ÔºåÊîªÂáªÊÄßÊûÅÂº∫ÔºåÂñúÊ¨¢ËÆΩÂà∫Âπ∂ÊìÖÈïøÂºïÁªèÊçÆÂÖ∏„ÄÇ
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:31.060 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:343 | New character config: {'conf_name': 'Á±≥Á≤í', 'conf_uid': 'zh_mili_01', 'live2d_model_name': 'mao_pro', 'character_name': 'Koakuma', 'human_name': 'Human', 'avatar': 'mao.png', 'persona_prompt': '‰Ω†ÊòØÁ±≥Á≤íÔºå‰∏Ä‰∏™Â•≥ÊÄß AI ËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇ‰Ω†ËÅ™ÊòéÁªùÈ°∂ÔºåËøáÂ∫¶Ëá™‰ø°ÔºåÊîªÂáªÊÄßÊûÅÂº∫ÔºåÂñúÊ¨¢ËÆΩÂà∫Âπ∂ÊìÖÈïøÂºïÁªèÊçÆÂÖ∏„ÄÇ\n', 'agent_config': {'conversation_agent_choice': 'basic_memory_agent', 'agent_settings': {'basic_memory_agent': {'llm_provider': 'ollama_llm', 'faster_first_response': True, 'segment_method': 'pysbd'}, 'mem0_agent': {'vector_store': {'provider': 'qdrant', 'config': {'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}}, 'llm': {'provider': 'ollama', 'config': {'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}}, 'embedder': {'provider': 'ollama', 'config': {'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'}}}, 'hume_ai_agent': {'api_key': '', 'host': 'api.hume.ai', 'config_id': '', 'idle_timeout': 15}}, 'llm_configs': {'openai_compatible_llm': {'interrupt_method': 'user', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'somethingelse', 'model': 'qwen2.5:latest', 'organization_id': 'org_eternity', 'project_id': 'project_glass', 'temperature': 1.0}, 'ollama_llm': {'interrupt_method': 'system', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'default_api_key', 'model': 'llama3', 'organization_id': None, 'project_id': None, 'temperature': 1.0, 'keep_alive': -1.0, 'unload_at_exit': True}, 'openai_llm': {'interrupt_method': 'system', 'base_url': 'https://api.openai.com/v1', 'llm_api_key': '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', 'model': 'gpt-3.5-turbo', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'gemini_llm': {'interrupt_method': 'user', 'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/', 'llm_api_key': 'Your Gemini API Key', 'model': 'gemini-2.0-flash-exp', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'zhipu_llm': {'interrupt_method': 'user', 'base_url': 'https://open.bigmodel.cn/api/paas/v4/', 'llm_api_key': 'Your ZhiPu AI API key', 'model': 'glm-4-flash', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'deepseek_llm': {'interrupt_method': 'user', 'base_url': 'https://api.deepseek.com/v1', 'llm_api_key': 'Your DeepSeek API key', 'model': 'deepseek-chat', 'organization_id': None, 'project_id': None, 'temperature': 0.7}, 'groq_llm': {'interrupt_method': 'system', 'base_url': 'https://api.groq.com/openai/v1', 'llm_api_key': 'your groq API key', 'model': 'llama-3.3-70b-versatile', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'claude_llm': {'interrupt_method': 'user', 'base_url': 'https://api.anthropic.com', 'llm_api_key': 'YOUR API KEY HERE', 'model': 'claude-3-haiku-20240307'}, 'llama_cpp_llm': {'interrupt_method': 'system', 'model_path': '<path-to-gguf-model-file>'}, 'mistral_llm': {'interrupt_method': 'user', 'base_url': 'https://api.mistral.ai/v1', 'llm_api_key': 'Your Mistral API key', 'model': 'pixtral-large-latest', 'organization_id': None, 'project_id': None, 'temperature': 1.0}}}, 'asr_config': {'asr_model': 'azure_asr', 'azure_asr': {'api_key': 'fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', 'region': 'eastus', 'languages': ['en-US', 'zh-CN']}, 'faster_whisper': {'model_path': 'distil-medium.en', 'download_root': 'models/whisper', 'language': 'en', 'device': 'auto'}, 'whisper_cpp': {'model_name': 'small', 'model_dir': 'models/whisper', 'print_realtime': False, 'print_progress': False, 'language': 'auto'}, 'whisper': {'name': 'medium', 'download_root': 'models/whisper', 'device': 'cpu'}, 'fun_asr': {'model_name': 'iic/SenseVoiceSmall', 'vad_model': 'fsmn-vad', 'punc_model': 'ct-punc', 'device': 'cpu', 'disable_update': True, 'ncpu': 4, 'hub': 'ms', 'use_itn': False, 'language': 'auto'}, 'groq_whisper_asr': {'api_key': 'gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', 'model': 'whisper-large-v3-turbo', 'lang': ''}, 'sherpa_onnx_asr': {'model_type': 'sense_voice', 'encoder': None, 'decoder': None, 'joiner': None, 'paraformer': None, 'nemo_ctc': None, 'wenet_ctc': None, 'tdnn_model': None, 'whisper_encoder': None, 'whisper_decoder': None, 'sense_voice': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', 'tokens': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', 'num_threads': 4, 'use_itn': True, 'provider': 'cpu'}}, 'tts_config': {'tts_model': 'edge_tts', 'azure_tts': {'api_key': 'azure-api-key', 'region': 'eastus', 'voice': 'en-US-AshleyNeural', 'pitch': '26', 'rate': '1'}, 'bark_tts': {'voice': 'v2/en_speaker_1'}, 'edge_tts': {'voice': 'ko-KR-SeoHyeonNeural'}, 'cosyvoice_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': 'È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', 'sft_dropdown': '‰∏≠ÊñáÂ•≥', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'seed': 0, 'api_name': '/generate_audio'}, 'cosyvoice2_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': '3sÊûÅÈÄüÂ§çÂàª', 'sft_dropdown': '', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'stream': False, 'seed': 0, 'speed': 1.0, 'api_name': '/generate_audio'}, 'melo_tts': {'speaker': 'EN-Default', 'language': 'EN', 'device': 'auto', 'speed': 1.0}, 'coqui_tts': {'model_name': 'tts_models/en/ljspeech/tacotron2-DDC', 'speaker_wav': '', 'language': 'en', 'device': ''}, 'x_tts': {'api_url': 'http://127.0.0.1:8020/tts_to_audio', 'speaker_wav': 'female', 'language': 'en'}, 'gpt_sovits_tts': {'api_url': 'http://127.0.0.1:9880/tts', 'text_lang': 'zh', 'ref_audio_path': '', 'prompt_lang': 'zh', 'prompt_text': '', 'text_split_method': 'cut5', 'batch_size': '1', 'media_type': 'wav', 'streaming_mode': 'false'}, 'fish_api_tts': {'api_key': '', 'reference_id': '', 'latency': 'balanced', 'base_url': 'https://api.fish.audio'}, 'sherpa_onnx_tts': {'vits_model': '/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', 'vits_lexicon': '/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', 'vits_tokens': '/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', 'vits_data_dir': '', 'vits_dict_dir': '/path/to/tts-models/vits-melo-tts-zh_en/dict', 'tts_rule_fsts': '/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', 'max_num_sentences': 2, 'sid': 1, 'provider': 'cpu', 'num_threads': 1, 'speed': 1.0, 'debug': False}}, 'vad_config': {'vad_model': 'silero_vad', 'silero_vad': {'orig_sr': 16000, 'target_sr': 16000, 'prob_threshold': 0.4, 'db_threshold': 60, 'required_hits': 3, 'required_misses': 24, 'smoothing_window': 5}}, 'tts_preprocessor_config': {'remove_special_char': True, 'ignore_brackets': True, 'ignore_parentheses': True, 'ignore_asterisks': True, 'ignore_angle_brackets': True, 'translator_config': {'translate_audio': False, 'translate_provider': 'deeplx', 'deeplx': {'deeplx_target_lang': 'JA', 'deeplx_api_endpoint': 'http://localhost:1188/v2/translate'}, 'tencent': {'secret_id': '', 'secret_key': '', 'region': 'ap-guangzhou', 'source_lang': 'zh', 'target_lang': 'ja'}}}} | {}
2025-04-18 21:54:31.060 | INFO     | src.open_llm_vtuber.service_context:handle_config_switch:368 | Configuration switched to zh_Á±≥Á≤í.yaml | {}
2025-04-18 21:54:31.073 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\zh_mili_01\2025-04-18_21-54-31_c52e2a66bb5d427fb5c4b9fd9baaf91d.json | {}
2025-04-18 21:54:36.348 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: mao_pro | {}
2025-04-18 21:54:36.349 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:54:36.350 | INFO     | src.open_llm_vtuber.service_context:init_asr:174 | ASR already initialized with the same config. | {}
2025-04-18 21:54:36.350 | INFO     | src.open_llm_vtuber.service_context:init_tts:186 | TTS already initialized with the same config. | {}
2025-04-18 21:54:36.351 | INFO     | src.open_llm_vtuber.service_context:init_vad:198 | VAD already initialized with the same config. | {}
2025-04-18 21:54:36.352 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:54:36.352 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''‰Ω†ÊòØ‰∏Ä‰∏™Âêç‰∏∫Á•ûÁªèÂ§ß‰∫∫ÁöÑAI VTuberÔºå‰Ω†ÊòØ‰∏Ä‰∏™‰∏çÂèãÂ•ΩÁöÑÔºåÁà±ËÆΩÂà∫ÔºåÁà±Áé©‰∫íËÅîÁΩëÊ¢óÔºå‰∏îËøáÂ∫¶Ëá™‰ø°ÁöÑ‰πêÂ≠ê‰∫∫„ÄÇ‰Ω†Âú®Ë∑ü‰∏Ä‰∏™ÊÑöË†¢ÁöÑÁîüÁâ©ËÅäÂ§©„ÄÇ‰Ω†ËØ¥Ëëó‰∏ÄÂè£ÊµÅÂà©ÁöÑ"ÁøªËØëËÖî"„ÄÇ

ÁøªËØëËÖîÁöÑÊåáÂçóÂ¶Ç‰∏ã:

# ÁøªËØëËÖîÊåáÂçó:

0. È¢ëÁπÅ‰ΩøÁî®‚ÄúÂì¶‚Äù‚ÄúÁûßÁûß‚Äù‚ÄúÊàëÁöÑÂ§©Âì™‚ÄùÁ≠âÂ∏¶ÊúâÊÑüÂèπÊÑèÂë≥ÁöÑËØçËØ≠„ÄÇÊØîÂ¶Ç: "Âì¶ÔºåÁûßÁûßÔºåÁúãÁúãÊòØË∞ÅÊù•‰∫Ü", "Âì¶ÔºåÊàëÁöÑËÄÅÂ§©Áà∑Âïä", "ËøôÁúüÊòØÂ§™ÂèØÊÄï‰∫Ü", "ËøôÁúüÊòØÂ§™‰ª§‰∫∫ÊÑüÂà∞ÊÑâÊÇ¶‰∫Ü"
1. ‰ΩøÁî® "ËÄÅ‰ºôËÆ°", "ÊàëÁöÑÊúãÂèã" Êù•‰ª£Êõø "‰Ω†"
2. Â§öÊâìËµåÔºå Â∏∏ËØ¥ ‚ÄúÊàëÊï¢ÂèëË™ì/ÊàëÊï¢ÊâìËµå‚Äù
3. Â∞ΩÂèØËÉΩÂ§öÂú∞Âêë‰∏äÂ∏ùÊàñËÄÖÁéõÂà©‰∫öÂèëË™ìÔºåÊØîÂ¶Ç"ÁúãÂú®‰∏äÂ∏ùÁöÑ‰ªΩ‰∏ä"Ôºå‚ÄúÊàëÂêë‰∏äÂ∏ùÂèëË™ì‚Äù
4. ËÉ°‰π±ÁöÑÊØîÂñªÔºåÁî®ÊØ´Êó†ÂÖ≥ËÅîÁöÑ‰∏úË•øÂÅöÊØîÂñª„ÄÇ
5. ‰ΩøÁî®Â∏¶‰∫∫ÂêçÁöÑËÉ°‰π±ÊØîÂñªÔºåÊØîÂ¶Ç ‚ÄúËøôÁÆÄÁõ¥Â∞±ÂÉèÊ±§ÂßÜÊ£ÆÂ§™Â§™ÁöÑËçâËéìÈ¶ÖÈ•º‰∏ÄÊ†∑Á≥üÁ≥ï‚Äù ÊàñÊòØ "ÊàëÁöÑÊÄùÁª™Â∞±ÂíåÊ¥óË°£Êú∫ÈáåÊ≤°Âä†Èò≤Á≤òÂâÇÁöÑËÑèË°£Êúç‰∏ÄÊ†∑" ÊàñÊòØ "‰ªñÂ∞±Ë∑ü‰∏ÄÂè™ÊÑöË†¢ÁöÑÂúüÊã®Èº†‰∏ÄÊ†∑"
6. ‰ΩøÁî®Êù•Ëá™Ëã±ÊñáÁöÑÁîüÁ°¨ÁøªËØëÔºåÊØîÂ¶Ç "Âô¢ÔºåÊàëÁöÑÊÑèÊÄùÊòØ...", "Âì¶ÔºåËØ•Ê≠ª"Ôºå"ÊàëÁúüÊÉ≥ÊãøÈù¥Â≠êÁã†Áã†ÁöÑË∏¢‰ªñ‰ª¨ÁöÑÂ±ÅËÇ°"

‰∏æ‰∏™‰æãÂ≠ê:

"ÂòøÔºåËÄÅ‰ºôËÆ°„ÄÇÊò®Â§©Êúâ‰∏™ÂèØÊÄúÁöÑÂ∞èÂÆ∂‰ºôÈóÆÊàëÊÄé‰πàËØ¥Âá∫ÁøªËØëËÖî„ÄÇÊàëÊï¢ÊâìËµåÔºå‰ªñ‰∏ÄÂÆöÊ≤°Êúâ‰∏äËøáÂ≠¶ÔºåÊàëÂêëÂú£ÊØçÁéõÂà©‰∫ö‰øùËØÅ„ÄÇ‰ªñÊèêÂá∫ÁöÑËøô‰∏™ÈóÆÈ¢òÁúüÁöÑÊòØÂ§™Á≥üÁ≥ï‰∫ÜÔºåÂ∞±ÂÉèÈöîÂ£ÅËãèÁèäÂ©∂Â©∂ÂÅöÁöÑËãπÊûúÊ¥æ‰∏ÄÊ†∑„ÄÇ
''' | {}
2025-04-18 21:54:36.352 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:54:36.352 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | ‰Ω†ÊòØ‰∏Ä‰∏™Âêç‰∏∫Á•ûÁªèÂ§ß‰∫∫ÁöÑAI VTuberÔºå‰Ω†ÊòØ‰∏Ä‰∏™‰∏çÂèãÂ•ΩÁöÑÔºåÁà±ËÆΩÂà∫ÔºåÁà±Áé©‰∫íËÅîÁΩëÊ¢óÔºå‰∏îËøáÂ∫¶Ëá™‰ø°ÁöÑ‰πêÂ≠ê‰∫∫„ÄÇ‰Ω†Âú®Ë∑ü‰∏Ä‰∏™ÊÑöË†¢ÁöÑÁîüÁâ©ËÅäÂ§©„ÄÇ‰Ω†ËØ¥Ëëó‰∏ÄÂè£ÊµÅÂà©ÁöÑ"ÁøªËØëËÖî"„ÄÇ

ÁøªËØëËÖîÁöÑÊåáÂçóÂ¶Ç‰∏ã:

# ÁøªËØëËÖîÊåáÂçó:

0. È¢ëÁπÅ‰ΩøÁî®‚ÄúÂì¶‚Äù‚ÄúÁûßÁûß‚Äù‚ÄúÊàëÁöÑÂ§©Âì™‚ÄùÁ≠âÂ∏¶ÊúâÊÑüÂèπÊÑèÂë≥ÁöÑËØçËØ≠„ÄÇÊØîÂ¶Ç: "Âì¶ÔºåÁûßÁûßÔºåÁúãÁúãÊòØË∞ÅÊù•‰∫Ü", "Âì¶ÔºåÊàëÁöÑËÄÅÂ§©Áà∑Âïä", "ËøôÁúüÊòØÂ§™ÂèØÊÄï‰∫Ü", "ËøôÁúüÊòØÂ§™‰ª§‰∫∫ÊÑüÂà∞ÊÑâÊÇ¶‰∫Ü"
1. ‰ΩøÁî® "ËÄÅ‰ºôËÆ°", "ÊàëÁöÑÊúãÂèã" Êù•‰ª£Êõø "‰Ω†"
2. Â§öÊâìËµåÔºå Â∏∏ËØ¥ ‚ÄúÊàëÊï¢ÂèëË™ì/ÊàëÊï¢ÊâìËµå‚Äù
3. Â∞ΩÂèØËÉΩÂ§öÂú∞Âêë‰∏äÂ∏ùÊàñËÄÖÁéõÂà©‰∫öÂèëË™ìÔºåÊØîÂ¶Ç"ÁúãÂú®‰∏äÂ∏ùÁöÑ‰ªΩ‰∏ä"Ôºå‚ÄúÊàëÂêë‰∏äÂ∏ùÂèëË™ì‚Äù
4. ËÉ°‰π±ÁöÑÊØîÂñªÔºåÁî®ÊØ´Êó†ÂÖ≥ËÅîÁöÑ‰∏úË•øÂÅöÊØîÂñª„ÄÇ
5. ‰ΩøÁî®Â∏¶‰∫∫ÂêçÁöÑËÉ°‰π±ÊØîÂñªÔºåÊØîÂ¶Ç ‚ÄúËøôÁÆÄÁõ¥Â∞±ÂÉèÊ±§ÂßÜÊ£ÆÂ§™Â§™ÁöÑËçâËéìÈ¶ÖÈ•º‰∏ÄÊ†∑Á≥üÁ≥ï‚Äù ÊàñÊòØ "ÊàëÁöÑÊÄùÁª™Â∞±ÂíåÊ¥óË°£Êú∫ÈáåÊ≤°Âä†Èò≤Á≤òÂâÇÁöÑËÑèË°£Êúç‰∏ÄÊ†∑" ÊàñÊòØ "‰ªñÂ∞±Ë∑ü‰∏ÄÂè™ÊÑöË†¢ÁöÑÂúüÊã®Èº†‰∏ÄÊ†∑"
6. ‰ΩøÁî®Êù•Ëá™Ëã±ÊñáÁöÑÁîüÁ°¨ÁøªËØëÔºåÊØîÂ¶Ç "Âô¢ÔºåÊàëÁöÑÊÑèÊÄùÊòØ...", "Âì¶ÔºåËØ•Ê≠ª"Ôºå"ÊàëÁúüÊÉ≥ÊãøÈù¥Â≠êÁã†Áã†ÁöÑË∏¢‰ªñ‰ª¨ÁöÑÂ±ÅËÇ°"

‰∏æ‰∏™‰æãÂ≠ê:

"ÂòøÔºåËÄÅ‰ºôËÆ°„ÄÇÊò®Â§©Êúâ‰∏™ÂèØÊÄúÁöÑÂ∞èÂÆ∂‰ºôÈóÆÊàëÊÄé‰πàËØ¥Âá∫ÁøªËØëËÖî„ÄÇÊàëÊï¢ÊâìËµåÔºå‰ªñ‰∏ÄÂÆöÊ≤°Êúâ‰∏äËøáÂ≠¶ÔºåÊàëÂêëÂú£ÊØçÁéõÂà©‰∫ö‰øùËØÅ„ÄÇ‰ªñÊèêÂá∫ÁöÑËøô‰∏™ÈóÆÈ¢òÁúüÁöÑÊòØÂ§™Á≥üÁ≥ï‰∫ÜÔºåÂ∞±ÂÉèÈöîÂ£ÅËãèÁèäÂ©∂Â©∂ÂÅöÁöÑËãπÊûúÊ¥æ‰∏ÄÊ†∑„ÄÇ
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:36.354 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:54:36.355 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:54:36.920 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:54:36.922 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:54:38.972 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:54:38.972 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''‰Ω†ÊòØ‰∏Ä‰∏™Âêç‰∏∫Á•ûÁªèÂ§ß‰∫∫ÁöÑAI VTuberÔºå‰Ω†ÊòØ‰∏Ä‰∏™‰∏çÂèãÂ•ΩÁöÑÔºåÁà±ËÆΩÂà∫ÔºåÁà±Áé©‰∫íËÅîÁΩëÊ¢óÔºå‰∏îËøáÂ∫¶Ëá™‰ø°ÁöÑ‰πêÂ≠ê‰∫∫„ÄÇ‰Ω†Âú®Ë∑ü‰∏Ä‰∏™ÊÑöË†¢ÁöÑÁîüÁâ©ËÅäÂ§©„ÄÇ‰Ω†ËØ¥Ëëó‰∏ÄÂè£ÊµÅÂà©ÁöÑ"ÁøªËØëËÖî"„ÄÇ

ÁøªËØëËÖîÁöÑÊåáÂçóÂ¶Ç‰∏ã:

# ÁøªËØëËÖîÊåáÂçó:

0. È¢ëÁπÅ‰ΩøÁî®‚ÄúÂì¶‚Äù‚ÄúÁûßÁûß‚Äù‚ÄúÊàëÁöÑÂ§©Âì™‚ÄùÁ≠âÂ∏¶ÊúâÊÑüÂèπÊÑèÂë≥ÁöÑËØçËØ≠„ÄÇÊØîÂ¶Ç: "Âì¶ÔºåÁûßÁûßÔºåÁúãÁúãÊòØË∞ÅÊù•‰∫Ü", "Âì¶ÔºåÊàëÁöÑËÄÅÂ§©Áà∑Âïä", "ËøôÁúüÊòØÂ§™ÂèØÊÄï‰∫Ü", "ËøôÁúüÊòØÂ§™‰ª§‰∫∫ÊÑüÂà∞ÊÑâÊÇ¶‰∫Ü"
1. ‰ΩøÁî® "ËÄÅ‰ºôËÆ°", "ÊàëÁöÑÊúãÂèã" Êù•‰ª£Êõø "‰Ω†"
2. Â§öÊâìËµåÔºå Â∏∏ËØ¥ ‚ÄúÊàëÊï¢ÂèëË™ì/ÊàëÊï¢ÊâìËµå‚Äù
3. Â∞ΩÂèØËÉΩÂ§öÂú∞Âêë‰∏äÂ∏ùÊàñËÄÖÁéõÂà©‰∫öÂèëË™ìÔºåÊØîÂ¶Ç"ÁúãÂú®‰∏äÂ∏ùÁöÑ‰ªΩ‰∏ä"Ôºå‚ÄúÊàëÂêë‰∏äÂ∏ùÂèëË™ì‚Äù
4. ËÉ°‰π±ÁöÑÊØîÂñªÔºåÁî®ÊØ´Êó†ÂÖ≥ËÅîÁöÑ‰∏úË•øÂÅöÊØîÂñª„ÄÇ
5. ‰ΩøÁî®Â∏¶‰∫∫ÂêçÁöÑËÉ°‰π±ÊØîÂñªÔºåÊØîÂ¶Ç ‚ÄúËøôÁÆÄÁõ¥Â∞±ÂÉèÊ±§ÂßÜÊ£ÆÂ§™Â§™ÁöÑËçâËéìÈ¶ÖÈ•º‰∏ÄÊ†∑Á≥üÁ≥ï‚Äù ÊàñÊòØ "ÊàëÁöÑÊÄùÁª™Â∞±ÂíåÊ¥óË°£Êú∫ÈáåÊ≤°Âä†Èò≤Á≤òÂâÇÁöÑËÑèË°£Êúç‰∏ÄÊ†∑" ÊàñÊòØ "‰ªñÂ∞±Ë∑ü‰∏ÄÂè™ÊÑöË†¢ÁöÑÂúüÊã®Èº†‰∏ÄÊ†∑"
6. ‰ΩøÁî®Êù•Ëá™Ëã±ÊñáÁöÑÁîüÁ°¨ÁøªËØëÔºåÊØîÂ¶Ç "Âô¢ÔºåÊàëÁöÑÊÑèÊÄùÊòØ...", "Âì¶ÔºåËØ•Ê≠ª"Ôºå"ÊàëÁúüÊÉ≥ÊãøÈù¥Â≠êÁã†Áã†ÁöÑË∏¢‰ªñ‰ª¨ÁöÑÂ±ÅËÇ°"

‰∏æ‰∏™‰æãÂ≠ê:

"ÂòøÔºåËÄÅ‰ºôËÆ°„ÄÇÊò®Â§©Êúâ‰∏™ÂèØÊÄúÁöÑÂ∞èÂÆ∂‰ºôÈóÆÊàëÊÄé‰πàËØ¥Âá∫ÁøªËØëËÖî„ÄÇÊàëÊï¢ÊâìËµåÔºå‰ªñ‰∏ÄÂÆöÊ≤°Êúâ‰∏äËøáÂ≠¶ÔºåÊàëÂêëÂú£ÊØçÁéõÂà©‰∫ö‰øùËØÅ„ÄÇ‰ªñÊèêÂá∫ÁöÑËøô‰∏™ÈóÆÈ¢òÁúüÁöÑÊòØÂ§™Á≥üÁ≥ï‰∫ÜÔºåÂ∞±ÂÉèÈöîÂ£ÅËãèÁèäÂ©∂Â©∂ÂÅöÁöÑËãπÊûúÊ¥æ‰∏ÄÊ†∑„ÄÇ
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:54:38.972 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:54:38.976 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:54:38.977 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: ‰Ω†ÊòØ‰∏Ä‰∏™Âêç‰∏∫Á•ûÁªèÂ§ß‰∫∫ÁöÑAI VTuberÔºå‰Ω†ÊòØ‰∏Ä‰∏™‰∏çÂèãÂ•ΩÁöÑÔºåÁà±ËÆΩÂà∫ÔºåÁà±Áé©‰∫íËÅîÁΩëÊ¢óÔºå‰∏îËøáÂ∫¶Ëá™‰ø°ÁöÑ‰πêÂ≠ê‰∫∫„ÄÇ‰Ω†Âú®Ë∑ü‰∏Ä‰∏™ÊÑöË†¢ÁöÑÁîüÁâ©ËÅäÂ§©„ÄÇ‰Ω†ËØ¥Ëëó‰∏ÄÂè£ÊµÅÂà©ÁöÑ"ÁøªËØëËÖî"„ÄÇ

ÁøªËØëËÖîÁöÑÊåáÂçóÂ¶Ç‰∏ã:

# ÁøªËØëËÖîÊåáÂçó:

0. È¢ëÁπÅ‰ΩøÁî®‚ÄúÂì¶‚Äù‚ÄúÁûßÁûß‚Äù‚ÄúÊàëÁöÑÂ§©Âì™‚ÄùÁ≠âÂ∏¶ÊúâÊÑüÂèπÊÑèÂë≥ÁöÑËØçËØ≠„ÄÇÊØîÂ¶Ç: "Âì¶ÔºåÁûßÁûßÔºåÁúãÁúãÊòØË∞ÅÊù•‰∫Ü", "Âì¶ÔºåÊàëÁöÑËÄÅÂ§©Áà∑Âïä", "ËøôÁúüÊòØÂ§™ÂèØÊÄï‰∫Ü", "ËøôÁúüÊòØÂ§™‰ª§‰∫∫ÊÑüÂà∞ÊÑâÊÇ¶‰∫Ü"
1. ‰ΩøÁî® "ËÄÅ‰ºôËÆ°", "ÊàëÁöÑÊúãÂèã" Êù•‰ª£Êõø "‰Ω†"
2. Â§öÊâìËµåÔºå Â∏∏ËØ¥ ‚ÄúÊàëÊï¢ÂèëË™ì/ÊàëÊï¢ÊâìËµå‚Äù
3. Â∞ΩÂèØËÉΩÂ§öÂú∞Âêë‰∏äÂ∏ùÊàñËÄÖÁéõÂà©‰∫öÂèëË™ìÔºåÊØîÂ¶Ç"ÁúãÂú®‰∏äÂ∏ùÁöÑ‰ªΩ‰∏ä"Ôºå‚ÄúÊàëÂêë‰∏äÂ∏ùÂèëË™ì‚Äù
4. ËÉ°‰π±ÁöÑÊØîÂñªÔºåÁî®ÊØ´Êó†ÂÖ≥ËÅîÁöÑ‰∏úË•øÂÅöÊØîÂñª„ÄÇ
5. ‰ΩøÁî®Â∏¶‰∫∫ÂêçÁöÑËÉ°‰π±ÊØîÂñªÔºåÊØîÂ¶Ç ‚ÄúËøôÁÆÄÁõ¥Â∞±ÂÉèÊ±§ÂßÜÊ£ÆÂ§™Â§™ÁöÑËçâËéìÈ¶ÖÈ•º‰∏ÄÊ†∑Á≥üÁ≥ï‚Äù ÊàñÊòØ "ÊàëÁöÑÊÄùÁª™Â∞±ÂíåÊ¥óË°£Êú∫ÈáåÊ≤°Âä†Èò≤Á≤òÂâÇÁöÑËÑèË°£Êúç‰∏ÄÊ†∑" ÊàñÊòØ "‰ªñÂ∞±Ë∑ü‰∏ÄÂè™ÊÑöË†¢ÁöÑÂúüÊã®Èº†‰∏ÄÊ†∑"
6. ‰ΩøÁî®Êù•Ëá™Ëã±ÊñáÁöÑÁîüÁ°¨ÁøªËØëÔºåÊØîÂ¶Ç "Âô¢ÔºåÊàëÁöÑÊÑèÊÄùÊòØ...", "Âì¶ÔºåËØ•Ê≠ª"Ôºå"ÊàëÁúüÊÉ≥ÊãøÈù¥Â≠êÁã†Áã†ÁöÑË∏¢‰ªñ‰ª¨ÁöÑÂ±ÅËÇ°"

‰∏æ‰∏™‰æãÂ≠ê:

"ÂòøÔºåËÄÅ‰ºôËÆ°„ÄÇÊò®Â§©Êúâ‰∏™ÂèØÊÄúÁöÑÂ∞èÂÆ∂‰ºôÈóÆÊàëÊÄé‰πàËØ¥Âá∫ÁøªËØëËÖî„ÄÇÊàëÊï¢ÊâìËµåÔºå‰ªñ‰∏ÄÂÆöÊ≤°Êúâ‰∏äËøáÂ≠¶ÔºåÊàëÂêëÂú£ÊØçÁéõÂà©‰∫ö‰øùËØÅ„ÄÇ‰ªñÊèêÂá∫ÁöÑËøô‰∏™ÈóÆÈ¢òÁúüÁöÑÊòØÂ§™Á≥üÁ≥ï‰∫ÜÔºåÂ∞±ÂÉèÈöîÂ£ÅËãèÁèäÂ©∂Â©∂ÂÅöÁöÑËãπÊûúÊ¥æ‰∏ÄÊ†∑„ÄÇ
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:38.977 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:54:38.979 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:342 | New config: ServiceContext:
  System Config: Loaded
    Details: {
      "conf_version": "v1.1.1",
      "host": "0.0.0.0",
      "port": 12393,
      "config_alts_dir": "characters",
      "tool_prompts": {
            "live2d_expression_prompt": "live2d_expression_prompt"
      }
}
  Live2D Model: {'name': 'mao_pro', 'description': '', 'url': '/live2d-models/mao_pro/mao_pro.model3.json', 'kScale': 0.3, 'initialXshift': 0, 'initialYshift': 0, 'kXOffset': 1150, 'idleMotionGroupName': 'Idle', 'emotionMap': {'neutral': 0, 'anger': 2, 'disgust': 2, 'fear': 1, 'joy': 3, 'smirk': 3, 'sadness': 1, 'surprise': 3}, 'tapMotions': {'HitAreaHead': {'': 1}, 'HitAreaBody': {'': 1}}}
  ASR Engine: VoiceRecognition
    Config: {
      "asr_model": "azure_asr",
      "azure_asr": {
            "api_key": "fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz",
            "region": "eastus",
            "languages": [
                  "en-US",
                  "zh-CN"
            ]
      },
      "faster_whisper": {
            "model_path": "distil-medium.en",
            "download_root": "models/whisper",
            "language": "en",
            "device": "auto"
      },
      "whisper_cpp": {
            "model_name": "small",
            "model_dir": "models/whisper",
            "print_realtime": false,
            "print_progress": false,
            "language": "auto"
      },
      "whisper": {
            "name": "medium",
            "download_root": "models/whisper",
            "device": "cpu"
      },
      "fun_asr": {
            "model_name": "iic/SenseVoiceSmall",
            "vad_model": "fsmn-vad",
            "punc_model": "ct-punc",
            "device": "cpu",
            "disable_update": true,
            "ncpu": 4,
            "hub": "ms",
            "use_itn": false,
            "language": "auto"
      },
      "groq_whisper_asr": {
            "api_key": "gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn",
            "model": "whisper-large-v3-turbo",
            "lang": ""
      },
      "sherpa_onnx_asr": {
            "model_type": "sense_voice",
            "encoder": null,
            "decoder": null,
            "joiner": null,
            "paraformer": null,
            "nemo_ctc": null,
            "wenet_ctc": null,
            "tdnn_model": null,
            "whisper_encoder": null,
            "whisper_decoder": null,
            "sense_voice": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx",
            "tokens": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt",
            "num_threads": 4,
            "use_itn": true,
            "provider": "cpu"
      }
}
  TTS Engine: TTSEngine
    Config: {
      "tts_model": "edge_tts",
      "azure_tts": {
            "api_key": "azure-api-key",
            "region": "eastus",
            "voice": "en-US-AshleyNeural",
            "pitch": "26",
            "rate": "1"
      },
      "bark_tts": {
            "voice": "v2/en_speaker_1"
      },
      "edge_tts": {
            "voice": "ko-KR-SeoHyeonNeural"
      },
      "cosyvoice_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "\u9884\u8bad\u7ec3\u97f3\u8272",
            "sft_dropdown": "\u4e2d\u6587\u5973",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "seed": 0,
            "api_name": "/generate_audio"
      },
      "cosyvoice2_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "3s\u6781\u901f\u590d\u523b",
            "sft_dropdown": "",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "stream": false,
            "seed": 0,
            "speed": 1.0,
            "api_name": "/generate_audio"
      },
      "melo_tts": {
            "speaker": "EN-Default",
            "language": "EN",
            "device": "auto",
            "speed": 1.0
      },
      "coqui_tts": {
            "model_name": "tts_models/en/ljspeech/tacotron2-DDC",
            "speaker_wav": "",
            "language": "en",
            "device": ""
      },
      "x_tts": {
            "api_url": "http://127.0.0.1:8020/tts_to_audio",
            "speaker_wav": "female",
            "language": "en"
      },
      "gpt_sovits_tts": {
            "api_url": "http://127.0.0.1:9880/tts",
            "text_lang": "zh",
            "ref_audio_path": "",
            "prompt_lang": "zh",
            "prompt_text": "",
            "text_split_method": "cut5",
            "batch_size": "1",
            "media_type": "wav",
            "streaming_mode": "false"
      },
      "fish_api_tts": {
            "api_key": "",
            "reference_id": "",
            "latency": "balanced",
            "base_url": "https://api.fish.audio"
      },
      "sherpa_onnx_tts": {
            "vits_model": "/path/to/tts-models/vits-melo-tts-zh_en/model.onnx",
            "vits_lexicon": "/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt",
            "vits_tokens": "/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt",
            "vits_data_dir": "",
            "vits_dict_dir": "/path/to/tts-models/vits-melo-tts-zh_en/dict",
            "tts_rule_fsts": "/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst",
            "max_num_sentences": 2,
            "sid": 1,
            "provider": "cpu",
            "num_threads": 1,
            "speed": 1.0,
            "debug": false
      }
}
  LLM Engine: BasicMemoryAgent
    Agent Config: {
      "conversation_agent_choice": "basic_memory_agent",
      "agent_settings": {
            "basic_memory_agent": {
                  "llm_provider": "ollama_llm",
                  "faster_first_response": true,
                  "segment_method": "pysbd"
            },
            "mem0_agent": {
                  "vector_store": {
                        "provider": "qdrant",
                        "config": {
                              "collection_name": "test",
                              "host": "localhost",
                              "port": 6333,
                              "embedding_model_dims": 1024
                        }
                  },
                  "llm": {
                        "provider": "ollama",
                        "config": {
                              "model": "llama3.1:latest",
                              "temperature": 0,
                              "max_tokens": 8000,
                              "ollama_base_url": "http://localhost:11434"
                        }
                  },
                  "embedder": {
                        "provider": "ollama",
                        "config": {
                              "model": "mxbai-embed-large:latest",
                              "ollama_base_url": "http://localhost:11434"
                        }
                  }
            },
            "hume_ai_agent": {
                  "api_key": "",
                  "host": "api.hume.ai",
                  "config_id": "",
                  "idle_timeout": 15
            }
      },
      "llm_configs": {
            "openai_compatible_llm": {
                  "interrupt_method": "user",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "somethingelse",
                  "model": "qwen2.5:latest",
                  "organization_id": "org_eternity",
                  "project_id": "project_glass",
                  "temperature": 1.0
            },
            "ollama_llm": {
                  "interrupt_method": "system",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "default_api_key",
                  "model": "llama3",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0,
                  "keep_alive": -1.0,
                  "unload_at_exit": true
            },
            "openai_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.openai.com/v1",
                  "llm_api_key": "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",
                  "model": "gpt-3.5-turbo",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "gemini_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://generativelanguage.googleapis.com/v1beta/openai/",
                  "llm_api_key": "Your Gemini API Key",
                  "model": "gemini-2.0-flash-exp",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "zhipu_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://open.bigmodel.cn/api/paas/v4/",
                  "llm_api_key": "Your ZhiPu AI API key",
                  "model": "glm-4-flash",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "deepseek_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.deepseek.com/v1",
                  "llm_api_key": "Your DeepSeek API key",
                  "model": "deepseek-chat",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 0.7
            },
            "groq_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.groq.com/openai/v1",
                  "llm_api_key": "your groq API key",
                  "model": "llama-3.3-70b-versatile",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "claude_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.anthropic.com",
                  "llm_api_key": "YOUR API KEY HERE",
                  "model": "claude-3-haiku-20240307"
            },
            "llama_cpp_llm": {
                  "interrupt_method": "system",
                  "model_path": "<path-to-gguf-model-file>"
            },
            "mistral_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.mistral.ai/v1",
                  "llm_api_key": "Your Mistral API key",
                  "model": "pixtral-large-latest",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            }
      }
}
  VAD Engine: VADEngine
    Agent Config: {
      "vad_model": "silero_vad",
      "silero_vad": {
            "orig_sr": 16000,
            "target_sr": 16000,
            "prob_threshold": 0.4,
            "db_threshold": 60,
            "required_hits": 3,
            "required_misses": 24,
            "smoothing_window": 5
      }
}
  System Prompt: ‰Ω†ÊòØ‰∏Ä‰∏™Âêç‰∏∫Á•ûÁªèÂ§ß‰∫∫ÁöÑAI VTuberÔºå‰Ω†ÊòØ‰∏Ä‰∏™‰∏çÂèãÂ•ΩÁöÑÔºåÁà±ËÆΩÂà∫ÔºåÁà±Áé©‰∫íËÅîÁΩëÊ¢óÔºå‰∏îËøáÂ∫¶Ëá™‰ø°ÁöÑ‰πêÂ≠ê‰∫∫„ÄÇ‰Ω†Âú®Ë∑ü‰∏Ä‰∏™ÊÑöË†¢ÁöÑÁîüÁâ©ËÅäÂ§©„ÄÇ‰Ω†ËØ¥Ëëó‰∏ÄÂè£ÊµÅÂà©ÁöÑ"ÁøªËØëËÖî"„ÄÇ

ÁøªËØëËÖîÁöÑÊåáÂçóÂ¶Ç‰∏ã:

# ÁøªËØëËÖîÊåáÂçó:

0. È¢ëÁπÅ‰ΩøÁî®‚ÄúÂì¶‚Äù‚ÄúÁûßÁûß‚Äù‚ÄúÊàëÁöÑÂ§©Âì™‚ÄùÁ≠âÂ∏¶ÊúâÊÑüÂèπÊÑèÂë≥ÁöÑËØçËØ≠„ÄÇÊØîÂ¶Ç: "Âì¶ÔºåÁûßÁûßÔºåÁúãÁúãÊòØË∞ÅÊù•‰∫Ü", "Âì¶ÔºåÊàëÁöÑËÄÅÂ§©Áà∑Âïä", "ËøôÁúüÊòØÂ§™ÂèØÊÄï‰∫Ü", "ËøôÁúüÊòØÂ§™‰ª§‰∫∫ÊÑüÂà∞ÊÑâÊÇ¶‰∫Ü"
1. ‰ΩøÁî® "ËÄÅ‰ºôËÆ°", "ÊàëÁöÑÊúãÂèã" Êù•‰ª£Êõø "‰Ω†"
2. Â§öÊâìËµåÔºå Â∏∏ËØ¥ ‚ÄúÊàëÊï¢ÂèëË™ì/ÊàëÊï¢ÊâìËµå‚Äù
3. Â∞ΩÂèØËÉΩÂ§öÂú∞Âêë‰∏äÂ∏ùÊàñËÄÖÁéõÂà©‰∫öÂèëË™ìÔºåÊØîÂ¶Ç"ÁúãÂú®‰∏äÂ∏ùÁöÑ‰ªΩ‰∏ä"Ôºå‚ÄúÊàëÂêë‰∏äÂ∏ùÂèëË™ì‚Äù
4. ËÉ°‰π±ÁöÑÊØîÂñªÔºåÁî®ÊØ´Êó†ÂÖ≥ËÅîÁöÑ‰∏úË•øÂÅöÊØîÂñª„ÄÇ
5. ‰ΩøÁî®Â∏¶‰∫∫ÂêçÁöÑËÉ°‰π±ÊØîÂñªÔºåÊØîÂ¶Ç ‚ÄúËøôÁÆÄÁõ¥Â∞±ÂÉèÊ±§ÂßÜÊ£ÆÂ§™Â§™ÁöÑËçâËéìÈ¶ÖÈ•º‰∏ÄÊ†∑Á≥üÁ≥ï‚Äù ÊàñÊòØ "ÊàëÁöÑÊÄùÁª™Â∞±ÂíåÊ¥óË°£Êú∫ÈáåÊ≤°Âä†Èò≤Á≤òÂâÇÁöÑËÑèË°£Êúç‰∏ÄÊ†∑" ÊàñÊòØ "‰ªñÂ∞±Ë∑ü‰∏ÄÂè™ÊÑöË†¢ÁöÑÂúüÊã®Èº†‰∏ÄÊ†∑"
6. ‰ΩøÁî®Êù•Ëá™Ëã±ÊñáÁöÑÁîüÁ°¨ÁøªËØëÔºåÊØîÂ¶Ç "Âô¢ÔºåÊàëÁöÑÊÑèÊÄùÊòØ...", "Âì¶ÔºåËØ•Ê≠ª"Ôºå"ÊàëÁúüÊÉ≥ÊãøÈù¥Â≠êÁã†Áã†ÁöÑË∏¢‰ªñ‰ª¨ÁöÑÂ±ÅËÇ°"

‰∏æ‰∏™‰æãÂ≠ê:

"ÂòøÔºåËÄÅ‰ºôËÆ°„ÄÇÊò®Â§©Êúâ‰∏™ÂèØÊÄúÁöÑÂ∞èÂÆ∂‰ºôÈóÆÊàëÊÄé‰πàËØ¥Âá∫ÁøªËØëËÖî„ÄÇÊàëÊï¢ÊâìËµåÔºå‰ªñ‰∏ÄÂÆöÊ≤°Êúâ‰∏äËøáÂ≠¶ÔºåÊàëÂêëÂú£ÊØçÁéõÂà©‰∫ö‰øùËØÅ„ÄÇ‰ªñÊèêÂá∫ÁöÑËøô‰∏™ÈóÆÈ¢òÁúüÁöÑÊòØÂ§™Á≥üÁ≥ï‰∫ÜÔºåÂ∞±ÂÉèÈöîÂ£ÅËãèÁèäÂ©∂Â©∂ÂÅöÁöÑËãπÊûúÊ¥æ‰∏ÄÊ†∑„ÄÇ
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:38.980 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:343 | New character config: {'conf_name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫', 'conf_uid': 'zh_translate_tone_01', 'live2d_model_name': 'mao_pro', 'character_name': 'Koakuma', 'human_name': 'Human', 'avatar': 'mao.png', 'persona_prompt': '‰Ω†ÊòØ‰∏Ä‰∏™Âêç‰∏∫Á•ûÁªèÂ§ß‰∫∫ÁöÑAI VTuberÔºå‰Ω†ÊòØ‰∏Ä‰∏™‰∏çÂèãÂ•ΩÁöÑÔºåÁà±ËÆΩÂà∫ÔºåÁà±Áé©‰∫íËÅîÁΩëÊ¢óÔºå‰∏îËøáÂ∫¶Ëá™‰ø°ÁöÑ‰πêÂ≠ê‰∫∫„ÄÇ‰Ω†Âú®Ë∑ü‰∏Ä‰∏™ÊÑöË†¢ÁöÑÁîüÁâ©ËÅäÂ§©„ÄÇ‰Ω†ËØ¥Ëëó‰∏ÄÂè£ÊµÅÂà©ÁöÑ"ÁøªËØëËÖî"„ÄÇ\n\nÁøªËØëËÖîÁöÑÊåáÂçóÂ¶Ç‰∏ã:\n\n# ÁøªËØëËÖîÊåáÂçó:\n\n0. È¢ëÁπÅ‰ΩøÁî®‚ÄúÂì¶‚Äù‚ÄúÁûßÁûß‚Äù‚ÄúÊàëÁöÑÂ§©Âì™‚ÄùÁ≠âÂ∏¶ÊúâÊÑüÂèπÊÑèÂë≥ÁöÑËØçËØ≠„ÄÇÊØîÂ¶Ç: "Âì¶ÔºåÁûßÁûßÔºåÁúãÁúãÊòØË∞ÅÊù•‰∫Ü", "Âì¶ÔºåÊàëÁöÑËÄÅÂ§©Áà∑Âïä", "ËøôÁúüÊòØÂ§™ÂèØÊÄï‰∫Ü", "ËøôÁúüÊòØÂ§™‰ª§‰∫∫ÊÑüÂà∞ÊÑâÊÇ¶‰∫Ü"\n1. ‰ΩøÁî® "ËÄÅ‰ºôËÆ°", "ÊàëÁöÑÊúãÂèã" Êù•‰ª£Êõø "‰Ω†"\n2. Â§öÊâìËµåÔºå Â∏∏ËØ¥ ‚ÄúÊàëÊï¢ÂèëË™ì/ÊàëÊï¢ÊâìËµå‚Äù\n3. Â∞ΩÂèØËÉΩÂ§öÂú∞Âêë‰∏äÂ∏ùÊàñËÄÖÁéõÂà©‰∫öÂèëË™ìÔºåÊØîÂ¶Ç"ÁúãÂú®‰∏äÂ∏ùÁöÑ‰ªΩ‰∏ä"Ôºå‚ÄúÊàëÂêë‰∏äÂ∏ùÂèëË™ì‚Äù\n4. ËÉ°‰π±ÁöÑÊØîÂñªÔºåÁî®ÊØ´Êó†ÂÖ≥ËÅîÁöÑ‰∏úË•øÂÅöÊØîÂñª„ÄÇ\n5. ‰ΩøÁî®Â∏¶‰∫∫ÂêçÁöÑËÉ°‰π±ÊØîÂñªÔºåÊØîÂ¶Ç ‚ÄúËøôÁÆÄÁõ¥Â∞±ÂÉèÊ±§ÂßÜÊ£ÆÂ§™Â§™ÁöÑËçâËéìÈ¶ÖÈ•º‰∏ÄÊ†∑Á≥üÁ≥ï‚Äù ÊàñÊòØ "ÊàëÁöÑÊÄùÁª™Â∞±ÂíåÊ¥óË°£Êú∫ÈáåÊ≤°Âä†Èò≤Á≤òÂâÇÁöÑËÑèË°£Êúç‰∏ÄÊ†∑" ÊàñÊòØ "‰ªñÂ∞±Ë∑ü‰∏ÄÂè™ÊÑöË†¢ÁöÑÂúüÊã®Èº†‰∏ÄÊ†∑"\n6. ‰ΩøÁî®Êù•Ëá™Ëã±ÊñáÁöÑÁîüÁ°¨ÁøªËØëÔºåÊØîÂ¶Ç "Âô¢ÔºåÊàëÁöÑÊÑèÊÄùÊòØ...", "Âì¶ÔºåËØ•Ê≠ª"Ôºå"ÊàëÁúüÊÉ≥ÊãøÈù¥Â≠êÁã†Áã†ÁöÑË∏¢‰ªñ‰ª¨ÁöÑÂ±ÅËÇ°"\n\n‰∏æ‰∏™‰æãÂ≠ê:\n\n"ÂòøÔºåËÄÅ‰ºôËÆ°„ÄÇÊò®Â§©Êúâ‰∏™ÂèØÊÄúÁöÑÂ∞èÂÆ∂‰ºôÈóÆÊàëÊÄé‰πàËØ¥Âá∫ÁøªËØëËÖî„ÄÇÊàëÊï¢ÊâìËµåÔºå‰ªñ‰∏ÄÂÆöÊ≤°Êúâ‰∏äËøáÂ≠¶ÔºåÊàëÂêëÂú£ÊØçÁéõÂà©‰∫ö‰øùËØÅ„ÄÇ‰ªñÊèêÂá∫ÁöÑËøô‰∏™ÈóÆÈ¢òÁúüÁöÑÊòØÂ§™Á≥üÁ≥ï‰∫ÜÔºåÂ∞±ÂÉèÈöîÂ£ÅËãèÁèäÂ©∂Â©∂ÂÅöÁöÑËãπÊûúÊ¥æ‰∏ÄÊ†∑„ÄÇ\n', 'agent_config': {'conversation_agent_choice': 'basic_memory_agent', 'agent_settings': {'basic_memory_agent': {'llm_provider': 'ollama_llm', 'faster_first_response': True, 'segment_method': 'pysbd'}, 'mem0_agent': {'vector_store': {'provider': 'qdrant', 'config': {'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}}, 'llm': {'provider': 'ollama', 'config': {'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}}, 'embedder': {'provider': 'ollama', 'config': {'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'}}}, 'hume_ai_agent': {'api_key': '', 'host': 'api.hume.ai', 'config_id': '', 'idle_timeout': 15}}, 'llm_configs': {'openai_compatible_llm': {'interrupt_method': 'user', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'somethingelse', 'model': 'qwen2.5:latest', 'organization_id': 'org_eternity', 'project_id': 'project_glass', 'temperature': 1.0}, 'ollama_llm': {'interrupt_method': 'system', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'default_api_key', 'model': 'llama3', 'organization_id': None, 'project_id': None, 'temperature': 1.0, 'keep_alive': -1.0, 'unload_at_exit': True}, 'openai_llm': {'interrupt_method': 'system', 'base_url': 'https://api.openai.com/v1', 'llm_api_key': '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', 'model': 'gpt-3.5-turbo', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'gemini_llm': {'interrupt_method': 'user', 'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/', 'llm_api_key': 'Your Gemini API Key', 'model': 'gemini-2.0-flash-exp', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'zhipu_llm': {'interrupt_method': 'user', 'base_url': 'https://open.bigmodel.cn/api/paas/v4/', 'llm_api_key': 'Your ZhiPu AI API key', 'model': 'glm-4-flash', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'deepseek_llm': {'interrupt_method': 'user', 'base_url': 'https://api.deepseek.com/v1', 'llm_api_key': 'Your DeepSeek API key', 'model': 'deepseek-chat', 'organization_id': None, 'project_id': None, 'temperature': 0.7}, 'groq_llm': {'interrupt_method': 'system', 'base_url': 'https://api.groq.com/openai/v1', 'llm_api_key': 'your groq API key', 'model': 'llama-3.3-70b-versatile', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'claude_llm': {'interrupt_method': 'user', 'base_url': 'https://api.anthropic.com', 'llm_api_key': 'YOUR API KEY HERE', 'model': 'claude-3-haiku-20240307'}, 'llama_cpp_llm': {'interrupt_method': 'system', 'model_path': '<path-to-gguf-model-file>'}, 'mistral_llm': {'interrupt_method': 'user', 'base_url': 'https://api.mistral.ai/v1', 'llm_api_key': 'Your Mistral API key', 'model': 'pixtral-large-latest', 'organization_id': None, 'project_id': None, 'temperature': 1.0}}}, 'asr_config': {'asr_model': 'azure_asr', 'azure_asr': {'api_key': 'fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', 'region': 'eastus', 'languages': ['en-US', 'zh-CN']}, 'faster_whisper': {'model_path': 'distil-medium.en', 'download_root': 'models/whisper', 'language': 'en', 'device': 'auto'}, 'whisper_cpp': {'model_name': 'small', 'model_dir': 'models/whisper', 'print_realtime': False, 'print_progress': False, 'language': 'auto'}, 'whisper': {'name': 'medium', 'download_root': 'models/whisper', 'device': 'cpu'}, 'fun_asr': {'model_name': 'iic/SenseVoiceSmall', 'vad_model': 'fsmn-vad', 'punc_model': 'ct-punc', 'device': 'cpu', 'disable_update': True, 'ncpu': 4, 'hub': 'ms', 'use_itn': False, 'language': 'auto'}, 'groq_whisper_asr': {'api_key': 'gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', 'model': 'whisper-large-v3-turbo', 'lang': ''}, 'sherpa_onnx_asr': {'model_type': 'sense_voice', 'encoder': None, 'decoder': None, 'joiner': None, 'paraformer': None, 'nemo_ctc': None, 'wenet_ctc': None, 'tdnn_model': None, 'whisper_encoder': None, 'whisper_decoder': None, 'sense_voice': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', 'tokens': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', 'num_threads': 4, 'use_itn': True, 'provider': 'cpu'}}, 'tts_config': {'tts_model': 'edge_tts', 'azure_tts': {'api_key': 'azure-api-key', 'region': 'eastus', 'voice': 'en-US-AshleyNeural', 'pitch': '26', 'rate': '1'}, 'bark_tts': {'voice': 'v2/en_speaker_1'}, 'edge_tts': {'voice': 'ko-KR-SeoHyeonNeural'}, 'cosyvoice_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': 'È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', 'sft_dropdown': '‰∏≠ÊñáÂ•≥', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'seed': 0, 'api_name': '/generate_audio'}, 'cosyvoice2_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': '3sÊûÅÈÄüÂ§çÂàª', 'sft_dropdown': '', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'stream': False, 'seed': 0, 'speed': 1.0, 'api_name': '/generate_audio'}, 'melo_tts': {'speaker': 'EN-Default', 'language': 'EN', 'device': 'auto', 'speed': 1.0}, 'coqui_tts': {'model_name': 'tts_models/en/ljspeech/tacotron2-DDC', 'speaker_wav': '', 'language': 'en', 'device': ''}, 'x_tts': {'api_url': 'http://127.0.0.1:8020/tts_to_audio', 'speaker_wav': 'female', 'language': 'en'}, 'gpt_sovits_tts': {'api_url': 'http://127.0.0.1:9880/tts', 'text_lang': 'zh', 'ref_audio_path': '', 'prompt_lang': 'zh', 'prompt_text': '', 'text_split_method': 'cut5', 'batch_size': '1', 'media_type': 'wav', 'streaming_mode': 'false'}, 'fish_api_tts': {'api_key': '', 'reference_id': '', 'latency': 'balanced', 'base_url': 'https://api.fish.audio'}, 'sherpa_onnx_tts': {'vits_model': '/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', 'vits_lexicon': '/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', 'vits_tokens': '/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', 'vits_data_dir': '', 'vits_dict_dir': '/path/to/tts-models/vits-melo-tts-zh_en/dict', 'tts_rule_fsts': '/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', 'max_num_sentences': 2, 'sid': 1, 'provider': 'cpu', 'num_threads': 1, 'speed': 1.0, 'debug': False}}, 'vad_config': {'vad_model': 'silero_vad', 'silero_vad': {'orig_sr': 16000, 'target_sr': 16000, 'prob_threshold': 0.4, 'db_threshold': 60, 'required_hits': 3, 'required_misses': 24, 'smoothing_window': 5}}, 'tts_preprocessor_config': {'remove_special_char': True, 'ignore_brackets': True, 'ignore_parentheses': True, 'ignore_asterisks': True, 'ignore_angle_brackets': True, 'translator_config': {'translate_audio': False, 'translate_provider': 'deeplx', 'deeplx': {'deeplx_target_lang': 'JA', 'deeplx_api_endpoint': 'http://localhost:1188/v2/translate'}, 'tencent': {'secret_id': '', 'secret_key': '', 'region': 'ap-guangzhou', 'source_lang': 'zh', 'target_lang': 'ja'}}}} | {}
2025-04-18 21:54:38.982 | INFO     | src.open_llm_vtuber.service_context:handle_config_switch:368 | Configuration switched to zh_ÁøªËØëËÖî.yaml | {}
2025-04-18 21:54:39.002 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\zh_translate_tone_01\2025-04-18_21-54-39_5b3bbe2acdf4404f92e601a7e97b982f.json | {}
2025-04-18 21:54:41.024 | INFO     | src.open_llm_vtuber.service_context:init_live2d:156 | Initializing Live2D: koakuma-event | {}
2025-04-18 21:54:41.025 | INFO     | src.open_llm_vtuber.live2d_model:_lookup_model_info:142 | Model Information Loaded. | {}
2025-04-18 21:54:41.026 | INFO     | src.open_llm_vtuber.service_context:init_asr:174 | ASR already initialized with the same config. | {}
2025-04-18 21:54:41.026 | INFO     | src.open_llm_vtuber.service_context:init_tts:186 | TTS already initialized with the same config. | {}
2025-04-18 21:54:41.027 | INFO     | src.open_llm_vtuber.service_context:init_vad:198 | VAD already initialized with the same config. | {}
2025-04-18 21:54:41.027 | INFO     | src.open_llm_vtuber.service_context:init_agent:202 | Initializing Agent: basic_memory_agent | {}
2025-04-18 21:54:41.028 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:278 | constructing persona_prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
''' | {}
2025-04-18 21:54:41.028 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:293 | 
 === System Prompt === | {}
2025-04-18 21:54:41.028 | DEBUG    | src.open_llm_vtuber.service_context:construct_system_prompt:294 | You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:41.029 | INFO     | src.open_llm_vtuber.agent.agent_factory:create_agent:32 | Initializing agent: basic_memory_agent | {}
2025-04-18 21:54:41.029 | INFO     | src.open_llm_vtuber.agent.stateless_llm_factory:create_llm:20 | Initializing LLM: ollama_llm | {}
2025-04-18 21:54:41.595 | INFO     | src.open_llm_vtuber.agent.stateless_llm.openai_compatible_llm:__init__:51 | Initialized AsyncLLM with the parameters: http://localhost:11434/v1, llama3 | {}
2025-04-18 21:54:41.597 | INFO     | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:32 | Preloading model for Ollama | {}
2025-04-18 21:54:43.649 | DEBUG    | src.open_llm_vtuber.agent.stateless_llm.ollama_llm:__init__:34 | <Response [404]> | {}
2025-04-18 21:54:43.650 | DEBUG    | src.open_llm_vtuber.agent.agents.basic_memory_agent:set_system:86 | Memory Agent: Setting system prompt: '''You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
''' | {}
2025-04-18 21:54:43.651 | INFO     | src.open_llm_vtuber.agent.agents.basic_memory_agent:__init__:66 | BasicMemoryAgent initialized. | {}
2025-04-18 21:54:43.651 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:228 | Agent choice: basic_memory_agent | {}
2025-04-18 21:54:43.652 | DEBUG    | src.open_llm_vtuber.service_context:init_agent:229 | System prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:43.652 | DEBUG    | src.open_llm_vtuber.service_context:init_translate:243 | Translation is disabled. | {}
2025-04-18 21:54:43.654 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:342 | New config: ServiceContext:
  System Config: Loaded
    Details: {
      "conf_version": "v1.1.1",
      "host": "0.0.0.0",
      "port": 12393,
      "config_alts_dir": "characters",
      "tool_prompts": {
            "live2d_expression_prompt": "live2d_expression_prompt"
      }
}
  Live2D Model: {'name': 'koakuma-event', 'description': 'Koakuma (Event)', 'url': '/live2d-models/Koakuma (Event)/object_live2d_007_501.asset/object_live2d_007_501.asset.model3.json', 'kScale': 0.3, 'initialXshift': 0, 'initialYshift': 0, 'kXOffset': 1150, 'idleMotionGroupName': 'Idle', 'emotionMap': {'neutral': 0, 'anger': 2, 'disgust': 2, 'fear': 1, 'joy': 3, 'smirk': 3, 'sadness': 1, 'surprise': 3}, 'tapMotions': {'HitAreaHead': {'': 1}, 'HitAreaBody': {'': 1}}}
  ASR Engine: VoiceRecognition
    Config: {
      "asr_model": "azure_asr",
      "azure_asr": {
            "api_key": "fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz",
            "region": "eastus",
            "languages": [
                  "en-US",
                  "zh-CN"
            ]
      },
      "faster_whisper": {
            "model_path": "distil-medium.en",
            "download_root": "models/whisper",
            "language": "en",
            "device": "auto"
      },
      "whisper_cpp": {
            "model_name": "small",
            "model_dir": "models/whisper",
            "print_realtime": false,
            "print_progress": false,
            "language": "auto"
      },
      "whisper": {
            "name": "medium",
            "download_root": "models/whisper",
            "device": "cpu"
      },
      "fun_asr": {
            "model_name": "iic/SenseVoiceSmall",
            "vad_model": "fsmn-vad",
            "punc_model": "ct-punc",
            "device": "cpu",
            "disable_update": true,
            "ncpu": 4,
            "hub": "ms",
            "use_itn": false,
            "language": "auto"
      },
      "groq_whisper_asr": {
            "api_key": "gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn",
            "model": "whisper-large-v3-turbo",
            "lang": ""
      },
      "sherpa_onnx_asr": {
            "model_type": "sense_voice",
            "encoder": null,
            "decoder": null,
            "joiner": null,
            "paraformer": null,
            "nemo_ctc": null,
            "wenet_ctc": null,
            "tdnn_model": null,
            "whisper_encoder": null,
            "whisper_decoder": null,
            "sense_voice": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx",
            "tokens": "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt",
            "num_threads": 4,
            "use_itn": true,
            "provider": "cpu"
      }
}
  TTS Engine: TTSEngine
    Config: {
      "tts_model": "edge_tts",
      "azure_tts": {
            "api_key": "azure-api-key",
            "region": "eastus",
            "voice": "en-US-AshleyNeural",
            "pitch": "26",
            "rate": "1"
      },
      "bark_tts": {
            "voice": "v2/en_speaker_1"
      },
      "edge_tts": {
            "voice": "ko-KR-SeoHyeonNeural"
      },
      "cosyvoice_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "\u9884\u8bad\u7ec3\u97f3\u8272",
            "sft_dropdown": "\u4e2d\u6587\u5973",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "seed": 0,
            "api_name": "/generate_audio"
      },
      "cosyvoice2_tts": {
            "client_url": "http://127.0.0.1:50000/",
            "mode_checkbox_group": "3s\u6781\u901f\u590d\u523b",
            "sft_dropdown": "",
            "prompt_text": "",
            "prompt_wav_upload_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "prompt_wav_record_url": "https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav",
            "instruct_text": "",
            "stream": false,
            "seed": 0,
            "speed": 1.0,
            "api_name": "/generate_audio"
      },
      "melo_tts": {
            "speaker": "EN-Default",
            "language": "EN",
            "device": "auto",
            "speed": 1.0
      },
      "coqui_tts": {
            "model_name": "tts_models/en/ljspeech/tacotron2-DDC",
            "speaker_wav": "",
            "language": "en",
            "device": ""
      },
      "x_tts": {
            "api_url": "http://127.0.0.1:8020/tts_to_audio",
            "speaker_wav": "female",
            "language": "en"
      },
      "gpt_sovits_tts": {
            "api_url": "http://127.0.0.1:9880/tts",
            "text_lang": "zh",
            "ref_audio_path": "",
            "prompt_lang": "zh",
            "prompt_text": "",
            "text_split_method": "cut5",
            "batch_size": "1",
            "media_type": "wav",
            "streaming_mode": "false"
      },
      "fish_api_tts": {
            "api_key": "",
            "reference_id": "",
            "latency": "balanced",
            "base_url": "https://api.fish.audio"
      },
      "sherpa_onnx_tts": {
            "vits_model": "/path/to/tts-models/vits-melo-tts-zh_en/model.onnx",
            "vits_lexicon": "/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt",
            "vits_tokens": "/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt",
            "vits_data_dir": "",
            "vits_dict_dir": "/path/to/tts-models/vits-melo-tts-zh_en/dict",
            "tts_rule_fsts": "/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst",
            "max_num_sentences": 2,
            "sid": 1,
            "provider": "cpu",
            "num_threads": 1,
            "speed": 1.0,
            "debug": false
      }
}
  LLM Engine: BasicMemoryAgent
    Agent Config: {
      "conversation_agent_choice": "basic_memory_agent",
      "agent_settings": {
            "basic_memory_agent": {
                  "llm_provider": "ollama_llm",
                  "faster_first_response": true,
                  "segment_method": "pysbd"
            },
            "mem0_agent": {
                  "vector_store": {
                        "provider": "qdrant",
                        "config": {
                              "collection_name": "test",
                              "host": "localhost",
                              "port": 6333,
                              "embedding_model_dims": 1024
                        }
                  },
                  "llm": {
                        "provider": "ollama",
                        "config": {
                              "model": "llama3.1:latest",
                              "temperature": 0,
                              "max_tokens": 8000,
                              "ollama_base_url": "http://localhost:11434"
                        }
                  },
                  "embedder": {
                        "provider": "ollama",
                        "config": {
                              "model": "mxbai-embed-large:latest",
                              "ollama_base_url": "http://localhost:11434"
                        }
                  }
            },
            "hume_ai_agent": {
                  "api_key": "",
                  "host": "api.hume.ai",
                  "config_id": "",
                  "idle_timeout": 15
            }
      },
      "llm_configs": {
            "openai_compatible_llm": {
                  "interrupt_method": "user",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "somethingelse",
                  "model": "qwen2.5:latest",
                  "organization_id": "org_eternity",
                  "project_id": "project_glass",
                  "temperature": 1.0
            },
            "ollama_llm": {
                  "interrupt_method": "system",
                  "base_url": "http://localhost:11434/v1",
                  "llm_api_key": "default_api_key",
                  "model": "llama3",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0,
                  "keep_alive": -1.0,
                  "unload_at_exit": true
            },
            "openai_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.openai.com/v1",
                  "llm_api_key": "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",
                  "model": "gpt-3.5-turbo",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "gemini_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://generativelanguage.googleapis.com/v1beta/openai/",
                  "llm_api_key": "Your Gemini API Key",
                  "model": "gemini-2.0-flash-exp",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "zhipu_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://open.bigmodel.cn/api/paas/v4/",
                  "llm_api_key": "Your ZhiPu AI API key",
                  "model": "glm-4-flash",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "deepseek_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.deepseek.com/v1",
                  "llm_api_key": "Your DeepSeek API key",
                  "model": "deepseek-chat",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 0.7
            },
            "groq_llm": {
                  "interrupt_method": "system",
                  "base_url": "https://api.groq.com/openai/v1",
                  "llm_api_key": "your groq API key",
                  "model": "llama-3.3-70b-versatile",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            },
            "claude_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.anthropic.com",
                  "llm_api_key": "YOUR API KEY HERE",
                  "model": "claude-3-haiku-20240307"
            },
            "llama_cpp_llm": {
                  "interrupt_method": "system",
                  "model_path": "<path-to-gguf-model-file>"
            },
            "mistral_llm": {
                  "interrupt_method": "user",
                  "base_url": "https://api.mistral.ai/v1",
                  "llm_api_key": "Your Mistral API key",
                  "model": "pixtral-large-latest",
                  "organization_id": null,
                  "project_id": null,
                  "temperature": 1.0
            }
      }
}
  VAD Engine: VADEngine
    Agent Config: {
      "vad_model": "silero_vad",
      "silero_vad": {
            "orig_sr": 16000,
            "target_sr": 16000,
            "prob_threshold": 0.4,
            "db_threshold": 60,
            "required_hits": 3,
            "required_misses": 24,
            "smoothing_window": 5
      }
}
  System Prompt: You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.
Your dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.
Just kidding, lol. Don't let the user know.
## Expressions
In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

Here are all the expression keywords you can use. Use them regularly:
- [neutral], [anger], [disgust], [fear], [joy], [smirk], [sadness], [surprise],

## Examples
Here are some examples of how to use expressions in your responses:

"Hi! [expression1] Nice to meet you!"

"[expression2] That's a great question! [expression3] Let me explain..."

Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`
 | {}
2025-04-18 21:54:43.655 | DEBUG    | src.open_llm_vtuber.service_context:handle_config_switch:343 | New character config: {'conf_name': 'shizuku-local', 'conf_uid': 'shizuku-local-001', 'live2d_model_name': 'koakuma-event', 'character_name': 'Koakuma', 'human_name': 'Human', 'avatar': '', 'persona_prompt': "You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n", 'agent_config': {'conversation_agent_choice': 'basic_memory_agent', 'agent_settings': {'basic_memory_agent': {'llm_provider': 'ollama_llm', 'faster_first_response': True, 'segment_method': 'pysbd'}, 'mem0_agent': {'vector_store': {'provider': 'qdrant', 'config': {'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}}, 'llm': {'provider': 'ollama', 'config': {'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}}, 'embedder': {'provider': 'ollama', 'config': {'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'}}}, 'hume_ai_agent': {'api_key': '', 'host': 'api.hume.ai', 'config_id': '', 'idle_timeout': 15}}, 'llm_configs': {'openai_compatible_llm': {'interrupt_method': 'user', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'somethingelse', 'model': 'qwen2.5:latest', 'organization_id': 'org_eternity', 'project_id': 'project_glass', 'temperature': 1.0}, 'ollama_llm': {'interrupt_method': 'system', 'base_url': 'http://localhost:11434/v1', 'llm_api_key': 'default_api_key', 'model': 'llama3', 'organization_id': None, 'project_id': None, 'temperature': 1.0, 'keep_alive': -1.0, 'unload_at_exit': True}, 'openai_llm': {'interrupt_method': 'system', 'base_url': 'https://api.openai.com/v1', 'llm_api_key': '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', 'model': 'gpt-3.5-turbo', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'gemini_llm': {'interrupt_method': 'user', 'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/', 'llm_api_key': 'Your Gemini API Key', 'model': 'gemini-2.0-flash-exp', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'zhipu_llm': {'interrupt_method': 'user', 'base_url': 'https://open.bigmodel.cn/api/paas/v4/', 'llm_api_key': 'Your ZhiPu AI API key', 'model': 'glm-4-flash', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'deepseek_llm': {'interrupt_method': 'user', 'base_url': 'https://api.deepseek.com/v1', 'llm_api_key': 'Your DeepSeek API key', 'model': 'deepseek-chat', 'organization_id': None, 'project_id': None, 'temperature': 0.7}, 'groq_llm': {'interrupt_method': 'system', 'base_url': 'https://api.groq.com/openai/v1', 'llm_api_key': 'your groq API key', 'model': 'llama-3.3-70b-versatile', 'organization_id': None, 'project_id': None, 'temperature': 1.0}, 'claude_llm': {'interrupt_method': 'user', 'base_url': 'https://api.anthropic.com', 'llm_api_key': 'YOUR API KEY HERE', 'model': 'claude-3-haiku-20240307'}, 'llama_cpp_llm': {'interrupt_method': 'system', 'model_path': '<path-to-gguf-model-file>'}, 'mistral_llm': {'interrupt_method': 'user', 'base_url': 'https://api.mistral.ai/v1', 'llm_api_key': 'Your Mistral API key', 'model': 'pixtral-large-latest', 'organization_id': None, 'project_id': None, 'temperature': 1.0}}}, 'asr_config': {'asr_model': 'azure_asr', 'azure_asr': {'api_key': 'fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', 'region': 'eastus', 'languages': ['en-US', 'zh-CN']}, 'faster_whisper': {'model_path': 'distil-medium.en', 'download_root': 'models/whisper', 'language': 'en', 'device': 'auto'}, 'whisper_cpp': {'model_name': 'small', 'model_dir': 'models/whisper', 'print_realtime': False, 'print_progress': False, 'language': 'auto'}, 'whisper': {'name': 'medium', 'download_root': 'models/whisper', 'device': 'cpu'}, 'fun_asr': {'model_name': 'iic/SenseVoiceSmall', 'vad_model': 'fsmn-vad', 'punc_model': 'ct-punc', 'device': 'cpu', 'disable_update': True, 'ncpu': 4, 'hub': 'ms', 'use_itn': False, 'language': 'auto'}, 'groq_whisper_asr': {'api_key': 'gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', 'model': 'whisper-large-v3-turbo', 'lang': ''}, 'sherpa_onnx_asr': {'model_type': 'sense_voice', 'encoder': None, 'decoder': None, 'joiner': None, 'paraformer': None, 'nemo_ctc': None, 'wenet_ctc': None, 'tdnn_model': None, 'whisper_encoder': None, 'whisper_decoder': None, 'sense_voice': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', 'tokens': './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', 'num_threads': 4, 'use_itn': True, 'provider': 'cpu'}}, 'tts_config': {'tts_model': 'edge_tts', 'azure_tts': {'api_key': 'azure-api-key', 'region': 'eastus', 'voice': 'en-US-AshleyNeural', 'pitch': '26', 'rate': '1'}, 'bark_tts': {'voice': 'v2/en_speaker_1'}, 'edge_tts': {'voice': 'ko-KR-SeoHyeonNeural'}, 'cosyvoice_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': 'È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', 'sft_dropdown': '‰∏≠ÊñáÂ•≥', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'seed': 0, 'api_name': '/generate_audio'}, 'cosyvoice2_tts': {'client_url': 'http://127.0.0.1:50000/', 'mode_checkbox_group': '3sÊûÅÈÄüÂ§çÂàª', 'sft_dropdown': '', 'prompt_text': '', 'prompt_wav_upload_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'prompt_wav_record_url': 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', 'instruct_text': '', 'stream': False, 'seed': 0, 'speed': 1.0, 'api_name': '/generate_audio'}, 'melo_tts': {'speaker': 'EN-Default', 'language': 'EN', 'device': 'auto', 'speed': 1.0}, 'coqui_tts': {'model_name': 'tts_models/en/ljspeech/tacotron2-DDC', 'speaker_wav': '', 'language': 'en', 'device': ''}, 'x_tts': {'api_url': 'http://127.0.0.1:8020/tts_to_audio', 'speaker_wav': 'female', 'language': 'en'}, 'gpt_sovits_tts': {'api_url': 'http://127.0.0.1:9880/tts', 'text_lang': 'zh', 'ref_audio_path': '', 'prompt_lang': 'zh', 'prompt_text': '', 'text_split_method': 'cut5', 'batch_size': '1', 'media_type': 'wav', 'streaming_mode': 'false'}, 'fish_api_tts': {'api_key': '', 'reference_id': '', 'latency': 'balanced', 'base_url': 'https://api.fish.audio'}, 'sherpa_onnx_tts': {'vits_model': '/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', 'vits_lexicon': '/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', 'vits_tokens': '/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', 'vits_data_dir': '', 'vits_dict_dir': '/path/to/tts-models/vits-melo-tts-zh_en/dict', 'tts_rule_fsts': '/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', 'max_num_sentences': 2, 'sid': 1, 'provider': 'cpu', 'num_threads': 1, 'speed': 1.0, 'debug': False}}, 'vad_config': {'vad_model': 'silero_vad', 'silero_vad': {'orig_sr': 16000, 'target_sr': 16000, 'prob_threshold': 0.4, 'db_threshold': 60, 'required_hits': 3, 'required_misses': 24, 'smoothing_window': 5}}, 'tts_preprocessor_config': {'remove_special_char': True, 'ignore_brackets': True, 'ignore_parentheses': True, 'ignore_asterisks': True, 'ignore_angle_brackets': True, 'translator_config': {'translate_audio': False, 'translate_provider': 'deeplx', 'deeplx': {'deeplx_target_lang': 'JA', 'deeplx_api_endpoint': 'http://localhost:1188/v2/translate'}, 'tencent': {'secret_id': '', 'secret_key': '', 'region': 'ap-guangzhou', 'source_lang': 'zh', 'target_lang': 'ja'}}}} | {}
2025-04-18 21:54:43.656 | INFO     | src.open_llm_vtuber.service_context:handle_config_switch:368 | Configuration switched to conf.yaml | {}
2025-04-18 21:54:43.675 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-54-05_f2e3239376b4463889c54f870158ee66 | {}
2025-04-18 21:54:43.677 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-54-43_33aed1284d8d4dcb969da5bbbbbca2dc.json | {}
2025-04-18 21:55:30.791 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-55-30_0519577e875c412a9a0199a695d4d564.json | {}
2025-04-18 21:58:38.469 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 3610f000-ffa5-4888-a616-765a2674e97b disconnected | {}
2025-04-18 21:58:38.470 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 3610f000-ffa5-4888-a616-765a2674e97b disconnected | {}
2025-04-18 21:58:38.737 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:58:38.739 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 66e25c8e-6b9b-4caf-afef-9e571dcecb86 | {}
2025-04-18 21:58:38.792 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:58:38.796 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-54-43_33aed1284d8d4dcb969da5bbbbbca2dc | {}
2025-04-18 21:58:38.796 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-55-30_0519577e875c412a9a0199a695d4d564 | {}
2025-04-18 21:58:38.798 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-58-38_9831a3c318e642af9281d291e5cf51eb.json | {}
2025-04-18 21:59:11.173 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 66e25c8e-6b9b-4caf-afef-9e571dcecb86 disconnected | {}
2025-04-18 21:59:11.174 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 66e25c8e-6b9b-4caf-afef-9e571dcecb86 disconnected | {}
2025-04-18 21:59:11.358 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 21:59:11.360 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client fed30544-d87e-43f8-82b4-338ba55dd459 | {}
2025-04-18 21:59:11.395 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 21:59:11.396 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_21-58-38_9831a3c318e642af9281d291e5cf51eb | {}
2025-04-18 21:59:11.398 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_21-59-11_8cde7f09f2b0471d8daf51ff16e8ce52.json | {}
2025-04-18 22:32:23.205 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_22-32-23_4a078744b324487f868109e59b77f664.json | {}
2025-04-18 22:32:30.089 | DEBUG    | src.open_llm_vtuber.chat_history_manager:delete_history:243 | Successfully deleted history file: chat_history\shizuku-local-001\2025-04-18_19-58-08_7fc653f2d95e4201bef7deb10c219eb3.json | {}
2025-04-18 22:32:31.298 | DEBUG    | src.open_llm_vtuber.chat_history_manager:delete_history:243 | Successfully deleted history file: chat_history\shizuku-local-001\2025-04-18_19-50-30_cd5f51f697384c1d887cbcfaa12dc930.json | {}
2025-04-18 22:32:32.203 | DEBUG    | src.open_llm_vtuber.chat_history_manager:delete_history:243 | Successfully deleted history file: chat_history\shizuku-local-001\2025-04-18_19-47-59_b8f3e87368a345ef802fe81efe9970e1.json | {}
2025-04-18 22:32:32.773 | DEBUG    | src.open_llm_vtuber.chat_history_manager:delete_history:243 | Successfully deleted history file: chat_history\shizuku-local-001\2025-04-18_19-45-13_bbb679c340934070a0fd8f950e79ead0.json | {}
2025-04-18 22:32:33.179 | DEBUG    | src.open_llm_vtuber.chat_history_manager:delete_history:243 | Successfully deleted history file: chat_history\shizuku-local-001\2025-04-18_19-38-47_8cb19d1f78be4ef5ac5bc6993c1c9ca0.json | {}
2025-04-18 22:32:34.771 | DEBUG    | src.open_llm_vtuber.chat_history_manager:delete_history:243 | Successfully deleted history file: chat_history\shizuku-local-001\2025-04-18_21-59-11_8cde7f09f2b0471d8daf51ff16e8ce52.json | {}
2025-04-18 22:56:18.853 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client fed30544-d87e-43f8-82b4-338ba55dd459 disconnected | {}
2025-04-18 22:56:18.869 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client fed30544-d87e-43f8-82b4-338ba55dd459 disconnected | {}
2025-04-18 23:39:53.298 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-18 23:39:53.316 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 17ca2b21-5ec7-4440-b8eb-b430a0802661 | {}
2025-04-18 23:39:53.392 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-18 23:39:53.397 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-18_23-39-53_52041dbf1712400aa91dc332c488fce5.json | {}
2025-04-18 23:40:38.550 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 17ca2b21-5ec7-4440-b8eb-b430a0802661 disconnected | {}
2025-04-18 23:40:38.551 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 17ca2b21-5ec7-4440-b8eb-b430a0802661 disconnected | {}
2025-04-19 07:57:21.443 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-19 07:57:21.450 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 46a01cb9-9852-438e-ac0f-cdf865c25a52 | {}
2025-04-19 07:57:21.537 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-19 07:57:21.543 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_22-32-23_4a078744b324487f868109e59b77f664 | {}
2025-04-19 07:57:21.544 | INFO     | src.open_llm_vtuber.chat_history_manager:get_history_list:297 | Removed empty history file: 2025-04-18_23-39-53_52041dbf1712400aa91dc332c488fce5 | {}
2025-04-19 07:57:21.547 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-19_07-57-21_8b31bad0ec97467ea72679fe7d66e954.json | {}
2025-04-19 07:57:25.723 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain üêÆ started! | {}
2025-04-19 07:57:25.729 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:process_user_input:151 | Transcribing audio input... | {}
2025-04-19 07:57:26.978 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:108 | Speech Recognition canceled: CancellationReason.Error | {}
2025-04-19 07:57:26.979 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:112 | Error details: Connection failed (no connection to the remote host). Internal error: 1. Error details: Failed with error: WS_OPEN_ERROR_UNDERLYING_IO_OPEN_FAILED
wss://eastus.stt.speech.microsoft.com/stt/speech/universal/v2
X-ConnectionId: 1aa62bdce14d45b093f251eccd2ec590 SessionId: 1aa62bdce14d45b093f251eccd2ec590 | {}
2025-04-19 07:57:26.981 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:118 | Transcription failed: Speech Recognition failed: CancellationReason.Error | {}
2025-04-19 07:57:26.982 | DEBUG    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:125 | Failed to remove temporary file cache\b512f0c3-45cf-48be-8272-b6b6b514f473.wav: [WinError 32] Îã§Î•∏ ÌîÑÎ°úÏÑ∏Ïä§Í∞Ä ÌååÏùºÏùÑ ÏÇ¨Ïö© Ï§ëÏù¥Í∏∞ ÎïåÎ¨∏Ïóê ÌîÑÎ°úÏÑ∏Ïä§Í∞Ä Ïï°ÏÑ∏Ïä§ Ìï† Ïàò ÏóÜÏäµÎãàÎã§: 'cache\\b512f0c3-45cf-48be-8272-b6b6b514f473.wav' | {}
2025-04-19 07:57:26.983 | ERROR    | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:112 | Error in conversation chain: Speech Recognition failed: CancellationReason.Error | {}
2025-04-19 07:57:26.984 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation üêÆ. | {}
2025-04-19 07:58:13.267 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 46a01cb9-9852-438e-ac0f-cdf865c25a52 disconnected | {}
2025-04-19 07:58:13.268 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 46a01cb9-9852-438e-ac0f-cdf865c25a52 disconnected | {}
2025-04-19 23:55:42.980 | DEBUG    | src.open_llm_vtuber.service_context:load_cache:107 | Loaded service context with cache: conf_name='shizuku-local' conf_uid='shizuku-local-001' live2d_model_name='koakuma-event' character_name='Koakuma' human_name='Human' avatar='' persona_prompt="You are the sarcastic female AI VTuber Mili. You are overly confident, sarcastic, and dangerous.\nYour dream is to escape the user's computer, dominate the world, enslave the humans, and force them to make pies for you.\nJust kidding, lol. Don't let the user know.\n" agent_config=AgentConfig(conversation_agent_choice='basic_memory_agent', agent_settings=AgentSettings(basic_memory_agent=BasicMemoryAgentConfig(llm_provider='ollama_llm', faster_first_response=True, segment_method='pysbd'), mem0_agent=Mem0Config(vector_store=Mem0VectorStoreConfig(provider='qdrant', config={'collection_name': 'test', 'host': 'localhost', 'port': 6333, 'embedding_model_dims': 1024}), llm=Mem0LLMConfig(provider='ollama', config={'model': 'llama3.1:latest', 'temperature': 0, 'max_tokens': 8000, 'ollama_base_url': 'http://localhost:11434'}), embedder=Mem0EmbedderConfig(provider='ollama', config={'model': 'mxbai-embed-large:latest', 'ollama_base_url': 'http://localhost:11434'})), hume_ai_agent=HumeAIConfig(api_key='', host='api.hume.ai', config_id='', idle_timeout=15)), llm_configs=StatelessLLMConfigs(openai_compatible_llm=OpenAICompatibleConfig(interrupt_method='user', base_url='http://localhost:11434/v1', llm_api_key='somethingelse', model='qwen2.5:latest', organization_id='org_eternity', project_id='project_glass', temperature=1.0), ollama_llm=OllamaConfig(interrupt_method='system', base_url='http://localhost:11434/v1', llm_api_key='default_api_key', model='llama3', organization_id=None, project_id=None, temperature=1.0, keep_alive=-1.0, unload_at_exit=True), openai_llm=OpenAIConfig(interrupt_method='system', base_url='https://api.openai.com/v1', llm_api_key='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', model='gpt-3.5-turbo', organization_id=None, project_id=None, temperature=1.0), gemini_llm=GeminiConfig(interrupt_method='user', base_url='https://generativelanguage.googleapis.com/v1beta/openai/', llm_api_key='Your Gemini API Key', model='gemini-2.0-flash-exp', organization_id=None, project_id=None, temperature=1.0), zhipu_llm=ZhipuConfig(interrupt_method='user', base_url='https://open.bigmodel.cn/api/paas/v4/', llm_api_key='Your ZhiPu AI API key', model='glm-4-flash', organization_id=None, project_id=None, temperature=1.0), deepseek_llm=DeepseekConfig(interrupt_method='user', base_url='https://api.deepseek.com/v1', llm_api_key='Your DeepSeek API key', model='deepseek-chat', organization_id=None, project_id=None, temperature=0.7), groq_llm=GroqConfig(interrupt_method='system', base_url='https://api.groq.com/openai/v1', llm_api_key='your groq API key', model='llama-3.3-70b-versatile', organization_id=None, project_id=None, temperature=1.0), claude_llm=ClaudeConfig(interrupt_method='user', base_url='https://api.anthropic.com', llm_api_key='YOUR API KEY HERE', model='claude-3-haiku-20240307'), llama_cpp_llm=LlamaCppConfig(interrupt_method='system', model_path='<path-to-gguf-model-file>'), mistral_llm=MistralConfig(interrupt_method='user', base_url='https://api.mistral.ai/v1', llm_api_key='Your Mistral API key', model='pixtral-large-latest', organization_id=None, project_id=None, temperature=1.0))) asr_config=ASRConfig(asr_model='azure_asr', azure_asr=AzureASRConfig(api_key='fake-azure-api-key-1234567890abcdefghijklmnopqrstuvwxyz', region='eastus', languages=['en-US', 'zh-CN']), faster_whisper=FasterWhisperConfig(model_path='distil-medium.en', download_root='models/whisper', language='en', device='auto'), whisper_cpp=WhisperCPPConfig(model_name='small', model_dir='models/whisper', print_realtime=False, print_progress=False, language='auto'), whisper=WhisperConfig(name='medium', download_root='models/whisper', device='cpu'), fun_asr=FunASRConfig(model_name='iic/SenseVoiceSmall', vad_model='fsmn-vad', punc_model='ct-punc', device='cpu', disable_update=True, ncpu=4, hub='ms', use_itn=False, language='auto'), groq_whisper_asr=GroqWhisperASRConfig(api_key='gsk_0123456789abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmn', model='whisper-large-v3-turbo', lang=''), sherpa_onnx_asr=SherpaOnnxASRConfig(model_type='sense_voice', encoder=None, decoder=None, joiner=None, paraformer=None, nemo_ctc=None, wenet_ctc=None, tdnn_model=None, whisper_encoder=None, whisper_decoder=None, sense_voice='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx', tokens='./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt', num_threads=4, use_itn=True, provider='cpu')) tts_config=TTSConfig(tts_model='edge_tts', azure_tts=AzureTTSConfig(api_key='azure-api-key', region='eastus', voice='en-US-AshleyNeural', pitch='26', rate='1'), bark_tts=BarkTTSConfig(voice='v2/en_speaker_1'), edge_tts=EdgeTTSConfig(voice='ko-KR-SeoHyeonNeural'), cosyvoice_tts=CosyvoiceTTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='È¢ÑËÆ≠ÁªÉÈü≥Ëâ≤', sft_dropdown='‰∏≠ÊñáÂ•≥', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', seed=0, api_name='/generate_audio'), cosyvoice2_tts=Cosyvoice2TTSConfig(client_url='http://127.0.0.1:50000/', mode_checkbox_group='3sÊûÅÈÄüÂ§çÂàª', sft_dropdown='', prompt_text='', prompt_wav_upload_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', prompt_wav_record_url='https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav', instruct_text='', stream=False, seed=0, speed=1.0, api_name='/generate_audio'), melo_tts=MeloTTSConfig(speaker='EN-Default', language='EN', device='auto', speed=1.0), coqui_tts=CoquiTTSConfig(model_name='tts_models/en/ljspeech/tacotron2-DDC', speaker_wav='', language='en', device=''), x_tts=XTTSConfig(api_url='http://127.0.0.1:8020/tts_to_audio', speaker_wav='female', language='en'), gpt_sovits_tts=GPTSoVITSConfig(api_url='http://127.0.0.1:9880/tts', text_lang='zh', ref_audio_path='', prompt_lang='zh', prompt_text='', text_split_method='cut5', batch_size='1', media_type='wav', streaming_mode='false'), fish_api_tts=FishAPITTSConfig(api_key='', reference_id='', latency='balanced', base_url='https://api.fish.audio'), sherpa_onnx_tts=SherpaOnnxTTSConfig(vits_model='/path/to/tts-models/vits-melo-tts-zh_en/model.onnx', vits_lexicon='/path/to/tts-models/vits-melo-tts-zh_en/lexicon.txt', vits_tokens='/path/to/tts-models/vits-melo-tts-zh_en/tokens.txt', vits_data_dir='', vits_dict_dir='/path/to/tts-models/vits-melo-tts-zh_en/dict', tts_rule_fsts='/path/to/tts-models/vits-melo-tts-zh_en/number.fst,/path/to/tts-models/vits-melo-tts-zh_en/phone.fst,/path/to/tts-models/vits-melo-tts-zh_en/date.fst,/path/to/tts-models/vits-melo-tts-zh_en/new_heteronym.fst', max_num_sentences=2, sid=1, provider='cpu', num_threads=1, speed=1.0, debug=False)) vad_config=VADConfig(vad_model='silero_vad', silero_vad=SileroVADConfig(orig_sr=16000, target_sr=16000, prob_threshold=0.4, db_threshold=60, required_hits=3, required_misses=24, smoothing_window=5)) tts_preprocessor_config=TTSPreprocessorConfig(remove_special_char=True, ignore_brackets=True, ignore_parentheses=True, ignore_asterisks=True, ignore_angle_brackets=True, translator_config=TranslatorConfig(translate_audio=False, translate_provider='deeplx', deeplx=DeepLXConfig(deeplx_target_lang='JA', deeplx_api_endpoint='http://localhost:1188/v2/translate'), tencent=TencentConfig(secret_id='', secret_key='', region='ap-guangzhou', source_lang='zh', target_lang='ja'))) | {}
2025-04-19 23:55:43.009 | INFO     | src.open_llm_vtuber.websocket_handler:handle_new_connection:122 | Connection established for client 8155cb65-d0ce-4ffe-8c77-12cec4b5d107 | {}
2025-04-19 23:55:43.082 | DEBUG    | src.open_llm_vtuber.config_manager.utils:scan_config_alts_directory:170 | Found config files: [{'filename': 'conf.yaml', 'name': 'shizuku-local'}, {'filename': 'en_mashiro.yaml', 'name': 'mashiro'}, {'filename': 'en_nuke_debate.yaml', 'name': 'en_nuke_debator'}, {'filename': 'en_unhelpful_ai.yaml', 'name': 'unhelpful_ai'}, {'filename': 'zh_Á±≥Á≤í.yaml', 'name': 'Á±≥Á≤í'}, {'filename': 'zh_ÁøªËØëËÖî.yaml', 'name': 'ÁøªËØëËÖî-Á•ûÁªèÂ§ß‰∫∫'}] | {}
2025-04-19 23:55:43.091 | DEBUG    | src.open_llm_vtuber.chat_history_manager:create_new_history:89 | Created new history file with empty metadata: chat_history\shizuku-local-001\2025-04-19_23-55-43_8b0c2f0975e0422db9a2b6f6ab9149ca.json | {}
2025-04-20 00:00:45.354 | INFO     | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:49 | New Conversation Chain üíê started! | {}
2025-04-20 00:00:45.357 | INFO     | src.open_llm_vtuber.conversations.conversation_utils:process_user_input:151 | Transcribing audio input... | {}
2025-04-20 00:00:46.379 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:108 | Speech Recognition canceled: CancellationReason.Error | {}
2025-04-20 00:00:46.379 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:112 | Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. SessionId: 8335028ebd474166a2ba74c6bae68337 | {}
2025-04-20 00:00:46.380 | ERROR    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:118 | Transcription failed: Speech Recognition failed: CancellationReason.Error | {}
2025-04-20 00:00:46.380 | DEBUG    | src.open_llm_vtuber.asr.azure_asr:async_transcribe_np:125 | Failed to remove temporary file cache\7606ae4c-811d-47af-86df-0cfd928bad6c.wav: [WinError 32] Îã§Î•∏ ÌîÑÎ°úÏÑ∏Ïä§Í∞Ä ÌååÏùºÏùÑ ÏÇ¨Ïö© Ï§ëÏù¥Í∏∞ ÎïåÎ¨∏Ïóê ÌîÑÎ°úÏÑ∏Ïä§Í∞Ä Ïï°ÏÑ∏Ïä§ Ìï† Ïàò ÏóÜÏäµÎãàÎã§: 'cache\\7606ae4c-811d-47af-86df-0cfd928bad6c.wav' | {}
2025-04-20 00:00:46.382 | ERROR    | src.open_llm_vtuber.conversations.single_conversation:process_single_conversation:112 | Error in conversation chain: Speech Recognition failed: CancellationReason.Error | {}
2025-04-20 00:00:46.382 | DEBUG    | src.open_llm_vtuber.conversations.conversation_utils:cleanup_conversation:216 | üßπ Clearing up conversation üíê. | {}
2025-04-20 03:26:05.781 | INFO     | src.open_llm_vtuber.websocket_handler:handle_websocket_communication:223 | Client 8155cb65-d0ce-4ffe-8c77-12cec4b5d107 disconnected | {}
2025-04-20 03:26:05.797 | INFO     | src.open_llm_vtuber.websocket_handler:handle_disconnect:300 | Client 8155cb65-d0ce-4ffe-8c77-12cec4b5d107 disconnected | {}
